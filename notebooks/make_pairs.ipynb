{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "                \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0]) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def getChars(item):\n",
    "    return [element for element in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_orig = pd.read_csv('../input/ru_with_types/output-00001-of-00100', sep='\\t', names=['class', 'before', 'after'],\n",
    "                       quoting=csv.QUOTE_NONE, encoding='utf-8', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('../input/ru_train.csv', dtype = str)\n",
    "data_test = pd.read_csv('../input/ru_test.csv', dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len pairs before filtering: 2981069\n",
      "Len pairs after filtering: 1887522\n"
     ]
    }
   ],
   "source": [
    "big_str = list(data_orig.before.astype(str).values)\n",
    "output_list = list(data_orig.after.astype(str).values)\n",
    "\n",
    "stride = 3\n",
    "input_list = []\n",
    "pairs = []\n",
    "for i in range(len(big_str)):\n",
    "    cur_item = ['<norm>'] + getChars(big_str[i]) + ['</norm>']\n",
    "    cur_item = getChars(' '.join(big_str[i-stride:i])) \\\n",
    "    + cur_item + \\\n",
    "    getChars(' '.join(big_str[i+1:i+stride+1]))\n",
    "    input_list += [' '.join(cur_item)]\n",
    "\n",
    "pairs = list(zip(input_list, output_list))\n",
    "print('Len pairs before filtering:', len(pairs))\n",
    "pairs = filterPairs(pairs)\n",
    "print('Len pairs after filtering:', len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lang, output_lang = Lang('nonnorm'), Lang('norm')\n",
    "\n",
    "for pair in pairs:\n",
    "    input_lang.addSentence(pair[0])\n",
    "    output_lang.addSentence(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "        \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=2):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "        \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_output, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "    \n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "   \n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            \n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "            \n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [variablesFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    " \n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "0m 10s (- 133m 37s) (100 0%) 2.4801\n",
      "0m 15s (- 98m 49s) (200 0%) 1.3551\n",
      "0m 20s (- 86m 41s) (300 0%) 0.6106\n",
      "0m 26s (- 81m 0s) (400 0%) 1.1455\n",
      "0m 31s (- 76m 59s) (500 0%) 1.1940\n",
      "0m 35s (- 74m 1s) (600 0%) 1.2815\n",
      "0m 40s (- 72m 17s) (700 0%) 1.0909\n",
      "0m 46s (- 71m 14s) (800 1%) 1.0254\n",
      "0m 50s (- 69m 55s) (900 1%) 1.2471\n",
      "0m 55s (- 69m 2s) (1000 1%) 1.2285\n",
      "1m 0s (- 68m 14s) (1100 1%) 1.1218\n",
      "1m 6s (- 67m 53s) (1200 1%) 1.1244\n",
      "1m 11s (- 67m 8s) (1300 1%) 1.1291\n",
      "1m 16s (- 66m 51s) (1400 1%) 1.0780\n",
      "1m 21s (- 66m 28s) (1500 2%) 1.1007\n",
      "1m 26s (- 66m 14s) (1600 2%) 0.9705\n",
      "1m 31s (- 65m 53s) (1700 2%) 1.1884\n",
      "1m 36s (- 65m 29s) (1800 2%) 1.0177\n",
      "1m 42s (- 65m 25s) (1900 2%) 1.1489\n",
      "1m 46s (- 65m 4s) (2000 2%) 1.2692\n",
      "1m 52s (- 64m 48s) (2100 2%) 1.2382\n",
      "1m 56s (- 64m 28s) (2200 2%) 1.2546\n",
      "2m 2s (- 64m 22s) (2300 3%) 1.0099\n",
      "2m 7s (- 64m 7s) (2400 3%) 1.2606\n",
      "2m 12s (- 63m 50s) (2500 3%) 1.3285\n",
      "2m 17s (- 63m 37s) (2600 3%) 1.1326\n",
      "2m 22s (- 63m 32s) (2700 3%) 1.2358\n",
      "2m 27s (- 63m 18s) (2800 3%) 0.9611\n",
      "2m 32s (- 63m 13s) (2900 3%) 0.8722\n",
      "2m 37s (- 63m 11s) (3000 4%) 0.9389\n",
      "2m 43s (- 63m 8s) (3100 4%) 0.9087\n",
      "2m 48s (- 62m 56s) (3200 4%) 1.1118\n",
      "2m 53s (- 62m 44s) (3300 4%) 0.8365\n",
      "2m 58s (- 62m 42s) (3400 4%) 1.0074\n",
      "3m 3s (- 62m 30s) (3500 4%) 0.9420\n",
      "3m 8s (- 62m 20s) (3600 4%) 1.0336\n",
      "3m 13s (- 62m 12s) (3700 4%) 0.6953\n",
      "3m 19s (- 62m 12s) (3800 5%) 0.5395\n",
      "3m 24s (- 62m 2s) (3900 5%) 0.5147\n",
      "3m 29s (- 61m 53s) (4000 5%) 0.7515\n",
      "3m 34s (- 61m 43s) (4100 5%) 0.6396\n",
      "3m 39s (- 61m 37s) (4200 5%) 0.6956\n",
      "3m 44s (- 61m 31s) (4300 5%) 0.6403\n",
      "3m 49s (- 61m 25s) (4400 5%) 0.9331\n",
      "3m 55s (- 61m 23s) (4500 6%) 0.7083\n",
      "4m 0s (- 61m 15s) (4600 6%) 0.6422\n",
      "4m 5s (- 61m 8s) (4700 6%) 0.7540\n",
      "4m 10s (- 61m 0s) (4800 6%) 0.8316\n",
      "4m 15s (- 60m 54s) (4900 6%) 0.6994\n",
      "4m 20s (- 60m 43s) (5000 6%) 0.7496\n",
      "4m 25s (- 60m 36s) (5100 6%) 0.5106\n",
      "4m 30s (- 60m 28s) (5200 6%) 0.8532\n",
      "4m 35s (- 60m 25s) (5300 7%) 0.9109\n",
      "4m 40s (- 60m 17s) (5400 7%) 0.6542\n",
      "4m 45s (- 60m 8s) (5500 7%) 0.8475\n",
      "4m 50s (- 59m 59s) (5600 7%) 0.6493\n",
      "4m 55s (- 59m 55s) (5700 7%) 0.7973\n",
      "5m 0s (- 59m 48s) (5800 7%) 0.6682\n",
      "5m 5s (- 59m 41s) (5900 7%) 0.6749\n",
      "5m 10s (- 59m 33s) (6000 8%) 0.7700\n",
      "5m 16s (- 59m 30s) (6100 8%) 0.5011\n",
      "5m 21s (- 59m 23s) (6200 8%) 0.8583\n",
      "5m 26s (- 59m 15s) (6300 8%) 0.6222\n",
      "5m 31s (- 59m 8s) (6400 8%) 0.7691\n",
      "5m 36s (- 59m 3s) (6500 8%) 0.6223\n",
      "5m 41s (- 58m 55s) (6600 8%) 0.5150\n",
      "5m 45s (- 58m 46s) (6700 8%) 0.6019\n",
      "5m 50s (- 58m 38s) (6800 9%) 0.3782\n",
      "5m 56s (- 58m 34s) (6900 9%) 0.8746\n",
      "6m 0s (- 58m 26s) (7000 9%) 0.5605\n",
      "6m 5s (- 58m 19s) (7100 9%) 0.5863\n",
      "6m 11s (- 58m 15s) (7200 9%) 0.7318\n",
      "6m 16s (- 58m 9s) (7300 9%) 0.4138\n",
      "6m 21s (- 58m 2s) (7400 9%) 0.5751\n",
      "6m 26s (- 57m 55s) (7500 10%) 0.6531\n",
      "6m 31s (- 57m 51s) (7600 10%) 0.4952\n",
      "6m 36s (- 57m 44s) (7700 10%) 0.4765\n",
      "6m 41s (- 57m 36s) (7800 10%) 0.5818\n",
      "6m 46s (- 57m 30s) (7900 10%) 0.5632\n",
      "6m 51s (- 57m 26s) (8000 10%) 0.5227\n",
      "6m 56s (- 57m 19s) (8100 10%) 0.6902\n",
      "7m 1s (- 57m 13s) (8200 10%) 0.5180\n",
      "7m 6s (- 57m 6s) (8300 11%) 0.3641\n",
      "7m 11s (- 57m 1s) (8400 11%) 0.4758\n",
      "7m 16s (- 56m 54s) (8500 11%) 0.5579\n",
      "7m 21s (- 56m 48s) (8600 11%) 0.5958\n",
      "7m 26s (- 56m 43s) (8700 11%) 0.6149\n",
      "7m 31s (- 56m 38s) (8800 11%) 0.5360\n",
      "7m 36s (- 56m 32s) (8900 11%) 0.5060\n",
      "7m 41s (- 56m 24s) (9000 12%) 0.6530\n",
      "7m 46s (- 56m 20s) (9100 12%) 0.3783\n",
      "7m 51s (- 56m 14s) (9200 12%) 0.5487\n",
      "7m 56s (- 56m 8s) (9300 12%) 0.5425\n",
      "8m 1s (- 56m 2s) (9400 12%) 0.4483\n",
      "8m 7s (- 55m 57s) (9500 12%) 0.6270\n",
      "8m 12s (- 55m 52s) (9600 12%) 0.5700\n",
      "8m 17s (- 55m 46s) (9700 12%) 0.5738\n",
      "8m 22s (- 55m 39s) (9800 13%) 0.6528\n",
      "8m 27s (- 55m 34s) (9900 13%) 0.6511\n",
      "8m 32s (- 55m 28s) (10000 13%) 0.3514\n",
      "8m 37s (- 55m 24s) (10100 13%) 0.4342\n",
      "8m 42s (- 55m 18s) (10200 13%) 0.6379\n",
      "8m 47s (- 55m 14s) (10300 13%) 0.4944\n",
      "8m 52s (- 55m 8s) (10400 13%) 0.7561\n",
      "8m 57s (- 55m 3s) (10500 14%) 0.6524\n",
      "9m 3s (- 54m 59s) (10600 14%) 0.4199\n",
      "9m 8s (- 54m 53s) (10700 14%) 0.4586\n",
      "9m 13s (- 54m 48s) (10800 14%) 0.7030\n",
      "9m 18s (- 54m 42s) (10900 14%) 0.4050\n",
      "9m 23s (- 54m 37s) (11000 14%) 0.3761\n",
      "9m 28s (- 54m 32s) (11100 14%) 0.4866\n",
      "9m 33s (- 54m 26s) (11200 14%) 0.6612\n",
      "9m 38s (- 54m 21s) (11300 15%) 0.4631\n",
      "9m 43s (- 54m 16s) (11400 15%) 0.2639\n",
      "9m 48s (- 54m 10s) (11500 15%) 0.2924\n",
      "9m 53s (- 54m 4s) (11600 15%) 0.2721\n",
      "9m 58s (- 53m 59s) (11700 15%) 0.3620\n",
      "10m 3s (- 53m 53s) (11800 15%) 0.6733\n",
      "10m 8s (- 53m 47s) (11900 15%) 0.3188\n",
      "10m 13s (- 53m 41s) (12000 16%) 0.3984\n",
      "10m 18s (- 53m 37s) (12100 16%) 0.3253\n",
      "10m 23s (- 53m 31s) (12200 16%) 0.4913\n",
      "10m 28s (- 53m 25s) (12300 16%) 0.4299\n",
      "10m 33s (- 53m 18s) (12400 16%) 0.4063\n",
      "10m 38s (- 53m 14s) (12500 16%) 0.4272\n",
      "10m 43s (- 53m 8s) (12600 16%) 0.3619\n",
      "10m 48s (- 53m 2s) (12700 16%) 0.5894\n",
      "10m 53s (- 52m 56s) (12800 17%) 0.5721\n",
      "10m 59s (- 52m 52s) (12900 17%) 0.6246\n",
      "11m 3s (- 52m 46s) (13000 17%) 0.3870\n",
      "11m 8s (- 52m 40s) (13100 17%) 0.3728\n",
      "11m 14s (- 52m 36s) (13200 17%) 0.5830\n",
      "11m 19s (- 52m 31s) (13300 17%) 0.4851\n",
      "11m 24s (- 52m 25s) (13400 17%) 0.5806\n",
      "11m 29s (- 52m 20s) (13500 18%) 0.6722\n",
      "11m 34s (- 52m 15s) (13600 18%) 0.4273\n",
      "11m 39s (- 52m 10s) (13700 18%) 0.5601\n",
      "11m 44s (- 52m 4s) (13800 18%) 0.5744\n",
      "11m 50s (- 52m 1s) (13900 18%) 0.4995\n",
      "11m 54s (- 51m 55s) (14000 18%) 0.4574\n",
      "11m 59s (- 51m 49s) (14100 18%) 0.4715\n",
      "12m 4s (- 51m 43s) (14200 18%) 0.7626\n",
      "12m 10s (- 51m 39s) (14300 19%) 0.6740\n",
      "12m 15s (- 51m 33s) (14400 19%) 0.4466\n",
      "12m 20s (- 51m 27s) (14500 19%) 0.5214\n",
      "12m 25s (- 51m 22s) (14600 19%) 0.4950\n",
      "12m 30s (- 51m 17s) (14700 19%) 0.5168\n",
      "12m 35s (- 51m 11s) (14800 19%) 0.3644\n",
      "12m 40s (- 51m 5s) (14900 19%) 0.5887\n",
      "12m 45s (- 51m 0s) (15000 20%) 0.6177\n",
      "12m 50s (- 50m 56s) (15100 20%) 0.5410\n",
      "12m 55s (- 50m 51s) (15200 20%) 0.4247\n",
      "13m 0s (- 50m 46s) (15300 20%) 0.4461\n",
      "13m 5s (- 50m 40s) (15400 20%) 0.5957\n",
      "13m 10s (- 50m 36s) (15500 20%) 0.6664\n",
      "13m 15s (- 50m 30s) (15600 20%) 0.4973\n",
      "13m 20s (- 50m 25s) (15700 20%) 0.4946\n",
      "13m 26s (- 50m 20s) (15800 21%) 0.4559\n",
      "13m 31s (- 50m 15s) (15900 21%) 0.5760\n",
      "13m 36s (- 50m 9s) (16000 21%) 0.3754\n",
      "13m 41s (- 50m 4s) (16100 21%) 0.4975\n",
      "13m 46s (- 49m 59s) (16200 21%) 0.5644\n",
      "13m 51s (- 49m 54s) (16300 21%) 0.3137\n",
      "13m 56s (- 49m 49s) (16400 21%) 0.5326\n",
      "14m 1s (- 49m 43s) (16500 22%) 0.4196\n",
      "14m 6s (- 49m 39s) (16600 22%) 0.5912\n",
      "14m 11s (- 49m 33s) (16700 22%) 0.4937\n",
      "14m 16s (- 49m 28s) (16800 22%) 0.6138\n",
      "14m 21s (- 49m 22s) (16900 22%) 0.6414\n",
      "14m 27s (- 49m 18s) (17000 22%) 0.4391\n",
      "14m 32s (- 49m 13s) (17100 22%) 0.4267\n",
      "14m 37s (- 49m 7s) (17200 22%) 0.5950\n",
      "14m 42s (- 49m 3s) (17300 23%) 0.4158\n",
      "14m 47s (- 48m 57s) (17400 23%) 0.4864\n",
      "14m 52s (- 48m 51s) (17500 23%) 0.5320\n",
      "14m 57s (- 48m 46s) (17600 23%) 0.5405\n",
      "15m 2s (- 48m 42s) (17700 23%) 0.5179\n",
      "15m 7s (- 48m 36s) (17800 23%) 0.6270\n",
      "15m 12s (- 48m 31s) (17900 23%) 0.5122\n",
      "15m 17s (- 48m 25s) (18000 24%) 0.3802\n",
      "15m 22s (- 48m 21s) (18100 24%) 0.3281\n",
      "15m 27s (- 48m 15s) (18200 24%) 0.4268\n",
      "15m 32s (- 48m 10s) (18300 24%) 0.4223\n",
      "15m 37s (- 48m 4s) (18400 24%) 0.4492\n",
      "15m 43s (- 48m 0s) (18500 24%) 0.3256\n",
      "15m 48s (- 47m 54s) (18600 24%) 0.4240\n",
      "15m 53s (- 47m 49s) (18700 24%) 0.5169\n",
      "15m 58s (- 47m 44s) (18800 25%) 0.5858\n",
      "16m 3s (- 47m 39s) (18900 25%) 0.4643\n",
      "16m 8s (- 47m 34s) (19000 25%) 0.3522\n",
      "16m 13s (- 47m 28s) (19100 25%) 0.3550\n",
      "16m 18s (- 47m 24s) (19200 25%) 0.4622\n",
      "16m 23s (- 47m 18s) (19300 25%) 0.3207\n",
      "16m 28s (- 47m 13s) (19400 25%) 0.3770\n",
      "16m 33s (- 47m 7s) (19500 26%) 0.6805\n",
      "16m 38s (- 47m 3s) (19600 26%) 0.3116\n",
      "16m 43s (- 46m 58s) (19700 26%) 0.6307\n",
      "16m 48s (- 46m 52s) (19800 26%) 0.6807\n",
      "16m 53s (- 46m 47s) (19900 26%) 0.4644\n",
      "16m 59s (- 46m 43s) (20000 26%) 0.4917\n",
      "17m 4s (- 46m 38s) (20100 26%) 0.4039\n",
      "17m 9s (- 46m 34s) (20200 26%) 0.6441\n",
      "17m 15s (- 46m 29s) (20300 27%) 0.3903\n",
      "17m 20s (- 46m 25s) (20400 27%) 0.4876\n",
      "17m 25s (- 46m 19s) (20500 27%) 0.2986\n",
      "17m 30s (- 46m 14s) (20600 27%) 0.4710\n",
      "17m 35s (- 46m 8s) (20700 27%) 0.6573\n",
      "17m 40s (- 46m 4s) (20800 27%) 0.4183\n",
      "17m 45s (- 45m 58s) (20900 27%) 0.3412\n",
      "17m 50s (- 45m 52s) (21000 28%) 0.3286\n",
      "17m 56s (- 45m 48s) (21100 28%) 0.3162\n",
      "18m 1s (- 45m 44s) (21200 28%) 0.5348\n",
      "18m 6s (- 45m 38s) (21300 28%) 0.3165\n",
      "18m 11s (- 45m 33s) (21400 28%) 0.3408\n",
      "18m 17s (- 45m 29s) (21500 28%) 0.5429\n",
      "18m 22s (- 45m 24s) (21600 28%) 0.3692\n",
      "18m 27s (- 45m 19s) (21700 28%) 0.4350\n",
      "18m 32s (- 45m 14s) (21800 29%) 0.5270\n",
      "18m 37s (- 45m 9s) (21900 29%) 0.2846\n",
      "18m 42s (- 45m 4s) (22000 29%) 0.4106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18m 47s (- 44m 59s) (22100 29%) 0.4353\n",
      "18m 53s (- 44m 54s) (22200 29%) 0.3153\n",
      "18m 58s (- 44m 50s) (22300 29%) 0.3692\n",
      "19m 4s (- 44m 46s) (22400 29%) 0.3707\n",
      "19m 9s (- 44m 41s) (22500 30%) 0.3020\n",
      "19m 14s (- 44m 37s) (22600 30%) 0.4740\n",
      "19m 19s (- 44m 31s) (22700 30%) 0.3846\n",
      "19m 24s (- 44m 26s) (22800 30%) 0.6881\n",
      "19m 29s (- 44m 21s) (22900 30%) 0.4772\n",
      "19m 35s (- 44m 16s) (23000 30%) 0.4574\n",
      "19m 39s (- 44m 11s) (23100 30%) 0.5055\n",
      "19m 44s (- 44m 5s) (23200 30%) 0.4475\n",
      "19m 49s (- 44m 0s) (23300 31%) 0.4374\n",
      "19m 55s (- 43m 55s) (23400 31%) 0.4420\n",
      "20m 0s (- 43m 50s) (23500 31%) 0.5252\n",
      "20m 5s (- 43m 44s) (23600 31%) 0.4532\n",
      "20m 10s (- 43m 39s) (23700 31%) 0.3466\n",
      "20m 15s (- 43m 35s) (23800 31%) 0.6021\n",
      "20m 20s (- 43m 30s) (23900 31%) 0.5455\n",
      "20m 26s (- 43m 25s) (24000 32%) 0.4595\n",
      "20m 31s (- 43m 20s) (24100 32%) 0.3337\n",
      "20m 36s (- 43m 15s) (24200 32%) 0.4111\n",
      "20m 41s (- 43m 10s) (24300 32%) 0.4415\n",
      "20m 46s (- 43m 4s) (24400 32%) 0.3847\n",
      "20m 51s (- 43m 0s) (24500 32%) 0.4132\n",
      "20m 56s (- 42m 55s) (24600 32%) 0.6469\n",
      "21m 2s (- 42m 50s) (24700 32%) 0.4738\n",
      "21m 7s (- 42m 44s) (24800 33%) 0.5348\n",
      "21m 12s (- 42m 40s) (24900 33%) 0.3029\n",
      "21m 17s (- 42m 34s) (25000 33%) 0.5563\n",
      "21m 22s (- 42m 29s) (25100 33%) 0.4473\n",
      "21m 27s (- 42m 23s) (25200 33%) 0.5048\n",
      "21m 32s (- 42m 19s) (25300 33%) 0.3283\n",
      "21m 37s (- 42m 13s) (25400 33%) 0.3304\n",
      "21m 42s (- 42m 8s) (25500 34%) 0.3870\n",
      "21m 47s (- 42m 3s) (25600 34%) 0.4932\n",
      "21m 52s (- 41m 58s) (25700 34%) 0.2259\n",
      "21m 57s (- 41m 52s) (25800 34%) 0.4074\n",
      "22m 2s (- 41m 47s) (25900 34%) 0.4312\n",
      "22m 7s (- 41m 42s) (26000 34%) 0.3609\n",
      "22m 13s (- 41m 37s) (26100 34%) 0.6521\n",
      "22m 18s (- 41m 32s) (26200 34%) 0.5976\n",
      "22m 23s (- 41m 26s) (26300 35%) 0.3697\n",
      "22m 28s (- 41m 22s) (26400 35%) 0.3124\n",
      "22m 33s (- 41m 16s) (26500 35%) 0.3674\n",
      "22m 38s (- 41m 11s) (26600 35%) 0.3880\n",
      "22m 43s (- 41m 6s) (26700 35%) 0.3874\n",
      "22m 48s (- 41m 1s) (26800 35%) 0.4248\n",
      "22m 53s (- 40m 56s) (26900 35%) 0.5683\n",
      "22m 58s (- 40m 51s) (27000 36%) 0.4001\n",
      "23m 4s (- 40m 46s) (27100 36%) 0.5063\n",
      "23m 9s (- 40m 41s) (27200 36%) 0.2443\n",
      "23m 14s (- 40m 36s) (27300 36%) 0.5444\n",
      "23m 19s (- 40m 30s) (27400 36%) 0.3287\n",
      "23m 24s (- 40m 25s) (27500 36%) 0.4198\n",
      "23m 29s (- 40m 20s) (27600 36%) 0.3222\n",
      "23m 34s (- 40m 14s) (27700 36%) 0.3920\n",
      "23m 39s (- 40m 9s) (27800 37%) 0.2515\n",
      "23m 44s (- 40m 5s) (27900 37%) 0.5425\n",
      "23m 49s (- 39m 59s) (28000 37%) 0.6510\n",
      "23m 54s (- 39m 54s) (28100 37%) 0.3910\n",
      "23m 59s (- 39m 49s) (28200 37%) 0.1985\n",
      "24m 5s (- 39m 44s) (28300 37%) 0.3521\n",
      "24m 10s (- 39m 39s) (28400 37%) 0.5126\n",
      "24m 15s (- 39m 33s) (28500 38%) 0.2942\n",
      "24m 20s (- 39m 29s) (28600 38%) 0.5506\n",
      "24m 25s (- 39m 23s) (28700 38%) 0.5658\n",
      "24m 29s (- 39m 18s) (28800 38%) 0.2871\n",
      "24m 34s (- 39m 12s) (28900 38%) 0.3425\n",
      "24m 40s (- 39m 8s) (29000 38%) 0.2518\n",
      "24m 45s (- 39m 2s) (29100 38%) 0.3640\n",
      "24m 50s (- 38m 57s) (29200 38%) 0.6552\n",
      "24m 55s (- 38m 52s) (29300 39%) 0.6033\n",
      "25m 0s (- 38m 47s) (29400 39%) 0.5091\n",
      "25m 5s (- 38m 42s) (29500 39%) 0.4850\n",
      "25m 10s (- 38m 37s) (29600 39%) 0.6919\n",
      "25m 15s (- 38m 32s) (29700 39%) 0.4617\n",
      "25m 21s (- 38m 27s) (29800 39%) 0.8267\n",
      "25m 26s (- 38m 21s) (29900 39%) 0.4658\n",
      "25m 30s (- 38m 16s) (30000 40%) 0.3147\n",
      "25m 36s (- 38m 11s) (30100 40%) 0.5996\n",
      "25m 41s (- 38m 6s) (30200 40%) 0.2423\n",
      "25m 46s (- 38m 1s) (30300 40%) 0.4493\n",
      "25m 51s (- 37m 55s) (30400 40%) 0.4369\n",
      "25m 56s (- 37m 50s) (30500 40%) 0.3795\n",
      "26m 1s (- 37m 45s) (30600 40%) 0.3612\n",
      "26m 6s (- 37m 40s) (30700 40%) 0.3290\n",
      "26m 11s (- 37m 35s) (30800 41%) 0.4981\n",
      "26m 16s (- 37m 30s) (30900 41%) 0.4436\n",
      "26m 21s (- 37m 24s) (31000 41%) 0.4661\n",
      "26m 26s (- 37m 19s) (31100 41%) 0.4338\n",
      "26m 32s (- 37m 15s) (31200 41%) 0.2508\n",
      "26m 37s (- 37m 9s) (31300 41%) 0.2334\n",
      "26m 42s (- 37m 4s) (31400 41%) 0.5501\n",
      "26m 47s (- 36m 59s) (31500 42%) 0.3056\n",
      "26m 52s (- 36m 54s) (31600 42%) 0.4409\n",
      "26m 57s (- 36m 49s) (31700 42%) 0.4244\n",
      "27m 3s (- 36m 44s) (31800 42%) 0.4735\n",
      "27m 8s (- 36m 40s) (31900 42%) 0.3424\n",
      "27m 13s (- 36m 34s) (32000 42%) 0.5104\n",
      "27m 18s (- 36m 29s) (32100 42%) 0.2949\n",
      "27m 23s (- 36m 24s) (32200 42%) 0.4801\n",
      "27m 28s (- 36m 19s) (32300 43%) 0.4244\n",
      "27m 33s (- 36m 14s) (32400 43%) 0.5694\n",
      "27m 38s (- 36m 9s) (32500 43%) 0.5030\n",
      "27m 43s (- 36m 4s) (32600 43%) 0.2236\n",
      "27m 48s (- 35m 58s) (32700 43%) 0.3259\n",
      "27m 54s (- 35m 53s) (32800 43%) 0.4447\n",
      "27m 59s (- 35m 48s) (32900 43%) 0.6314\n",
      "28m 4s (- 35m 43s) (33000 44%) 0.3825\n",
      "28m 9s (- 35m 38s) (33100 44%) 0.3249\n",
      "28m 14s (- 35m 33s) (33200 44%) 0.2972\n",
      "28m 19s (- 35m 28s) (33300 44%) 0.4238\n",
      "28m 24s (- 35m 23s) (33400 44%) 0.3387\n",
      "28m 29s (- 35m 18s) (33500 44%) 0.4824\n",
      "28m 34s (- 35m 12s) (33600 44%) 0.4738\n",
      "28m 39s (- 35m 7s) (33700 44%) 0.3831\n",
      "28m 44s (- 35m 2s) (33800 45%) 0.3282\n",
      "28m 49s (- 34m 57s) (33900 45%) 0.4151\n",
      "28m 54s (- 34m 51s) (34000 45%) 0.2452\n",
      "28m 59s (- 34m 46s) (34100 45%) 0.3569\n",
      "29m 5s (- 34m 41s) (34200 45%) 0.4576\n",
      "29m 9s (- 34m 36s) (34300 45%) 0.2440\n",
      "29m 14s (- 34m 31s) (34400 45%) 0.5301\n",
      "29m 20s (- 34m 26s) (34500 46%) 0.2711\n",
      "29m 25s (- 34m 20s) (34600 46%) 0.4222\n",
      "29m 30s (- 34m 15s) (34700 46%) 0.1713\n",
      "29m 35s (- 34m 10s) (34800 46%) 0.4943\n",
      "29m 40s (- 34m 5s) (34900 46%) 0.4573\n",
      "29m 45s (- 34m 0s) (35000 46%) 0.4231\n",
      "29m 50s (- 33m 55s) (35100 46%) 0.4686\n",
      "29m 55s (- 33m 49s) (35200 46%) 0.1422\n",
      "30m 0s (- 33m 44s) (35300 47%) 0.3672\n",
      "30m 5s (- 33m 39s) (35400 47%) 0.5309\n",
      "30m 10s (- 33m 34s) (35500 47%) 0.5082\n",
      "30m 15s (- 33m 29s) (35600 47%) 0.3595\n",
      "30m 20s (- 33m 24s) (35700 47%) 0.3151\n",
      "30m 25s (- 33m 19s) (35800 47%) 0.3420\n",
      "30m 30s (- 33m 13s) (35900 47%) 0.4932\n",
      "30m 35s (- 33m 8s) (36000 48%) 0.3766\n",
      "30m 41s (- 33m 3s) (36100 48%) 0.2423\n",
      "30m 46s (- 32m 58s) (36200 48%) 0.4060\n",
      "30m 51s (- 32m 53s) (36300 48%) 0.4811\n",
      "30m 56s (- 32m 48s) (36400 48%) 0.3734\n",
      "31m 1s (- 32m 43s) (36500 48%) 0.5249\n",
      "31m 6s (- 32m 38s) (36600 48%) 0.2901\n",
      "31m 11s (- 32m 33s) (36700 48%) 0.4874\n",
      "31m 16s (- 32m 28s) (36800 49%) 0.3511\n",
      "31m 21s (- 32m 22s) (36900 49%) 0.4901\n",
      "31m 26s (- 32m 17s) (37000 49%) 0.3325\n",
      "31m 32s (- 32m 12s) (37100 49%) 0.2545\n",
      "31m 37s (- 32m 7s) (37200 49%) 0.4424\n",
      "31m 42s (- 32m 2s) (37300 49%) 0.4327\n",
      "31m 47s (- 31m 57s) (37400 49%) 0.5647\n",
      "31m 52s (- 31m 52s) (37500 50%) 0.4858\n",
      "31m 57s (- 31m 47s) (37600 50%) 0.4172\n",
      "32m 2s (- 31m 42s) (37700 50%) 0.4479\n",
      "32m 7s (- 31m 36s) (37800 50%) 0.3677\n",
      "32m 12s (- 31m 32s) (37900 50%) 0.2758\n",
      "32m 17s (- 31m 26s) (38000 50%) 0.4301\n",
      "32m 22s (- 31m 21s) (38100 50%) 0.3280\n",
      "32m 27s (- 31m 16s) (38200 50%) 0.2598\n",
      "32m 33s (- 31m 11s) (38300 51%) 0.5205\n",
      "32m 38s (- 31m 6s) (38400 51%) 0.3588\n",
      "32m 43s (- 31m 1s) (38500 51%) 0.3195\n",
      "32m 48s (- 30m 56s) (38600 51%) 0.4409\n",
      "32m 53s (- 30m 51s) (38700 51%) 0.4475\n",
      "32m 58s (- 30m 45s) (38800 51%) 0.3804\n",
      "33m 3s (- 30m 40s) (38900 51%) 0.3363\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words,\n",
    "                               1, dropout_p=0.1)\n",
    "\n",
    "if use_cuda:\n",
    "    print('Using CUDA')\n",
    "    encoder1 = encoder1.cuda()\n",
    "    attn_decoder1 = attn_decoder1.cuda()\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в Валуйском районе <norm> , </norm> Белгородская область ,\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 6: wrong matrix size at /pytorch/torch/lib/THC/generic/THCTensorMathBlas.cu:453",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-210-04336f534276>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind_to_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind_to_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-171-47e72a3d56f4>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(encoder, decoder, sentence, max_length)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         decoder_output, decoder_hidden, decoder_attention = decoder(\n\u001b[0;32m---> 24\u001b[0;31m             decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mdecoder_attentions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_attention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtopv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-198-fcbab6eb1ad0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, encoder_output, encoder_outputs)\u001b[0m\n\u001b[1;32m     71\u001b[0m             self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n\u001b[1;32m     72\u001b[0m         attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n\u001b[0;32m---> 73\u001b[0;31m                                  encoder_outputs.unsqueeze(0))\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_applied\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbmm\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    582\u001b[0m         output = Variable(self.data.new(self.data.size(0), self.data.size(1),\n\u001b[1;32m    583\u001b[0m                                         batch.data.size(2)))\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_static_blas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaddbmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m_static_blas\u001b[0;34m(cls, args, inplace)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_args\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_blas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/_functions/blas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, add_batch, batch1, batch2, alpha, beta, inplace)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         return torch.baddbmm(alpha, add_batch, beta,\n\u001b[0;32m--> 109\u001b[0;31m                              batch1, batch2, out=output)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 6: wrong matrix size at /pytorch/torch/lib/THC/generic/THCTensorMathBlas.cu:453"
     ]
    }
   ],
   "source": [
    "ind_to_test = 5\n",
    "\n",
    "print(input_list[ind_to_test])\n",
    "evaluate(encoder1, attn_decoder1, input_list[ind_to_test])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-212-4596e3519444>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_pairs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-212-4596e3519444>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_pairs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-211-47e72a3d56f4>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(encoder, decoder, sentence, max_length)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mei\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         encoder_output, encoder_hidden = encoder(input_variable[ei],\n\u001b[0;32m---> 11\u001b[0;31m                                                  encoder_hidden)\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-198-fcbab6eb1ad0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         )\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutogradRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36m_do_forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mflat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iter_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mflat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNestedIOFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0mnested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mnested_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mnested_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_variable_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward_extended\u001b[0;34m(self, input, weight, hx)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(fn, input, hx, weight, output, hy)\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0m_copyParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_weight_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_buf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_buf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36minit_weight_descriptor\u001b[0;34m(fn, weight)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minit_weight_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mw_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFilterDescriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mw_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# seems that filters require >=3 dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mw_desc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/backends/cudnn/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mcheck_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnnCreateFilterDescriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_parameter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mptr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_pairs = pairs[-1000:]\n",
    "\n",
    "preds = [evaluate(encoder1, attn_decoder1, item[0])[0] for item in test_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))  # SOS\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "        \n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в Валуйском районе <norm> , </norm> Белгородская область ,\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 6: wrong matrix size at /pytorch/torch/lib/THC/generic/THCTensorMathBlas.cu:453",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-208-04336f534276>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind_to_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind_to_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-171-47e72a3d56f4>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(encoder, decoder, sentence, max_length)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         decoder_output, decoder_hidden, decoder_attention = decoder(\n\u001b[0;32m---> 24\u001b[0;31m             decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mdecoder_attentions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_attention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtopv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-198-fcbab6eb1ad0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, encoder_output, encoder_outputs)\u001b[0m\n\u001b[1;32m     71\u001b[0m             self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n\u001b[1;32m     72\u001b[0m         attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n\u001b[0;32m---> 73\u001b[0;31m                                  encoder_outputs.unsqueeze(0))\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_applied\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbmm\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    582\u001b[0m         output = Variable(self.data.new(self.data.size(0), self.data.size(1),\n\u001b[1;32m    583\u001b[0m                                         batch.data.size(2)))\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_static_blas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaddbmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m_static_blas\u001b[0;34m(cls, args, inplace)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_args\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_blas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/_functions/blas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, add_batch, batch1, batch2, alpha, beta, inplace)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         return torch.baddbmm(alpha, add_batch, beta,\n\u001b[0;32m--> 109\u001b[0;31m                              batch1, batch2, out=output)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 6: wrong matrix size at /pytorch/torch/lib/THC/generic/THCTensorMathBlas.cu:453"
     ]
    }
   ],
   "source": [
    "ind_to_test = 5\n",
    "\n",
    "print(input_list[ind_to_test])\n",
    "evaluate(encoder1, attn_decoder1, input_list[ind_to_test])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' <norm> Ныне </norm> — в Валуйском'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
