{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 200\n",
    "teacher_forcing_ratio = 0.5\n",
    "model_name = 'first_big_run'\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_output, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "check_trans = lambda s: (len(s) == len(s.encode())) and ('.' not in s) and ('www' not in s) and ('http' not in s)\n",
    "        \n",
    "def filterPair(p):\n",
    "    return len(p[0]) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def getChars(item):\n",
    "    return [element for element in item]\n",
    "\n",
    "def get_data(file_range):\n",
    "    print('File range:', list(file_range))\n",
    "    data_list = []\n",
    "    for i in file_range:\n",
    "        index = str(i)\n",
    "        if len(index) == 1:\n",
    "            filename = 'output-0000{}-of-00100'.format(index)\n",
    "        elif len(index) == 2:\n",
    "            filename = 'output-000{}-of-00100'.format(index)\n",
    "        else:\n",
    "            raise ValueError('Wrong index')\n",
    "\n",
    "        cur_data = pd.read_csv('../input/ru_with_types/' + filename, sep='\\t', names=['class', 'before', 'after'],\n",
    "                           quoting=csv.QUOTE_NONE, encoding='utf-8', dtype=str, na_filter=False)\n",
    "        \n",
    "        is_trans = cur_data.before.astype(str).apply(lambda x: check_trans(x))\n",
    "        cur_data.loc[(is_trans) & (cur_data['class'] == 'PLAIN'), 'class'] = 'TRANS'\n",
    "\n",
    "        if (cur_data.shape[0] > 1074563-10) and (cur_data.shape[0] < 1074563+10):\n",
    "            print(filename)\n",
    "        data_list.append(cur_data)\n",
    "        print('Data shape for item {} is {}'.format(i,cur_data.shape))\n",
    "\n",
    "\n",
    "    data_orig = pd.concat(data_list, axis=0)\n",
    "    print('Overall data shape is {}'.format(data_orig.shape))\n",
    "\n",
    "    return data_orig\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)\n",
    "\n",
    "def make_sample(data_learn, self_frac = 0.33, sil_frac = 1):\n",
    "\n",
    "    data_nn = data_learn.copy()\n",
    "    to_concat = []\n",
    "    to_concat.append(data_nn[(data_nn.after != '<self>') & (data_nn.after != 'sil')])\n",
    "    to_concat.append(data_nn[data_nn.after == '<self>'].sample(frac = self_frac))\n",
    "    to_concat.append(data_nn[data_nn.after == 'sil'].sample(frac = sil_frac))\n",
    "\n",
    "    data_nn = pd.concat(to_concat, axis=0)\n",
    "    return data_nn\n",
    "\n",
    "def get_pairs(data_orig, filter_length = MAX_LENGTH, downsample_common = 500):\n",
    "\n",
    "    big_str = list(data_orig.before.astype(str).values)\n",
    "    output_list = list(data_orig.after.astype(str).values)\n",
    "    types_list = list(data_orig['class'].values)\n",
    "    \n",
    "    grp = data_orig.fillna('NaN').groupby(by='before')\n",
    "    group_sizes = grp.size().to_dict()\n",
    "\n",
    "    stride = 3\n",
    "    input_list = []\n",
    "    pairs = []\n",
    "    for i in range(len(big_str)):\n",
    "        if big_str[i] != '<eos>':\n",
    "            #print(big_str[i])\n",
    "            cur_item = ['<norm>'] + getChars(big_str[i]) + ['</norm>']\n",
    "            cur_type = types_list[i]\n",
    "            cur_item = ['<{}>'.format(cur_type)] + cur_item + ['</{}>'.format(cur_type)]\n",
    "            #print(big_str[i-stride:i])\n",
    "            prefix = getChars(' '.join(big_str[i-stride:i]))\n",
    "            #print(prefix)\n",
    "            prefix = ' '.join(prefix).split('< e o s >')[-1].split(' ')\n",
    "            #print(prefix)\n",
    "            suffix = getChars(' '.join(big_str[i+1:i+stride+1]))\n",
    "            suffix = ' '.join(suffix).split('< e o s >')[0].split(' ')\n",
    "            cur_item = prefix \\\n",
    "            + cur_item + \\\n",
    "            suffix\n",
    "\n",
    "            cur_item = ' '.join(cur_item)\n",
    "            cur_item = cur_item.replace('  ', ' ')\n",
    "            cur_item = cur_item.replace('  ', ' ')\n",
    "            if cur_item[0] == ' ':\n",
    "                cur_item = cur_item[1:]\n",
    "            if downsample_common:\n",
    "                #print(big_str[i])\n",
    "                leave_flag = np.random.random(1)[0] < downsample_common/group_sizes[big_str[i]]\n",
    "            else:\n",
    "                leave_flag = True\n",
    "            pairs += [(cur_item, output_list[i], cur_type, leave_flag)]\n",
    "            \n",
    "\n",
    "    #pairs = list(zip(input_list, output_list))\n",
    "    print('Len of pairs:', len(pairs))\n",
    "\n",
    "    if filter_length:\n",
    "        pairs = filterPairs(pairs)\n",
    "        print('Len of pairs after filtering:', len(pairs))\n",
    "    return pairs\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "          criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length\n",
    "\n",
    "def trainIters_weighted(encoder, decoder, pairs, test_pairs,\n",
    "               n_iters, print_every=1000, plot_every=100,\n",
    "               learning_rate=0.01, evaluate_each=False, min_class_size = 100, add_weighted = False):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    plot_accuracies = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    classes = ['PLAIN', 'PUNCT', 'VERBATIM', 'ORDINAL', 'MEASURE', 'DATE',\n",
    "           'ELECTRONIC', 'CARDINAL', 'LETTERS', 'DECIMAL', 'FRACTION',\n",
    "           'TELEPHONE', 'TIME', 'MONEY', 'DIGIT', 'TRANS', '<eos>']\n",
    "\n",
    "    initial_weights = [3.0 for i in range(len(classes) -1)] + [0.0]\n",
    "    initial_errors = [0.5 for i in range(len(classes) -1)] + [0.0]\n",
    "    weight_dict = dict(zip(classes, initial_weights))\n",
    "    weight_dict[\"PLAIN\"] = 1\n",
    "    weight_dict[\"PUNCT\"] = 2\n",
    "\n",
    "    error_dict = dict(zip(classes, initial_errors))\n",
    "    cur_iter = 1\n",
    "    epoch_lag = 20\n",
    "    for big_iter in range(1, int(np.ceil(n_iters/evaluate_each))):\n",
    "        \n",
    "        if add_weighted:\n",
    "            even_sample = make_even_sample(pairs, size_of_class = min_class_size)\n",
    "            weighted_sample = sample_pairs(pairs, size = evaluate_each - len(even_sample) + 1,\n",
    "                                           weight_dict = weight_dict)\n",
    "            sample = weighted_sample + even_sample\n",
    "        else:\n",
    "            num_classes = (len(classes) - 1) \n",
    "            class_size = int(evaluate_each/num_classes)\n",
    "            sample = make_even_sample(pairs, size_of_class = class_size)\n",
    "            if num_classes*class_size < evaluate_each:\n",
    "                weighted_sample = sample_pairs(pairs, size = evaluate_each - num_classes*class_size,\n",
    "                                           weight_dict = weight_dict)\n",
    "                sample += weighted_sample\n",
    "            \n",
    "        print(sample[0])\n",
    "        random.shuffle(sample)\n",
    "        print(sample[0])\n",
    "        print(len(sample))\n",
    "        training_pairs = [variablesFromPair(item)\n",
    "                      for item in sample]\n",
    "\n",
    "        for iter in range(1, evaluate_each + 1):\n",
    "            training_pair = training_pairs[iter - 1]\n",
    "            input_variable = training_pair[0]\n",
    "            target_variable = training_pair[1]\n",
    "\n",
    "            loss = train(input_variable, target_variable, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if cur_iter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, cur_iter / n_iters),\n",
    "                                             cur_iter, cur_iter / n_iters * 100, print_loss_avg))\n",
    "            cur_iter += 1\n",
    "\n",
    "            if iter % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "\n",
    "            if evaluate_each and iter % evaluate_each == 0 and iter != 0:\n",
    "\n",
    "                cur_accuracy, new_error_dict = evaluate_pairs(encoder, decoder, test_pairs)\n",
    "                for item in classes[:-1]:\n",
    "                    if new_error_dict[item] >= error_dict[item] and new_error_dict[item] > 0.05:\n",
    "                        weight_dict[item] += 1\n",
    "                    else:\n",
    "                        error_dict[item] = new_error_dict[item]\n",
    "                #error_dict = new_error_dict\n",
    "                #weight_dict['<eos>'] = 0.0\n",
    "                print(weight_dict)\n",
    "                plot_accuracies.append(cur_accuracy)\n",
    "            '''\n",
    "            if plot_losses and np.min(plot_losses) not in plot_losses[-epoch_lag:]:\n",
    "                learning_rate = learning_rate/np.sqrt(10)\n",
    "                epoch_lag += 5\n",
    "                print('Setting new learning rate to {:.5f}'.format(learning_rate))\n",
    "                encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "                decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "            '''\n",
    "\n",
    "    #showPlot(plot_losses)\n",
    "    #showPlot(plot_accuracies)\n",
    "\n",
    "    return plot_losses\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))  # SOS\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "def sample_pairs(train_pairs, size = 1000, weight_dict = None):\n",
    "\n",
    "    classes = ['PLAIN', 'PUNCT', 'VERBATIM', 'ORDINAL', 'MEASURE', 'DATE',\n",
    "           'ELECTRONIC', 'CARDINAL', 'LETTERS', 'DECIMAL', 'FRACTION',\n",
    "           'TELEPHONE', 'TIME', 'MONEY', 'DIGIT', 'TRANS', '<eos>']\n",
    "\n",
    "    if weight_dict is None:\n",
    "        weights = [1 for i in range(len(classes) -1)] + [0.0]\n",
    "        weight_dict = dict(zip(classes, weights))\n",
    "\n",
    "        weight_dict['PLAIN'] = 0.05\n",
    "        weight_dict['PUNCT'] = 0.15\n",
    "        weight_dict['DECIMAL'] = 5\n",
    "        weight_dict['FRACTION'] = 5\n",
    "        weight_dict['MONEY'] = 20\n",
    "        weight_dict['TIME'] = 10\n",
    "        weight_dict['ELECTRONIC'] = 10\n",
    "        weight_dict['ELECTRONIC'] = 10\n",
    "        weight_dict['DIGIT'] = 10\n",
    "\n",
    "\n",
    "    sample_weights = np.array([weight_dict[item[2]] for item in train_pairs])\n",
    "    sample_weights = sample_weights/ sample_weights.sum()\n",
    "\n",
    "    sample_indices = np.random.choice(range(len(train_pairs)), size = size, p=sample_weights)\n",
    "    sample = [train_pairs[i] for i in sample_indices]\n",
    "\n",
    "    return sample\n",
    "\n",
    "def make_even_sample(pairs, size_of_class = 100):\n",
    "\n",
    "    classes = ['PLAIN', 'PUNCT', 'VERBATIM', 'ORDINAL', 'MEASURE', 'DATE',\n",
    "           'ELECTRONIC', 'CARDINAL', 'LETTERS', 'DECIMAL', 'FRACTION',\n",
    "           'TELEPHONE', 'TIME', 'MONEY', 'DIGIT', 'TRANS']\n",
    "\n",
    "    sample = []\n",
    "    for item in classes:\n",
    "        class_pairs = [pair for pair in pairs if pair[2] == item]\n",
    "        sample_indices = np.random.choice(range(len(class_pairs)), size = size_of_class)\n",
    "        cur_sample = [class_pairs[i] for i in sample_indices]\n",
    "        sample += cur_sample\n",
    "\n",
    "    return sample\n",
    "\n",
    "def evaluate_pairs(encoder, decoder, test_pairs):\n",
    "\n",
    "    classes = ['PLAIN', 'PUNCT', 'VERBATIM', 'ORDINAL', 'MEASURE', 'DATE',\n",
    "           'ELECTRONIC', 'CARDINAL', 'LETTERS', 'DECIMAL', 'FRACTION',\n",
    "           'TELEPHONE', 'TIME', 'MONEY', 'DIGIT', 'TRANS']\n",
    "\n",
    "    results_dict = dict.fromkeys(classes)\n",
    "    preds = np.array([(item[1], ' '.join(evaluate(encoder, decoder, item[0])[0][:-1]), item[0]) for item in test_pairs])\n",
    "    results = np.array([item[0] == item[1] for item in preds])\n",
    "    print('\\t\\t eval accuracy: {:.3f}'.format(results.mean()))\n",
    "\n",
    "    for item in classes:\n",
    "        results_dict[item] = 1 - np.mean([results[i] for i in range(len(results)) if test_pairs[i][2] == item])\n",
    "        print('\\t\\t\\t {} eval error: {:.3f}'.format(item, results_dict[item]))\n",
    "\n",
    "    results_dict['<eos>'] = 0\n",
    "    return results.mean(), results_dict\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "#setting seeds\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File range: [0, 1]\n",
      "Data shape for item 0 is (2973646, 3)\n",
      "Data shape for item 1 is (2981069, 3)\n",
      "Overall data shape is (5954715, 3)\n",
      "File range: [5, 6, 7, 8, 9]\n",
      "Data shape for item 5 is (2975471, 3)\n",
      "Data shape for item 6 is (2980056, 3)\n",
      "Data shape for item 7 is (2975255, 3)\n",
      "Data shape for item 8 is (2974627, 3)\n",
      "Data shape for item 9 is (2967303, 3)\n",
      "Overall data shape is (14872712, 3)\n",
      "Len of pairs: 13854189\n",
      "Len of pairs after filtering: 13852302\n",
      "Len of pairs: 5547039\n",
      "Len of pairs after filtering: 5546221\n",
      "Filtering common words in train...\n",
      "Done. Updated length is 4925983\n",
      "[('<PLAIN> <norm> б е р е т </norm> </PLAIN> н а ч а л о о т с л о в а', '<self>', 'PLAIN', True), ('о т с л о в а \" <PLAIN> <norm> н е п е я </norm> </PLAIN> \" - ч е л о в е к а', '<self>', 'PLAIN', True), ('\" - ч е л о в е к а <PLAIN> <norm> в е д у щ е г о </norm> </PLAIN> т р е з в ы й о б р а з ж и з н и', '<self>', 'PLAIN', True), ('- ч е л о в е к а в е д у щ е г о <PLAIN> <norm> т р е з в ы й </norm> </PLAIN> о б р а з ж и з н и .', '<self>', 'PLAIN', True), ('<PLAIN> <norm> П о я в и л и с ь </norm> </PLAIN> в о в т о р о й ч е т в е р т и', '<self>', 'PLAIN', True)]\n",
      "[('<PLAIN> <norm> П о </norm> </PLAIN> с о с т о я н и ю н а 1 8 6 2 г о д', '<self>', 'PLAIN', True), ('<PLAIN> <norm> с о с т о я н и ю </norm> </PLAIN> н а 1 8 6 2 г о д .', '<self>', 'PLAIN', True), ('<PLAIN> <norm> н а </norm> </PLAIN> 1 8 6 2 г о д . ', '<self>', 'PLAIN', True), ('П о с о с т о я н и ю н а <DATE> <norm> 1 8 6 2 г о д </norm> </DATE> . ', 'тысяча восемьсот шестьдесят второй год', 'DATE', True), ('с о с т о я н и ю н а 1 8 6 2 г о д <PUNCT> <norm> . </norm> </PUNCT> ', 'sil', 'PUNCT', True)]\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "data_dev = get_data(range(0,2))\n",
    "data_learn = get_data(range(5,10))\n",
    "\n",
    "train_pairs = get_pairs(data_learn, downsample_common = 100)\n",
    "dev_pairs = get_pairs(data_dev, downsample_common = False)\n",
    "\n",
    "input_lang, output_lang = Lang('nonnorm'), Lang('norm')\n",
    "\n",
    "print('Filtering common words in train...')\n",
    "train_pairs = [item for item in train_pairs if item[3]]\n",
    "print('Done. Updated length is {}'.format(len(train_pairs)))\n",
    "\n",
    "for pair in train_pairs + dev_pairs:\n",
    "    input_lang.addSentence(pair[0])\n",
    "    output_lang.addSentence(pair[1])\n",
    "\n",
    "print(train_pairs[:5])\n",
    "print(dev_pairs[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3486"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3486"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1577753\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = data_dev.groupby(by = 'before').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst.index.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PLAIN': 0.59443861172446211, 'PUNCT': 0.20528603606481741, '<eos>': 0.068444596296936486, 'TRANS': 0.047757870304669756, 'CARDINAL': 0.024709733438344712, 'LETTERS': 0.018014585461753014, 'DATE': 0.016650939620923271, 'VERBATIM': 0.013962993577581191, 'ORDINAL': 0.0040072019332496201, 'MEASURE': 0.0038010576914669736, 'TELEPHONE': 0.000939587294519926, 'DECIMAL': 0.00064937117599068615, 'ELECTRONIC': 0.00053806001117819675, 'MONEY': 0.00022396747965292439, 'FRACTION': 0.00020984340435949674, 'DIGIT': 0.00019571932906606906, 'TIME': 0.00016982519102811834}\n",
      "Using CUDA\n",
      "('S h i n i n g <TRANS> <norm> F o r c e </norm> </TRANS> C D — п р я м о е', 'ф_trans о_trans р_trans с_trans', 'TRANS')\n",
      "('H o l d i n g s P L C з а <MONEY> <norm> 6 1 м и л л и о н д о л л а р о в </norm> </MONEY> ( 3 7 , 5 м л н ф у н т о в', 'шестьдесят один миллион долларов', 'MONEY')\n",
      "10001\n",
      "1m 48s (- 3609m 50s) (1000 0%) 3.1963\n",
      "3m 32s (- 3539m 48s) (2000 0%) 2.6289\n",
      "5m 18s (- 3530m 12s) (3000 0%) 2.5199\n",
      "7m 1s (- 3504m 22s) (4000 0%) 2.4552\n",
      "8m 47s (- 3505m 47s) (5000 0%) 2.4832\n",
      "10m 30s (- 3490m 46s) (6000 0%) 2.3404\n",
      "12m 16s (- 3494m 38s) (7000 0%) 2.4408\n",
      "14m 3s (- 3498m 57s) (8000 0%) 2.3434\n",
      "15m 47s (- 3492m 52s) (9000 0%) 2.3427\n",
      "17m 32s (- 3489m 32s) (10000 0%) 2.2899\n",
      "\t\t eval accuracy: 0.094\n",
      "\t\t\t PLAIN eval error: 0.030\n",
      "\t\t\t PUNCT eval error: 0.530\n",
      "\t\t\t VERBATIM eval error: 0.930\n",
      "\t\t\t ORDINAL eval error: 1.000\n",
      "\t\t\t MEASURE eval error: 1.000\n",
      "\t\t\t DATE eval error: 1.000\n",
      "\t\t\t ELECTRONIC eval error: 1.000\n",
      "\t\t\t CARDINAL eval error: 1.000\n",
      "\t\t\t LETTERS eval error: 1.000\n",
      "\t\t\t DECIMAL eval error: 1.000\n",
      "\t\t\t FRACTION eval error: 1.000\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 1.000\n",
      "\t\t\t MONEY eval error: 1.000\n",
      "\t\t\t DIGIT eval error: 1.000\n",
      "\t\t\t TRANS eval error: 1.000\n",
      "{'PLAIN': 1, 'PUNCT': 3, 'VERBATIM': 4.0, 'ORDINAL': 4.0, 'MEASURE': 4.0, 'DATE': 4.0, 'ELECTRONIC': 4.0, 'CARDINAL': 4.0, 'LETTERS': 4.0, 'DECIMAL': 4.0, 'FRACTION': 4.0, 'TELEPHONE': 4.0, 'TIME': 4.0, 'MONEY': 4.0, 'DIGIT': 4.0, 'TRANS': 4.0, '<eos>': 0.0}\n",
      "('П р и т о к р е к и М и с с у р и <PUNCT> <norm> . </norm> </PUNCT> ', 'sil', 'PUNCT')\n",
      "('К л и р е п а р х и и в к л ю ч а е т <CARDINAL> <norm> 1 0 6 </norm> </CARDINAL> с в я щ е н н и к о в ( 8 6', 'сто шесть', 'CARDINAL')\n",
      "10001\n",
      "20m 26s (- 3694m 56s) (11000 0%) 2.2546\n",
      "22m 8s (- 3668m 44s) (12000 0%) 2.2217\n",
      "23m 53s (- 3651m 11s) (13000 0%) 2.2534\n",
      "25m 38s (- 3638m 23s) (14000 0%) 2.2803\n",
      "27m 23s (- 3624m 58s) (15000 0%) 1.9975\n",
      "29m 9s (- 3616m 19s) (16000 0%) 2.0685\n",
      "30m 54s (- 3605m 32s) (17000 0%) 1.8834\n",
      "32m 41s (- 3599m 26s) (18000 0%) 1.9161\n",
      "34m 27s (- 3592m 51s) (19000 0%) 1.8166\n",
      "36m 13s (- 3585m 52s) (20000 0%) 1.7761\n",
      "\t\t eval accuracy: 0.188\n",
      "\t\t\t PLAIN eval error: 0.000\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.060\n",
      "\t\t\t ORDINAL eval error: 1.000\n",
      "\t\t\t MEASURE eval error: 1.000\n",
      "\t\t\t DATE eval error: 1.000\n",
      "\t\t\t ELECTRONIC eval error: 1.000\n",
      "\t\t\t CARDINAL eval error: 1.000\n",
      "\t\t\t LETTERS eval error: 1.000\n",
      "\t\t\t DECIMAL eval error: 0.990\n",
      "\t\t\t FRACTION eval error: 1.000\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 1.000\n",
      "\t\t\t MONEY eval error: 1.000\n",
      "\t\t\t DIGIT eval error: 0.940\n",
      "\t\t\t TRANS eval error: 1.000\n",
      "{'PLAIN': 1, 'PUNCT': 3, 'VERBATIM': 4.0, 'ORDINAL': 5.0, 'MEASURE': 5.0, 'DATE': 5.0, 'ELECTRONIC': 5.0, 'CARDINAL': 5.0, 'LETTERS': 5.0, 'DECIMAL': 5.0, 'FRACTION': 5.0, 'TELEPHONE': 5.0, 'TIME': 5.0, 'MONEY': 5.0, 'DIGIT': 5.0, 'TRANS': 5.0, '<eos>': 0.0}\n",
      "('Б о р и с П о к р о в с к и й — <PLAIN> <norm> С е н е к а </norm> </PLAIN> 1 9 9 8 — «', '<self>', 'PLAIN')\n",
      "('г о д а т р е н и р о в а л Б а й е р <DIGIT> <norm> 0 5 </norm> </DIGIT> Ю р д и н г е н ( п е р в ы й', 'ноль пять', 'DIGIT')\n",
      "10001\n",
      "39m 13s (- 3696m 45s) (21000 1%) 1.8393\n",
      "41m 0s (- 3687m 45s) (22000 1%) 1.8133\n",
      "42m 48s (- 3679m 19s) (23000 1%) 1.7732\n",
      "44m 35s (- 3671m 26s) (24000 1%) 1.7679\n",
      "46m 20s (- 3661m 19s) (25000 1%) 1.6867\n",
      "48m 6s (- 3652m 23s) (26000 1%) 1.6558\n",
      "49m 54s (- 3647m 9s) (27000 1%) 1.7556\n",
      "51m 40s (- 3639m 38s) (28000 1%) 1.6708\n",
      "53m 27s (- 3633m 40s) (29000 1%) 1.5839\n",
      "55m 14s (- 3627m 20s) (30000 1%) 1.6642\n",
      "\t\t eval accuracy: 0.195\n",
      "\t\t\t PLAIN eval error: 0.000\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.060\n",
      "\t\t\t ORDINAL eval error: 0.980\n",
      "\t\t\t MEASURE eval error: 1.000\n",
      "\t\t\t DATE eval error: 1.000\n",
      "\t\t\t ELECTRONIC eval error: 1.000\n",
      "\t\t\t CARDINAL eval error: 0.950\n",
      "\t\t\t LETTERS eval error: 1.000\n",
      "\t\t\t DECIMAL eval error: 1.000\n",
      "\t\t\t FRACTION eval error: 1.000\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.950\n",
      "\t\t\t MONEY eval error: 1.000\n",
      "\t\t\t DIGIT eval error: 0.960\n",
      "\t\t\t TRANS eval error: 0.980\n",
      "{'PLAIN': 2, 'PUNCT': 4, 'VERBATIM': 5.0, 'ORDINAL': 6.0, 'MEASURE': 6.0, 'DATE': 6.0, 'ELECTRONIC': 6.0, 'CARDINAL': 6.0, 'LETTERS': 6.0, 'DECIMAL': 6.0, 'FRACTION': 6.0, 'TELEPHONE': 6.0, 'TIME': 6.0, 'MONEY': 6.0, 'DIGIT': 6.0, 'TRANS': 6.0, '<eos>': 0.0}\n",
      "('1 8 7 7 - 1 9 5 2 ) , <PLAIN> <norm> к а к </norm> </PLAIN> и Б о г д а н ,', '<self>', 'PLAIN')\n",
      "('1 : D e <TRANS> <norm> l a </norm> </TRANS> C o n f e d e r a t i o n a l a', 'л_trans а_trans', 'TRANS')\n",
      "10001\n",
      "58m 12s (- 3696m 41s) (31000 1%) 1.4869\n",
      "59m 59s (- 3689m 4s) (32000 1%) 1.5111\n",
      "61m 45s (- 3681m 13s) (33000 1%) 1.4967\n",
      "63m 30s (- 3672m 40s) (34000 1%) 1.5376\n",
      "65m 17s (- 3665m 40s) (35000 1%) 1.4700\n",
      "67m 3s (- 3658m 26s) (36000 1%) 1.4610\n",
      "68m 50s (- 3652m 37s) (37000 1%) 1.3661\n",
      "70m 39s (- 3648m 30s) (38000 1%) 1.4576\n",
      "72m 25s (- 3641m 55s) (39000 1%) 1.3614\n",
      "74m 11s (- 3635m 9s) (40000 1%) 1.3925\n",
      "\t\t eval accuracy: 0.241\n",
      "\t\t\t PLAIN eval error: 0.000\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.060\n",
      "\t\t\t ORDINAL eval error: 0.970\n",
      "\t\t\t MEASURE eval error: 0.990\n",
      "\t\t\t DATE eval error: 0.980\n",
      "\t\t\t ELECTRONIC eval error: 0.970\n",
      "\t\t\t CARDINAL eval error: 0.900\n",
      "\t\t\t LETTERS eval error: 0.900\n",
      "\t\t\t DECIMAL eval error: 0.980\n",
      "\t\t\t FRACTION eval error: 0.970\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.950\n",
      "\t\t\t MONEY eval error: 1.000\n",
      "\t\t\t DIGIT eval error: 0.480\n",
      "\t\t\t TRANS eval error: 0.990\n",
      "{'PLAIN': 3, 'PUNCT': 5, 'VERBATIM': 6.0, 'ORDINAL': 7.0, 'MEASURE': 7.0, 'DATE': 7.0, 'ELECTRONIC': 7.0, 'CARDINAL': 7.0, 'LETTERS': 7.0, 'DECIMAL': 7.0, 'FRACTION': 7.0, 'TELEPHONE': 7.0, 'TIME': 7.0, 'MONEY': 7.0, 'DIGIT': 6.0, 'TRANS': 7.0, '<eos>': 0.0}\n",
      "('М ы ш о н о к <PLAIN> <norm> п о д б е г а е т </norm> </PLAIN> к м о р д е к о т а', '<self>', 'PLAIN')\n",
      "('п л о т н о с т ь н а с е л е н и я — <DECIMAL> <norm> 4 7 , 5 3 </norm> </DECIMAL> ч е л . /', 'сорок семь целых и пятьдесят три сотых', 'DECIMAL')\n",
      "10001\n",
      "77m 10s (- 3687m 25s) (41000 2%) 1.3701\n",
      "79m 1s (- 3684m 16s) (42000 2%) 1.2133\n",
      "80m 50s (- 3679m 12s) (43000 2%) 1.2236\n",
      "82m 37s (- 3673m 1s) (44000 2%) 1.2835\n",
      "84m 25s (- 3667m 30s) (45000 2%) 1.2328\n",
      "86m 14s (- 3663m 18s) (46000 2%) 1.2434\n",
      "88m 1s (- 3657m 50s) (47000 2%) 1.1632\n",
      "89m 51s (- 3653m 56s) (48000 2%) 1.2005\n",
      "91m 40s (- 3649m 57s) (49000 2%) 1.0773\n",
      "93m 29s (- 3646m 28s) (50000 2%) 1.1589\n",
      "\t\t eval accuracy: 0.282\n",
      "\t\t\t PLAIN eval error: 0.020\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.050\n",
      "\t\t\t ORDINAL eval error: 0.970\n",
      "\t\t\t MEASURE eval error: 0.970\n",
      "\t\t\t DATE eval error: 0.940\n",
      "\t\t\t ELECTRONIC eval error: 0.950\n",
      "\t\t\t CARDINAL eval error: 0.850\n",
      "\t\t\t LETTERS eval error: 0.820\n",
      "\t\t\t DECIMAL eval error: 0.950\n",
      "\t\t\t FRACTION eval error: 0.990\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.840\n",
      "\t\t\t MONEY eval error: 1.000\n",
      "\t\t\t DIGIT eval error: 0.190\n",
      "\t\t\t TRANS eval error: 0.940\n",
      "{'PLAIN': 4, 'PUNCT': 6, 'VERBATIM': 6.0, 'ORDINAL': 8.0, 'MEASURE': 8.0, 'DATE': 8.0, 'ELECTRONIC': 8.0, 'CARDINAL': 8.0, 'LETTERS': 8.0, 'DECIMAL': 8.0, 'FRACTION': 8.0, 'TELEPHONE': 8.0, 'TIME': 8.0, 'MONEY': 8.0, 'DIGIT': 6.0, 'TRANS': 8.0, '<eos>': 0.0}\n",
      "('Н е к о т о р ы е ф р о н т о в и к и о т п р а в л я ю т с я <PLAIN> <norm> д о м о й </norm> </PLAIN> , в и х', '<self>', 'PLAIN')\n",
      "(') с о о б щ е н и й м е ж д у <PLAIN> <norm> н а с е л е н н ы м и </norm> </PLAIN> п у н к т а м и с е л ь с к и х о к р у г о в', '<self>', 'PLAIN')\n",
      "10001\n",
      "96m 33s (- 3689m 44s) (51000 2%) 1.1404\n",
      "98m 20s (- 3683m 47s) (52000 2%) 1.0709\n",
      "100m 9s (- 3679m 27s) (53000 2%) 1.0762\n",
      "101m 56s (- 3673m 48s) (54000 2%) 1.0478\n",
      "103m 44s (- 3668m 43s) (55000 2%) 1.0718\n",
      "105m 33s (- 3664m 28s) (56000 2%) 1.0664\n",
      "107m 20s (- 3659m 12s) (57000 2%) 1.0397\n",
      "109m 8s (- 3654m 26s) (58000 2%) 0.9863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110m 56s (- 3649m 40s) (59000 2%) 0.9291\n",
      "112m 45s (- 3646m 3s) (60000 2%) 1.0100\n",
      "\t\t eval accuracy: 0.328\n",
      "\t\t\t PLAIN eval error: 0.000\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.050\n",
      "\t\t\t ORDINAL eval error: 0.880\n",
      "\t\t\t MEASURE eval error: 0.850\n",
      "\t\t\t DATE eval error: 0.900\n",
      "\t\t\t ELECTRONIC eval error: 0.940\n",
      "\t\t\t CARDINAL eval error: 0.680\n",
      "\t\t\t LETTERS eval error: 0.790\n",
      "\t\t\t DECIMAL eval error: 0.940\n",
      "\t\t\t FRACTION eval error: 0.870\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.720\n",
      "\t\t\t MONEY eval error: 0.990\n",
      "\t\t\t DIGIT eval error: 0.240\n",
      "\t\t\t TRANS eval error: 0.910\n",
      "{'PLAIN': 5, 'PUNCT': 7, 'VERBATIM': 7.0, 'ORDINAL': 9.0, 'MEASURE': 9.0, 'DATE': 9.0, 'ELECTRONIC': 9.0, 'CARDINAL': 9.0, 'LETTERS': 9.0, 'DECIMAL': 9.0, 'FRACTION': 9.0, 'TELEPHONE': 9.0, 'TIME': 9.0, 'MONEY': 9.0, 'DIGIT': 7.0, 'TRANS': 9.0, '<eos>': 0.0}\n",
      "('в ы с о к о н а п о р н ы х к о т л о в э т и <PLAIN> <norm> к о т л ы </norm> </PLAIN> о т л и ч а л и с ь в ы с о к о й н а д е ж н о с т ь ю', '<self>', 'PLAIN')\n",
      "('— 1 9 7 с . — <CARDINAL> <norm> 8 0 0 0 </norm> </CARDINAL> э к з . ', 'восемь тысяч', 'CARDINAL')\n",
      "10001\n",
      "115m 47s (- 3680m 49s) (61000 3%) 1.0199\n",
      "117m 33s (- 3674m 53s) (62000 3%) 0.9310\n",
      "119m 22s (- 3670m 29s) (63000 3%) 0.9340\n",
      "121m 10s (- 3665m 36s) (64000 3%) 0.9066\n",
      "122m 58s (- 3660m 48s) (65000 3%) 1.0051\n",
      "124m 46s (- 3656m 6s) (66000 3%) 0.9052\n",
      "126m 34s (- 3651m 44s) (67000 3%) 0.9265\n",
      "128m 21s (- 3646m 55s) (68000 3%) 0.9105\n",
      "130m 10s (- 3643m 11s) (69000 3%) 0.9225\n",
      "131m 59s (- 3639m 3s) (70000 3%) 0.9183\n",
      "\t\t eval accuracy: 0.362\n",
      "\t\t\t PLAIN eval error: 0.000\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.050\n",
      "\t\t\t ORDINAL eval error: 0.790\n",
      "\t\t\t MEASURE eval error: 0.870\n",
      "\t\t\t DATE eval error: 0.830\n",
      "\t\t\t ELECTRONIC eval error: 0.940\n",
      "\t\t\t CARDINAL eval error: 0.600\n",
      "\t\t\t LETTERS eval error: 0.720\n",
      "\t\t\t DECIMAL eval error: 0.800\n",
      "\t\t\t FRACTION eval error: 0.820\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.710\n",
      "\t\t\t MONEY eval error: 0.980\n",
      "\t\t\t DIGIT eval error: 0.190\n",
      "\t\t\t TRANS eval error: 0.900\n",
      "{'PLAIN': 6, 'PUNCT': 8, 'VERBATIM': 8.0, 'ORDINAL': 10.0, 'MEASURE': 10.0, 'DATE': 10.0, 'ELECTRONIC': 10.0, 'CARDINAL': 10.0, 'LETTERS': 10.0, 'DECIMAL': 10.0, 'FRACTION': 10.0, 'TELEPHONE': 10.0, 'TIME': 10.0, 'MONEY': 10.0, 'DIGIT': 8.0, 'TRANS': 10.0, '<eos>': 0.0}\n",
      "('л е в ы й п р и т о к В е п ш и <PUNCT> <norm> , </norm> </PUNCT> о д н а и з в а ж н е й ш и х', 'sil', 'PUNCT')\n",
      "('к о т о р а я в и н о в н а в <PLAIN> <norm> г и б е л и </norm> </PLAIN> е е с е с т р ы .', '<self>', 'PLAIN')\n",
      "10001\n",
      "135m 4s (- 3670m 0s) (71000 3%) 0.8784\n",
      "136m 54s (- 3665m 57s) (72000 3%) 0.8384\n",
      "138m 42s (- 3661m 29s) (73000 3%) 0.8886\n",
      "140m 31s (- 3657m 21s) (74000 3%) 0.9475\n",
      "142m 18s (- 3652m 28s) (75000 3%) 0.9331\n",
      "144m 5s (- 3647m 44s) (76000 3%) 0.8078\n",
      "145m 52s (- 3642m 57s) (77000 3%) 0.8010\n",
      "147m 41s (- 3639m 13s) (78000 3%) 0.7852\n",
      "149m 28s (- 3634m 35s) (79000 3%) 0.8130\n",
      "151m 16s (- 3630m 43s) (80000 3%) 0.7716\n",
      "\t\t eval accuracy: 0.386\n",
      "\t\t\t PLAIN eval error: 0.000\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.050\n",
      "\t\t\t ORDINAL eval error: 0.820\n",
      "\t\t\t MEASURE eval error: 0.810\n",
      "\t\t\t DATE eval error: 0.800\n",
      "\t\t\t ELECTRONIC eval error: 0.920\n",
      "\t\t\t CARDINAL eval error: 0.610\n",
      "\t\t\t LETTERS eval error: 0.630\n",
      "\t\t\t DECIMAL eval error: 0.760\n",
      "\t\t\t FRACTION eval error: 0.800\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.650\n",
      "\t\t\t MONEY eval error: 0.940\n",
      "\t\t\t DIGIT eval error: 0.110\n",
      "\t\t\t TRANS eval error: 0.930\n",
      "{'PLAIN': 7, 'PUNCT': 9, 'VERBATIM': 9.0, 'ORDINAL': 11.0, 'MEASURE': 11.0, 'DATE': 11.0, 'ELECTRONIC': 11.0, 'CARDINAL': 11.0, 'LETTERS': 11.0, 'DECIMAL': 11.0, 'FRACTION': 11.0, 'TELEPHONE': 11.0, 'TIME': 11.0, 'MONEY': 11.0, 'DIGIT': 8.0, 'TRANS': 11.0, '<eos>': 0.0}\n",
      "('ч е м п и о н о в и п о к и н у л <PLAIN> <norm> П о р т у г а л и ю </norm> </PLAIN> . ', '<self>', 'PLAIN')\n",
      "('з а щ и щ а в ш и х о т н а п а д е н и я <PLAIN> <norm> п р о т и в н и к а </norm> </PLAIN> м о с т и в х о д', '<self>', 'PLAIN')\n",
      "10001\n",
      "154m 22s (- 3657m 30s) (81000 4%) 0.7740\n",
      "156m 12s (- 3653m 37s) (82000 4%) 0.7975\n",
      "158m 1s (- 3649m 43s) (83000 4%) 0.8230\n",
      "159m 49s (- 3645m 38s) (84000 4%) 0.7907\n",
      "161m 38s (- 3641m 31s) (85000 4%) 0.7564\n",
      "163m 27s (- 3637m 46s) (86000 4%) 0.7613\n",
      "165m 16s (- 3633m 59s) (87000 4%) 0.7418\n",
      "167m 3s (- 3629m 44s) (88000 4%) 0.7752\n",
      "168m 52s (- 3626m 7s) (89000 4%) 0.6982\n",
      "170m 42s (- 3622m 51s) (90000 4%) 0.8212\n",
      "\t\t eval accuracy: 0.421\n",
      "\t\t\t PLAIN eval error: 0.000\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.060\n",
      "\t\t\t ORDINAL eval error: 0.740\n",
      "\t\t\t MEASURE eval error: 0.720\n",
      "\t\t\t DATE eval error: 0.770\n",
      "\t\t\t ELECTRONIC eval error: 0.910\n",
      "\t\t\t CARDINAL eval error: 0.580\n",
      "\t\t\t LETTERS eval error: 0.620\n",
      "\t\t\t DECIMAL eval error: 0.640\n",
      "\t\t\t FRACTION eval error: 0.760\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.590\n",
      "\t\t\t MONEY eval error: 0.930\n",
      "\t\t\t DIGIT eval error: 0.110\n",
      "\t\t\t TRANS eval error: 0.840\n",
      "{'PLAIN': 8, 'PUNCT': 10, 'VERBATIM': 10.0, 'ORDINAL': 12.0, 'MEASURE': 12.0, 'DATE': 12.0, 'ELECTRONIC': 12.0, 'CARDINAL': 12.0, 'LETTERS': 12.0, 'DECIMAL': 12.0, 'FRACTION': 12.0, 'TELEPHONE': 12.0, 'TIME': 12.0, 'MONEY': 12.0, 'DIGIT': 9.0, 'TRANS': 12.0, '<eos>': 0.0}\n",
      "('с а н и т а р ы - н о с и л ь щ и к и <PUNCT> <norm> . </norm> </PUNCT> ', 'sil', 'PUNCT')\n",
      "('М е д и а , 2 0 0 9 <PUNCT> <norm> . </norm> </PUNCT> — I S B N 9 7 8 5 9 7 0 4 0 9 5 3 4', 'sil', 'PUNCT')\n",
      "10001\n",
      "173m 48s (- 3646m 13s) (91000 4%) 0.7688\n",
      "175m 37s (- 3642m 26s) (92000 4%) 0.7056\n",
      "177m 26s (- 3638m 26s) (93000 4%) 0.6958\n",
      "179m 14s (- 3634m 23s) (94000 4%) 0.7396\n",
      "181m 2s (- 3630m 29s) (95000 4%) 0.7305\n",
      "182m 51s (- 3626m 35s) (96000 4%) 0.7059\n",
      "184m 41s (- 3623m 14s) (97000 4%) 0.7754\n",
      "186m 29s (- 3619m 23s) (98000 4%) 0.7320\n",
      "188m 19s (- 3616m 13s) (99000 4%) 0.6612\n",
      "190m 8s (- 3612m 46s) (100000 4%) 0.6643\n",
      "\t\t eval accuracy: 0.424\n",
      "\t\t\t PLAIN eval error: 0.000\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.050\n",
      "\t\t\t ORDINAL eval error: 0.740\n",
      "\t\t\t MEASURE eval error: 0.750\n",
      "\t\t\t DATE eval error: 0.780\n",
      "\t\t\t ELECTRONIC eval error: 0.900\n",
      "\t\t\t CARDINAL eval error: 0.580\n",
      "\t\t\t LETTERS eval error: 0.550\n",
      "\t\t\t DECIMAL eval error: 0.730\n",
      "\t\t\t FRACTION eval error: 0.760\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.540\n",
      "\t\t\t MONEY eval error: 0.890\n",
      "\t\t\t DIGIT eval error: 0.120\n",
      "\t\t\t TRANS eval error: 0.820\n",
      "{'PLAIN': 9, 'PUNCT': 11, 'VERBATIM': 11.0, 'ORDINAL': 13.0, 'MEASURE': 13.0, 'DATE': 13.0, 'ELECTRONIC': 13.0, 'CARDINAL': 13.0, 'LETTERS': 13.0, 'DECIMAL': 13.0, 'FRACTION': 13.0, 'TELEPHONE': 13.0, 'TIME': 13.0, 'MONEY': 13.0, 'DIGIT': 10.0, 'TRANS': 13.0, '<eos>': 0.0}\n",
      "('у Э л ь - <PLAIN> <norm> К а н к а </norm> </PLAIN> 4 0 0 м а м е л ю к о в и', '<self>', 'PLAIN')\n",
      "(': [ И з <PLAIN> <norm> б и о г р а ф и и </norm> </PLAIN> п р е д с е д а т е л я К а р Ц И К а Н . В .', '<self>', 'PLAIN')\n",
      "10001\n",
      "193m 13s (- 3632m 54s) (101000 5%) 0.7246\n",
      "195m 3s (- 3629m 31s) (102000 5%) 0.6750\n",
      "196m 51s (- 3625m 32s) (103000 5%) 0.6824\n",
      "198m 42s (- 3622m 29s) (104000 5%) 0.6963\n",
      "200m 30s (- 3618m 46s) (105000 5%) 0.6988\n",
      "202m 20s (- 3615m 21s) (106000 5%) 0.6539\n",
      "204m 10s (- 3612m 4s) (107000 5%) 0.7260\n",
      "205m 58s (- 3608m 28s) (108000 5%) 0.6859\n",
      "207m 48s (- 3605m 3s) (109000 5%) 0.6624\n",
      "209m 38s (- 3602m 7s) (110000 5%) 0.6227\n",
      "\t\t eval accuracy: 0.449\n",
      "\t\t\t PLAIN eval error: 0.000\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.050\n",
      "\t\t\t ORDINAL eval error: 0.640\n",
      "\t\t\t MEASURE eval error: 0.750\n",
      "\t\t\t DATE eval error: 0.740\n",
      "\t\t\t ELECTRONIC eval error: 0.930\n",
      "\t\t\t CARDINAL eval error: 0.500\n",
      "\t\t\t LETTERS eval error: 0.470\n",
      "\t\t\t DECIMAL eval error: 0.710\n",
      "\t\t\t FRACTION eval error: 0.730\n",
      "\t\t\t TELEPHONE eval error: 0.990\n",
      "\t\t\t TIME eval error: 0.490\n",
      "\t\t\t MONEY eval error: 0.880\n",
      "\t\t\t DIGIT eval error: 0.130\n",
      "\t\t\t TRANS eval error: 0.800\n",
      "{'PLAIN': 10, 'PUNCT': 12, 'VERBATIM': 12.0, 'ORDINAL': 14.0, 'MEASURE': 14.0, 'DATE': 14.0, 'ELECTRONIC': 14.0, 'CARDINAL': 14.0, 'LETTERS': 13.0, 'DECIMAL': 14.0, 'FRACTION': 14.0, 'TELEPHONE': 14.0, 'TIME': 13.0, 'MONEY': 14.0, 'DIGIT': 11.0, 'TRANS': 14.0, '<eos>': 0.0}\n",
      "('ю р и д и ч е с к о г о з а о ч н о г о и н с т и т у т а <PUNCT> <norm> . </norm> </PUNCT> ', 'sil', 'PUNCT')\n",
      "('д о х о д с е м ь и — <MONEY> <norm> 4 7 5 0 0 д о л л а р о в </norm> </MONEY> . ', 'сорок семь тысяч пятьсот долларов', 'MONEY')\n",
      "10001\n",
      "212m 43s (- 3620m 14s) (111000 5%) 0.6688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214m 34s (- 3617m 4s) (112000 5%) 0.6803\n",
      "216m 23s (- 3613m 29s) (113000 5%) 0.6351\n",
      "218m 11s (- 3609m 44s) (114000 5%) 0.6633\n",
      "219m 58s (- 3605m 48s) (115000 5%) 0.6022\n",
      "221m 47s (- 3602m 12s) (116000 5%) 0.6103\n",
      "223m 35s (- 3598m 36s) (117000 5%) 0.6508\n",
      "225m 25s (- 3595m 17s) (118000 5%) 0.5579\n",
      "227m 15s (- 3592m 14s) (119000 5%) 0.6082\n",
      "229m 3s (- 3588m 38s) (120000 5%) 0.6022\n",
      "\t\t eval accuracy: 0.469\n",
      "\t\t\t PLAIN eval error: 0.000\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.070\n",
      "\t\t\t ORDINAL eval error: 0.610\n",
      "\t\t\t MEASURE eval error: 0.720\n",
      "\t\t\t DATE eval error: 0.590\n",
      "\t\t\t ELECTRONIC eval error: 0.900\n",
      "\t\t\t CARDINAL eval error: 0.490\n",
      "\t\t\t LETTERS eval error: 0.490\n",
      "\t\t\t DECIMAL eval error: 0.690\n",
      "\t\t\t FRACTION eval error: 0.680\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.450\n",
      "\t\t\t MONEY eval error: 0.800\n",
      "\t\t\t DIGIT eval error: 0.130\n",
      "\t\t\t TRANS eval error: 0.870\n",
      "{'PLAIN': 11, 'PUNCT': 13, 'VERBATIM': 13.0, 'ORDINAL': 15.0, 'MEASURE': 15.0, 'DATE': 15.0, 'ELECTRONIC': 15.0, 'CARDINAL': 14.0, 'LETTERS': 14.0, 'DECIMAL': 15.0, 'FRACTION': 15.0, 'TELEPHONE': 15.0, 'TIME': 13.0, 'MONEY': 15.0, 'DIGIT': 12.0, 'TRANS': 15.0, '<eos>': 0.0}\n",
      "('И х п о с л е д н я я <PLAIN> <norm> в с т р е ч а </norm> </PLAIN> с о с т о я л а с ь в м а е', '<self>', 'PLAIN')\n",
      "('я з ы к е д о 1 9 2 7 г о д а <PUNCT> <norm> , </norm> </PUNCT> п о с л е ч е г о б ы л', 'sil', 'PUNCT')\n",
      "10001\n",
      "232m 9s (- 3605m 3s) (121000 6%) 0.6556\n",
      "233m 59s (- 3601m 52s) (122000 6%) 0.6079\n",
      "235m 48s (- 3598m 32s) (123000 6%) 0.6223\n",
      "237m 39s (- 3595m 30s) (124000 6%) 0.5887\n",
      "239m 30s (- 3592m 32s) (125000 6%) 0.6523\n",
      "241m 20s (- 3589m 21s) (126000 6%) 0.5856\n",
      "243m 9s (- 3586m 5s) (127000 6%) 0.6286\n",
      "244m 59s (- 3582m 55s) (128000 6%) 0.5795\n",
      "246m 48s (- 3579m 39s) (129000 6%) 0.6023\n",
      "248m 35s (- 3575m 54s) (130000 6%) 0.5351\n",
      "\t\t eval accuracy: 0.481\n",
      "\t\t\t PLAIN eval error: 0.000\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.080\n",
      "\t\t\t ORDINAL eval error: 0.580\n",
      "\t\t\t MEASURE eval error: 0.680\n",
      "\t\t\t DATE eval error: 0.680\n",
      "\t\t\t ELECTRONIC eval error: 0.860\n",
      "\t\t\t CARDINAL eval error: 0.470\n",
      "\t\t\t LETTERS eval error: 0.420\n",
      "\t\t\t DECIMAL eval error: 0.690\n",
      "\t\t\t FRACTION eval error: 0.630\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.360\n",
      "\t\t\t MONEY eval error: 0.880\n",
      "\t\t\t DIGIT eval error: 0.210\n",
      "\t\t\t TRANS eval error: 0.760\n",
      "{'PLAIN': 12, 'PUNCT': 14, 'VERBATIM': 14.0, 'ORDINAL': 16.0, 'MEASURE': 16.0, 'DATE': 16.0, 'ELECTRONIC': 16.0, 'CARDINAL': 14.0, 'LETTERS': 14.0, 'DECIMAL': 16.0, 'FRACTION': 16.0, 'TELEPHONE': 16.0, 'TIME': 13.0, 'MONEY': 16.0, 'DIGIT': 13.0, 'TRANS': 16.0, '<eos>': 0.0}\n",
      "(', ч е р е з с р е д н е в о л н о в о й <PLAIN> <norm> п е р е д а т ч и к </norm> </PLAIN> л и т о в с к о й R a d i o B a l t i c', '<self>', 'PLAIN')\n",
      "('/ / О н л а й н <VERBATIM> <norm> - </norm> </VERBATIM> э н ц и к л о п е д и я « К р у г о с в е т', 'sil', 'VERBATIM')\n",
      "10001\n",
      "251m 39s (- 3590m 27s) (131000 6%) 0.5773\n",
      "253m 28s (- 3587m 3s) (132000 6%) 0.5673\n",
      "255m 15s (- 3583m 8s) (133000 6%) 0.5768\n",
      "257m 3s (- 3579m 38s) (134000 6%) 0.5164\n",
      "258m 53s (- 3576m 33s) (135000 6%) 0.5622\n",
      "260m 41s (- 3572m 54s) (136000 6%) 0.5821\n",
      "262m 31s (- 3570m 3s) (137000 6%) 0.5061\n",
      "264m 20s (- 3566m 36s) (138000 6%) 0.5336\n",
      "266m 9s (- 3563m 28s) (139000 6%) 0.5755\n",
      "268m 0s (- 3560m 39s) (140000 6%) 0.5645\n",
      "\t\t eval accuracy: 0.509\n",
      "\t\t\t PLAIN eval error: 0.000\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.030\n",
      "\t\t\t ORDINAL eval error: 0.540\n",
      "\t\t\t MEASURE eval error: 0.660\n",
      "\t\t\t DATE eval error: 0.550\n",
      "\t\t\t ELECTRONIC eval error: 0.850\n",
      "\t\t\t CARDINAL eval error: 0.390\n",
      "\t\t\t LETTERS eval error: 0.430\n",
      "\t\t\t DECIMAL eval error: 0.700\n",
      "\t\t\t FRACTION eval error: 0.600\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.310\n",
      "\t\t\t MONEY eval error: 0.890\n",
      "\t\t\t DIGIT eval error: 0.100\n",
      "\t\t\t TRANS eval error: 0.810\n",
      "{'PLAIN': 13, 'PUNCT': 15, 'VERBATIM': 14.0, 'ORDINAL': 17.0, 'MEASURE': 17.0, 'DATE': 17.0, 'ELECTRONIC': 17.0, 'CARDINAL': 14.0, 'LETTERS': 15.0, 'DECIMAL': 17.0, 'FRACTION': 17.0, 'TELEPHONE': 17.0, 'TIME': 13.0, 'MONEY': 17.0, 'DIGIT': 13.0, 'TRANS': 17.0, '<eos>': 0.0}\n",
      "('и з г н а н и к у д о л ж н о с т ь е п и с к о п а <PLAIN> <norm> В о р ч е с т е р а </norm> </PLAIN> , з а т е м Л о н д о н а', '<self>', 'PLAIN')\n",
      "('С у м м а с д е л к и с о с т а в и т <MONEY> <norm> $ 2 3 м л р д </norm> </MONEY> , г о д о в ы е п р о д а ж и', 'двадцать три миллиарда долларов сэ ш а', 'MONEY')\n",
      "10001\n",
      "271m 5s (- 3574m 7s) (141000 7%) 0.5650\n",
      "272m 54s (- 3570m 56s) (142000 7%) 0.5980\n",
      "274m 43s (- 3567m 34s) (143000 7%) 0.6007\n",
      "276m 32s (- 3564m 19s) (144000 7%) 0.5207\n",
      "278m 22s (- 3561m 15s) (145000 7%) 0.5288\n",
      "280m 12s (- 3558m 12s) (146000 7%) 0.6132\n",
      "282m 2s (- 3555m 10s) (147000 7%) 0.5689\n",
      "283m 50s (- 3551m 53s) (148000 7%) 0.5705\n",
      "285m 41s (- 3549m 0s) (149000 7%) 0.5785\n",
      "287m 29s (- 3545m 42s) (150000 7%) 0.5452\n",
      "\t\t eval accuracy: 0.489\n",
      "\t\t\t PLAIN eval error: 0.000\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.050\n",
      "\t\t\t ORDINAL eval error: 0.520\n",
      "\t\t\t MEASURE eval error: 0.670\n",
      "\t\t\t DATE eval error: 0.510\n",
      "\t\t\t ELECTRONIC eval error: 0.870\n",
      "\t\t\t CARDINAL eval error: 0.550\n",
      "\t\t\t LETTERS eval error: 0.490\n",
      "\t\t\t DECIMAL eval error: 0.680\n",
      "\t\t\t FRACTION eval error: 0.670\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.410\n",
      "\t\t\t MONEY eval error: 0.880\n",
      "\t\t\t DIGIT eval error: 0.100\n",
      "\t\t\t TRANS eval error: 0.780\n",
      "{'PLAIN': 14, 'PUNCT': 16, 'VERBATIM': 15.0, 'ORDINAL': 18.0, 'MEASURE': 18.0, 'DATE': 18.0, 'ELECTRONIC': 18.0, 'CARDINAL': 15.0, 'LETTERS': 16.0, 'DECIMAL': 18.0, 'FRACTION': 18.0, 'TELEPHONE': 18.0, 'TIME': 14.0, 'MONEY': 18.0, 'DIGIT': 14.0, 'TRANS': 18.0, '<eos>': 0.0}\n",
      "('с п и с о к с е л е н и й п о <PLAIN> <norm> у е з д а м </norm> </PLAIN> и с т а н а м С .', '<self>', 'PLAIN')\n",
      "('а л ь - М а р р а к у ш и <PLAIN> <norm> у п о м и н а е т </norm> </PLAIN> э т у б и т в у в', '<self>', 'PLAIN')\n",
      "10001\n",
      "290m 34s (- 3558m 9s) (151000 7%) 0.4335\n",
      "292m 25s (- 3555m 12s) (152000 7%) 0.5729\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cd278f1d5d22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m plot_losses = trainIters_weighted(encoder1, attn_decoder1, train_pairs, test_pairs, 2000001, print_every=callback_num,\n\u001b[1;32m     19\u001b[0m                          \u001b[0mplot_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_each\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                         min_class_size = 400, add_weighted = True)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'models/encoder_{}.states'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f4494b2f6017>\u001b[0m in \u001b[0;36mtrainIters_weighted\u001b[0;34m(encoder, decoder, pairs, test_pairs, n_iters, print_every, plot_every, learning_rate, evaluate_each, min_class_size, add_weighted)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             loss = train(input_variable, target_variable, encoder,\n\u001b[0;32m--> 363\u001b[0;31m                          decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m    364\u001b[0m             \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f4494b2f6017>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.enabled = False\n",
    "test_pairs = make_even_sample(dev_pairs, size_of_class = 100)\n",
    "\n",
    "test_weight = dict((data_dev['class'].value_counts()/len(data_dev)))\n",
    "print(test_weight)\n",
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size, n_layers=4)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words,\n",
    "                           n_layers = 2, dropout_p=0.2)\n",
    "\n",
    "if use_cuda:\n",
    "    print('Using CUDA')\n",
    "    encoder1 = encoder1.cuda()\n",
    "    attn_decoder1 = attn_decoder1.cuda()\n",
    "\n",
    "callback_num = 1000\n",
    "\n",
    "plot_losses = trainIters_weighted(encoder1, attn_decoder1, train_pairs, test_pairs, 2000001, print_every=callback_num,\n",
    "                         plot_every=callback_num, evaluate_each=10000, learning_rate = 0.01, \n",
    "                        min_class_size = 400, add_weighted = True)\n",
    "\n",
    "torch.save(encoder1.state_dict() , 'models/encoder_{}.states'.format(model_name))\n",
    "torch.save(attn_decoder1.state_dict(), 'models/decoder_{}.states'.format(model_name))\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
