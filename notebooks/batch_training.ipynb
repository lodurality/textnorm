{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence#, masked_cross_entropy\n",
    "from torch.nn import functional\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "PAD_token = 2\n",
    "MAX_LENGTH = 200\n",
    "teacher_forcing_ratio = 0.5\n",
    "model_name = 'first_big_run'\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"<PAD>\"}\n",
    "        self.n_words = 3  # Count SOS and EOS and PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "                \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1            \n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0]) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def getChars(item):\n",
    "    return [element for element in item]\n",
    "\n",
    "def get_data(file_range):\n",
    "    print('File range:', list(file_range))\n",
    "    data_list = []\n",
    "    for i in file_range:\n",
    "        index = str(i)\n",
    "        if len(index) == 1:\n",
    "            filename = 'output-0000{}-of-00100'.format(index)\n",
    "        elif len(index) == 2:\n",
    "            filename = 'output-000{}-of-00100'.format(index)\n",
    "        else:\n",
    "            raise ValueError('Wrong index')\n",
    "\n",
    "        cur_data = pd.read_csv('../input/ru_with_types/' + filename, sep='\\t', names=['class', 'before', 'after'],\n",
    "                           quoting=csv.QUOTE_NONE, encoding='utf-8', dtype=str)\n",
    "\n",
    "        if (cur_data.shape[0] > 1074563-10) and (cur_data.shape[0] < 1074563+10):\n",
    "            print(filename)\n",
    "        data_list.append(cur_data)\n",
    "        print('Data shape for item {} is {}'.format(i,cur_data.shape))\n",
    "\n",
    "\n",
    "    data_orig = pd.concat(data_list, axis=0)\n",
    "    print('Overall data shape is {}'.format(data_orig.shape))\n",
    "    \n",
    "    return data_orig\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)\n",
    "\n",
    "def make_sample(data_learn, self_frac = 0.33, sil_frac = 1):\n",
    "\n",
    "    data_nn = data_learn.copy()\n",
    "    to_concat = []\n",
    "    to_concat.append(data_nn[(data_nn.after != '<self>') & (data_nn.after != 'sil')])\n",
    "    to_concat.append(data_nn[data_nn.after == '<self>'].sample(frac = self_frac))\n",
    "    to_concat.append(data_nn[data_nn.after == 'sil'].sample(frac = sil_frac))\n",
    "\n",
    "    data_nn = pd.concat(to_concat, axis=0)\n",
    "    return data_nn\n",
    "\n",
    "def get_pairs(data_orig, filter_length = MAX_LENGTH):\n",
    "\n",
    "    big_str = list(data_orig.before.astype(str).values)\n",
    "    output_list = list(data_orig.after.astype(str).values)\n",
    "    types_list = list(data_orig['class'].values)\n",
    "    \n",
    "    stride = 3\n",
    "    input_list = []\n",
    "    pairs = []\n",
    "    for i in range(len(big_str)):\n",
    "        if big_str[i] != '<eos>':\n",
    "            #print(big_str[i])\n",
    "            cur_item = ['<norm>'] + getChars(big_str[i]) + ['</norm>']\n",
    "            cur_type = types_list[i]\n",
    "            cur_item = ['<{}>'.format(cur_type)] + cur_item + ['</{}>'.format(cur_type)]\n",
    "            #print(big_str[i-stride:i])\n",
    "            prefix = getChars(' '.join(big_str[i-stride:i]))\n",
    "            #print(prefix)\n",
    "            prefix = ' '.join(prefix).split('< e o s >')[-1].split(' ')\n",
    "            #print(prefix)\n",
    "            suffix = getChars(' '.join(big_str[i+1:i+stride+1]))\n",
    "            suffix = ' '.join(suffix).split('< e o s >')[0].split(' ')\n",
    "            cur_item = prefix \\\n",
    "            + cur_item + \\\n",
    "            suffix\n",
    "\n",
    "            cur_item = ' '.join(cur_item)\n",
    "            cur_item = cur_item.replace('  ', ' ')\n",
    "            cur_item = cur_item.replace('  ', ' ')\n",
    "            if cur_item[0] == ' ':\n",
    "                cur_item = cur_item[1:]\n",
    "            pairs += [(cur_item, output_list[i], cur_type)]\n",
    "\n",
    "    #pairs = list(zip(input_list, output_list))\n",
    "    print('Len of pairs:', len(pairs))\n",
    "    \n",
    "    if filter_length:\n",
    "        pairs = filterPairs(pairs)\n",
    "        print('Len of pairs after filtering:', len(pairs))\n",
    "    return pairs\n",
    "\n",
    "def trainIters_weighted(encoder, decoder, pairs, test_pairs, \n",
    "               n_iters, print_every=1000, plot_every=100, \n",
    "               learning_rate=0.01, evaluate_each=False):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    plot_accuracies = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    classes = ['PLAIN', 'PUNCT', 'VERBATIM', 'ORDINAL', 'MEASURE', 'DATE',\n",
    "           'ELECTRONIC', 'CARDINAL', 'LETTERS', 'DECIMAL', 'FRACTION',\n",
    "           'TELEPHONE', 'TIME', 'MONEY', 'DIGIT', '<eos>']\n",
    "    \n",
    "    initial_weights = [3.0 for i in range(len(classes) -1)] + [0.0]\n",
    "    initial_errors = [0.5 for i in range(len(classes) -1)] + [0.0]\n",
    "    weight_dict = dict(zip(classes, initial_weights))\n",
    "    weight_dict[\"PLAIN\"] = 1\n",
    "    weight_dict[\"PUNCT\"] = 2\n",
    "    \n",
    "    error_dict = dict(zip(classes, initial_errors))\n",
    "    cur_iter = 1\n",
    "    epoch_lag = 20\n",
    "    for big_iter in range(1, int(np.ceil(n_iters/evaluate_each))):\n",
    "        even_sample = make_even_sample(pairs, size_of_class = 50)\n",
    "        weighted_sample = sample_pairs(pairs, size = evaluate_each - len(even_sample) + 1,\n",
    "                                       weight_dict = weight_dict)\n",
    "        weighted_sample += even_sample\n",
    "        print(weighted_sample[0])\n",
    "        random.shuffle(weighted_sample)\n",
    "        print(weighted_sample[0])\n",
    "        print(len(weighted_sample))\n",
    "        training_pairs = [variablesFromPair(item)\n",
    "                      for item in weighted_sample]\n",
    "        \n",
    "        for iter in range(1, evaluate_each + 1):\n",
    "            training_pair = training_pairs[iter - 1]\n",
    "            input_variable = training_pair[0]\n",
    "            target_variable = training_pair[1]\n",
    "\n",
    "            loss = train(input_variable, target_variable, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if cur_iter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, cur_iter / n_iters),\n",
    "                                             cur_iter, cur_iter / n_iters * 100, print_loss_avg))\n",
    "            cur_iter += 1\n",
    "\n",
    "            if iter % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "\n",
    "            if evaluate_each and iter % evaluate_each == 0 and iter != 0:\n",
    "\n",
    "                cur_accuracy, new_error_dict = evaluate_pairs(encoder, decoder, test_pairs)\n",
    "                for item in classes[:-1]:\n",
    "                    if new_error_dict[item] >= error_dict[item]:\n",
    "                        weight_dict[item] += 1\n",
    "                    else:\n",
    "                        error_dict[item] = new_error_dict[item]\n",
    "                #error_dict = new_error_dict\n",
    "                #weight_dict['<eos>'] = 0.0\n",
    "                print(weight_dict)\n",
    "                plot_accuracies.append(cur_accuracy)\n",
    "            '''    \n",
    "            if plot_losses and np.min(plot_losses) not in plot_losses[-epoch_lag:]:\n",
    "                learning_rate = learning_rate/np.sqrt(10)\n",
    "                epoch_lag += 5\n",
    "                print('Setting new learning rate to {:.5f}'.format(learning_rate))\n",
    "                encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "                decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "            ''' \n",
    "\n",
    "    #showPlot(plot_losses)\n",
    "    #showPlot(plot_accuracies)\n",
    "    \n",
    "    return plot_losses\n",
    "\n",
    "def sample_pairs(train_pairs, size = 1000, weight_dict = None):\n",
    "\n",
    "    classes = ['PLAIN', 'PUNCT', 'VERBATIM', 'ORDINAL', 'MEASURE', 'DATE',\n",
    "           'ELECTRONIC', 'CARDINAL', 'LETTERS', 'DECIMAL', 'FRACTION',\n",
    "           'TELEPHONE', 'TIME', 'MONEY', 'DIGIT', '<eos>']\n",
    "    \n",
    "    if weight_dict is None:\n",
    "        weights = [1 for i in range(len(classes) -1)] + [0.0]\n",
    "        weight_dict = dict(zip(classes, weights))\n",
    "        \n",
    "        weight_dict['PLAIN'] = 0.05\n",
    "        weight_dict['PUNCT'] = 0.15\n",
    "        weight_dict['DECIMAL'] = 5\n",
    "        weight_dict['FRACTION'] = 5\n",
    "        weight_dict['MONEY'] = 20\n",
    "        weight_dict['TIME'] = 10\n",
    "        weight_dict['ELECTRONIC'] = 10\n",
    "        weight_dict['ELECTRONIC'] = 10\n",
    "        weight_dict['DIGIT'] = 10\n",
    "        \n",
    "        \n",
    "    sample_weights = np.array([weight_dict[item[2]] for item in train_pairs])\n",
    "    sample_weights = sample_weights/ sample_weights.sum()\n",
    "    \n",
    "    sample_indices = np.random.choice(range(len(train_pairs)), size = size, p=sample_weights)\n",
    "    sample = [train_pairs[i] for i in sample_indices]\n",
    "    \n",
    "    return sample\n",
    "\n",
    "def make_even_sample(pairs, size_of_class = 100):\n",
    "\n",
    "    classes = ['PLAIN', 'PUNCT', 'VERBATIM', 'ORDINAL', 'MEASURE', 'DATE',\n",
    "           'ELECTRONIC', 'CARDINAL', 'LETTERS', 'DECIMAL', 'FRACTION',\n",
    "           'TELEPHONE', 'TIME', 'MONEY', 'DIGIT']\n",
    "    \n",
    "    sample = []\n",
    "    for item in classes:\n",
    "        class_pairs = [pair for pair in pairs if pair[2] == item]\n",
    "        sample_indices = np.random.choice(range(len(class_pairs)), size = size_of_class)\n",
    "        cur_sample = [class_pairs[i] for i in sample_indices]\n",
    "        sample += cur_sample\n",
    "        \n",
    "    return sample\n",
    "\n",
    "def evaluate_pairs(encoder, decoder, test_pairs):\n",
    "    \n",
    "    classes = ['PLAIN', 'PUNCT', 'VERBATIM', 'ORDINAL', 'MEASURE', 'DATE',\n",
    "           'ELECTRONIC', 'CARDINAL', 'LETTERS', 'DECIMAL', 'FRACTION',\n",
    "           'TELEPHONE', 'TIME', 'MONEY', 'DIGIT']\n",
    "    \n",
    "    results_dict = dict.fromkeys(classes)\n",
    "    preds = np.array([(item[1], ' '.join(evaluate(encoder, decoder, item[0])[0][:-1]), item[0]) for item in test_pairs])\n",
    "    results = np.array([item[0] == item[1] for item in preds])\n",
    "    print('\\t\\t eval accuracy: {:.3f}'.format(results.mean()))\n",
    "\n",
    "    for item in classes:\n",
    "        results_dict[item] = 1 - np.mean([results[i] for i in range(len(results)) if test_pairs[i][2] == item])\n",
    "        print('\\t\\t\\t {} eval error: {:.3f}'.format(item, results_dict[item]))\n",
    "    \n",
    "    results_dict['<eos>'] = 0\n",
    "    return results.mean(), results_dict\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "#setting seeds\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sequence_mask(sequence_length, max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = sequence_length.data.max()\n",
    "    batch_size = sequence_length.size(0)\n",
    "    seq_range = torch.range(0, max_len - 1).long()\n",
    "    seq_range_expand = seq_range.unsqueeze(0).expand(batch_size, max_len)\n",
    "    seq_range_expand = Variable(seq_range_expand)\n",
    "    if sequence_length.is_cuda:\n",
    "        seq_range_expand = seq_range_expand.cuda()\n",
    "    seq_length_expand = (sequence_length.unsqueeze(1)\n",
    "                         .expand_as(seq_range_expand))\n",
    "    return seq_range_expand < seq_length_expand\n",
    "\n",
    "\n",
    "def masked_cross_entropy(logits, target, length):\n",
    "    length = Variable(torch.LongTensor(length)).cuda()\n",
    "\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        logits: A Variable containing a FloatTensor of size\n",
    "            (batch, max_len, num_classes) which contains the\n",
    "            unnormalized probability for each class.\n",
    "        target: A Variable containing a LongTensor of size\n",
    "            (batch, max_len) which contains the index of the true\n",
    "            class for each corresponding step.\n",
    "        length: A Variable containing a LongTensor of size (batch,)\n",
    "            which contains the length of each data in a batch.\n",
    "    Returns:\n",
    "        loss: An average loss value masked by the length.\n",
    "    \"\"\"\n",
    "\n",
    "    # logits_flat: (batch * max_len, num_classes)\n",
    "    logits_flat = logits.view(-1, logits.size(-1))\n",
    "    # log_probs_flat: (batch * max_len, num_classes)\n",
    "    log_probs_flat = functional.log_softmax(logits_flat)\n",
    "    # target_flat: (batch * max_len, 1)\n",
    "    target_flat = target.view(-1, 1)\n",
    "    # losses_flat: (batch * max_len, 1)\n",
    "    losses_flat = -torch.gather(log_probs_flat, dim=1, index=target_flat)\n",
    "    # losses: (batch, max_len)\n",
    "    losses = losses_flat.view(*target.size())\n",
    "    # mask: (batch, max_len)\n",
    "    mask = sequence_mask(sequence_length=length, max_len=target.size(1))\n",
    "    losses = losses * mask.float()\n",
    "    loss = losses.sum() / length.float().sum()\n",
    "    return loss\n",
    "\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=self.dropout, bidirectional=True)\n",
    "        \n",
    "    def forward(self, input_seqs, input_lengths, hidden=None):\n",
    "        # Note: we run this all at once (over multiple batches of multiple sequences)\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) # unpack (back to padded)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs\n",
    "        return outputs, hidden\n",
    "    \n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        max_len = encoder_outputs.size(0)\n",
    "        this_batch_size = encoder_outputs.size(1)\n",
    "\n",
    "        # Create variable to store attention energies\n",
    "        attn_energies = Variable(torch.zeros(this_batch_size, max_len)) # B x S\n",
    "\n",
    "        if USE_CUDA:\n",
    "            attn_energies = attn_energies.cuda()\n",
    "\n",
    "        # For each batch of encoder outputs\n",
    "        for b in range(this_batch_size):\n",
    "            # Calculate energy for each encoder output\n",
    "            for i in range(max_len):\n",
    "                attn_energies[b, i] = self.score(hidden[:, b], encoder_outputs[i, b].unsqueeze(0))\n",
    "\n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x B x S\n",
    "        return F.softmax(attn_energies).unsqueeze(1)\n",
    "    \n",
    "    def score(self, hidden, encoder_output):\n",
    "        \n",
    "        if self.method == 'dot':\n",
    "            energy = hidden.view(-1).dot(encoder_output.view(-1))\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'general':\n",
    "            energy = self.attn(encoder_output).view(-1)\n",
    "            energy = hidden.view(-1).dot(energy)\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'concat':\n",
    "            energy = self.attn(torch.cat((hidden, encoder_output), 1)).view(-1)\n",
    "            energy = self.v.view(-1).dot(energy)\n",
    "            return energy\n",
    "        \n",
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # Choose attention model\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_seq, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time\n",
    "\n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        batch_size = input_seq.size(0)\n",
    "        embedded = self.embedding(input_seq)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        embedded = embedded.view(1, batch_size, self.hidden_size) # S=1 x B x N\n",
    "\n",
    "        # Get current hidden state from input word and last hidden state\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "\n",
    "        # Calculate attention from current RNN state and all encoder outputs;\n",
    "        # apply to encoder outputs to get weighted average\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x S=1 x N\n",
    "\n",
    "        # Attentional vector using the RNN hidden state and context vector\n",
    "        # concatenated together (Luong eq. 5)\n",
    "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
    "        context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = F.tanh(self.concat(concat_input))\n",
    "\n",
    "        # Finally predict next token (Luong eq. 6, without softmax)\n",
    "        output = self.out(concat_output)\n",
    "\n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_seq(seq, max_length):\n",
    "    seq += [PAD_token for i in range(max_length - len(seq))]\n",
    "    return seq\n",
    "\n",
    "def random_batch(pairs, batch_size):\n",
    "    input_seqs = []\n",
    "    target_seqs = []\n",
    "\n",
    "    # Choose random pairs\n",
    "    for i in range(batch_size):\n",
    "        pair = random.choice(pairs)\n",
    "        input_seqs.append(indexesFromSentence(input_lang, pair[0]))\n",
    "        target_seqs.append(indexesFromSentence(output_lang, pair[1]))\n",
    "\n",
    "    # Zip into pairs, sort by length (descending), unzip\n",
    "    seq_pairs = sorted(zip(input_seqs, target_seqs), key=lambda p: len(p[0]), reverse=True)\n",
    "    input_seqs, target_seqs = zip(*seq_pairs)\n",
    "    \n",
    "    # For input and target sequences, get array of lengths and pad with 0s to max length\n",
    "    input_lengths = [len(s) for s in input_seqs]\n",
    "    input_padded = [pad_seq(s, max(input_lengths)) for s in input_seqs]\n",
    "    target_lengths = [len(s) for s in target_seqs]\n",
    "    target_padded = [pad_seq(s, max(target_lengths)) for s in target_seqs]\n",
    "\n",
    "    # Turn padded arrays into (batch_size x max_len) tensors, transpose into (max_len x batch_size)\n",
    "    input_var = Variable(torch.LongTensor(input_padded)).transpose(0, 1)\n",
    "    target_var = Variable(torch.LongTensor(target_padded)).transpose(0, 1)\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        input_var = input_var.cuda()\n",
    "        target_var = target_var.cuda()\n",
    "        \n",
    "    return input_var, input_lengths, target_var, target_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_batches torch.Size([67, 3])\n",
      "target_batches torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "small_batch_size = 3\n",
    "input_batches, input_lengths, target_batches, target_lengths = random_batch(train_pairs, small_batch_size)\n",
    "\n",
    "print('input_batches', input_batches.size()) # (max_len x batch_size)\n",
    "print('target_batches', target_batches.size()) # (max_len x batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "small_hidden_size = 8\n",
    "small_n_layers = 2\n",
    "\n",
    "hidden_size = 256\n",
    "\n",
    "encoder_test = EncoderRNN(input_lang.n_words, hidden_size, n_layers = 2)\n",
    "decoder_test = LuongAttnDecoderRNN('general', hidden_size, output_lang.n_words,\n",
    "                           n_layers = 2, dropout=0.2)\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder_test.cuda()\n",
    "    decoder_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_outputs torch.Size([67, 3, 256])\n",
      "encoder_hidden torch.Size([4, 3, 256])\n"
     ]
    }
   ],
   "source": [
    "encoder_outputs, encoder_hidden = encoder_test(input_batches, input_lengths, None)\n",
    "\n",
    "print('encoder_outputs', encoder_outputs.size()) # max_len x batch_size x hidden_size\n",
    "print('encoder_hidden', encoder_hidden.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2\n",
       " 2\n",
       " 3\n",
       "[torch.cuda.LongTensor of size 3 (GPU 0)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 7.937414646148682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dpetrov/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.3. Note that arange generates values in [start; end), not [start; end].\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "max_target_length = max(target_lengths)\n",
    "\n",
    "# Prepare decoder input and outputs\n",
    "decoder_input = Variable(torch.LongTensor([SOS_token] * small_batch_size))\n",
    "decoder_hidden = encoder_hidden[:decoder_test.n_layers] # Use last (forward) hidden state from encoder\n",
    "all_decoder_outputs = Variable(torch.zeros(max_target_length, small_batch_size, decoder_test.output_size))\n",
    "\n",
    "if USE_CUDA:\n",
    "    all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "    decoder_input = decoder_input.cuda()\n",
    "\n",
    "# Run through decoder one time step at a time\n",
    "for t in range(max_target_length):\n",
    "    decoder_output, decoder_hidden, decoder_attn = decoder_test(\n",
    "        decoder_input, decoder_hidden, encoder_outputs\n",
    "    )\n",
    "    all_decoder_outputs[t] = decoder_output # Store this step's outputs\n",
    "    decoder_input = target_batches[t] # Next input is current target\n",
    "\n",
    "# Test masked cross entropy loss\n",
    "loss = masked_cross_entropy(\n",
    "    all_decoder_outputs.transpose(0, 1).contiguous(),\n",
    "    target_batches.transpose(0, 1).contiguous(),\n",
    "    target_lengths\n",
    ")\n",
    "print('loss', loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(input_batches, input_lengths, target_batches, target_lengths, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    \n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches, input_lengths, None)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = Variable(torch.LongTensor([SOS_token] * batch_size))\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "\n",
    "    max_target_length = max(target_lengths)\n",
    "    all_decoder_outputs = Variable(torch.zeros(max_target_length, batch_size, decoder.output_size))\n",
    "\n",
    "    # Move new Variables to CUDA\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "\n",
    "    # Run through decoder one time step at a time\n",
    "    for t in range(max_target_length):\n",
    "        decoder_output, decoder_hidden, decoder_attn = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs\n",
    "        )\n",
    "\n",
    "        all_decoder_outputs[t] = decoder_output\n",
    "        decoder_input = target_batches[t] # Next input is current target\n",
    "\n",
    "    # Loss calculation and backpropagation\n",
    "    loss = masked_cross_entropy(\n",
    "        all_decoder_outputs.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "        target_batches.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "        target_lengths\n",
    "    )\n",
    "    loss.backward()\n",
    "    \n",
    "    # Clip gradient norms\n",
    "    ec = torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    dc = torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "\n",
    "    # Update parameters with optimizers\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0], ec, dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure models\n",
    "attn_model = 'dot'\n",
    "hidden_size = 256\n",
    "n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 100\n",
    "batch_size = 50\n",
    "\n",
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "learning_rate = 0.01\n",
    "decoder_learning_ratio = 5.0\n",
    "n_epochs = 50000\n",
    "epoch = 0\n",
    "plot_every = 2\n",
    "print_every = 2\n",
    "evaluate_every = 1000\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, n_layers, dropout=dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, hidden_size, output_lang.n_words, n_layers, dropout=dropout)\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dpetrov/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.3. Note that arange generates values in [start; end), not [start; end].\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "2m 28s (- 20627m 8s) (6 0%) 10.4262\n",
      "61\n",
      "60\n",
      "2m 51s (- 17845m 14s) (8 0%) 11.2056\n",
      "79\n",
      "68\n",
      "3m 15s (- 16298m 14s) (10 0%) 11.6851\n",
      "64\n",
      "68\n",
      "3m 36s (- 15034m 51s) (12 0%) 12.9327\n",
      "59\n",
      "78\n",
      "3m 58s (- 14213m 29s) (14 0%) 9.6066\n",
      "67\n",
      "78\n",
      "4m 19s (- 13521m 6s) (16 0%) 8.4035\n",
      "61\n",
      "59\n",
      "4m 38s (- 12900m 50s) (18 0%) 7.7523\n",
      "66\n",
      "77\n",
      "4m 55s (- 12326m 8s) (20 0%) 7.7323\n",
      "68\n",
      "58\n",
      "5m 10s (- 11757m 15s) (22 0%) 5.4485\n",
      "66\n",
      "63\n",
      "5m 25s (- 11311m 40s) (24 0%) 5.5261\n",
      "73\n",
      "66\n",
      "6m 25s (- 12358m 27s) (26 0%) 9.6619\n",
      "61\n",
      "57\n",
      "6m 38s (- 11863m 57s) (28 0%) 4.6885\n",
      "65\n",
      "52\n",
      "7m 5s (- 11806m 19s) (30 0%) 9.6771\n",
      "63\n",
      "68\n",
      "7m 22s (- 11516m 53s) (32 0%) 8.9777\n",
      "67\n",
      "72\n",
      "7m 39s (- 11248m 6s) (34 0%) 4.9463\n",
      "73\n",
      "71\n",
      "8m 0s (- 11117m 25s) (36 0%) 9.2044\n",
      "64\n",
      "56\n",
      "8m 17s (- 10911m 40s) (38 0%) 8.3867\n",
      "57\n",
      "70\n",
      "8m 35s (- 10740m 16s) (40 0%) 11.2259\n",
      "75\n",
      "62\n",
      "8m 48s (- 10480m 49s) (42 0%) 4.7105\n",
      "67\n",
      "60\n",
      "9m 11s (- 10431m 13s) (44 0%) 9.6441\n",
      "65\n",
      "68\n",
      "9m 43s (- 10566m 38s) (46 0%) 9.6814\n",
      "72\n",
      "61\n",
      "10m 2s (- 10445m 1s) (48 0%) 6.0985\n",
      "64\n",
      "54\n",
      "10m 23s (- 10376m 43s) (50 0%) 9.7140\n",
      "72\n",
      "60\n",
      "10m 42s (- 10283m 31s) (52 0%) 5.9862\n",
      "57\n",
      "60\n",
      "10m 53s (- 10081m 3s) (54 0%) 7.9799\n",
      "69\n",
      "65\n",
      "11m 27s (- 10225m 16s) (56 0%) 6.5671\n",
      "71\n",
      "59\n",
      "11m 45s (- 10129m 25s) (58 0%) 9.0204\n",
      "71\n",
      "61\n",
      "12m 3s (- 10030m 1s) (60 0%) 4.5274\n",
      "64\n",
      "76\n",
      "12m 28s (- 10050m 44s) (62 0%) 4.6108\n",
      "68\n",
      "72\n",
      "12m 53s (- 10056m 41s) (64 0%) 9.3817\n",
      "62\n",
      "61\n",
      "13m 6s (- 9921m 32s) (66 0%) 4.8138\n",
      "62\n",
      "56\n",
      "13m 30s (- 9913m 16s) (68 0%) 7.7376\n",
      "57\n",
      "54\n",
      "13m 51s (- 9884m 9s) (70 0%) 9.1709\n",
      "68\n",
      "64\n",
      "14m 8s (- 9801m 51s) (72 0%) 6.7550\n",
      "76\n",
      "68\n",
      "14m 26s (- 9748m 6s) (74 0%) 7.5925\n",
      "59\n",
      "62\n",
      "14m 42s (- 9663m 55s) (76 0%) 6.4586\n",
      "56\n",
      "59\n",
      "15m 0s (- 9609m 1s) (78 0%) 5.0842\n",
      "67\n",
      "69\n",
      "15m 25s (- 9627m 31s) (80 0%) 9.3223\n",
      "62\n",
      "61\n",
      "15m 44s (- 9587m 0s) (82 0%) 9.8462\n",
      "69\n",
      "67\n",
      "16m 10s (- 9613m 56s) (84 0%) 10.3088\n",
      "65\n",
      "48\n",
      "16m 26s (- 9544m 46s) (86 0%) 6.1957\n",
      "58\n",
      "70\n",
      "16m 59s (- 9637m 20s) (88 0%) 8.3003\n",
      "61\n",
      "68\n",
      "17m 17s (- 9590m 30s) (90 0%) 8.7651\n",
      "59\n",
      "64\n",
      "17m 41s (- 9596m 50s) (92 0%) 8.0396\n",
      "68\n",
      "55\n",
      "18m 1s (- 9566m 4s) (94 0%) 8.8366\n",
      "82\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-bd226c9437ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0minput_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-148-7d51dc014236>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_batches, input_lengths, target_batches, target_lengths, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtarget_lengths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     )\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Clip gradient norms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "\n",
    "\n",
    "# Begin!\n",
    "ecs = []\n",
    "dcs = []\n",
    "eca = 0\n",
    "dca = 0\n",
    "\n",
    "while epoch < n_epochs:\n",
    "    epoch += 1\n",
    "    \n",
    "    # Get training data for this cycle\n",
    "    input_batches, input_lengths, target_batches, target_lengths = random_batch(train_pairs, batch_size)\n",
    "    \n",
    "    print(len(input_batches))\n",
    "    # Run the train function\n",
    "    loss, ec, dc = train(\n",
    "        input_batches, input_lengths, target_batches, target_lengths,\n",
    "        encoder, decoder,\n",
    "        encoder_optimizer, decoder_optimizer, criterion\n",
    "    )\n",
    "\n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "    eca += ec\n",
    "    dca += dc\n",
    "    \n",
    "    #job.record(epoch, loss)\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_epochs), epoch, epoch / n_epochs * 100, print_loss_avg)\n",
    "        print(print_summary)\n",
    "        \n",
    "    if epoch % evaluate_every == 0:\n",
    "        evaluate_randomly()\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0\n",
    "        \n",
    "        # TODO: Running average helper\n",
    "        ecs.append(eca / plot_every)\n",
    "        dcs.append(dca / plot_every)\n",
    "        ecs_win = 'encoder grad (%s)' % hostname\n",
    "        dcs_win = 'decoder grad (%s)' % hostname\n",
    "        #vis.line(np.array(ecs), win=ecs_win, opts={'title': ecs_win})\n",
    "        #vis.line(np.array(dcs), win=dcs_win, opts={'title': dcs_win})\n",
    "        eca = 0\n",
    "        dca = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File range: [0, 1]\n",
      "Data shape for item 0 is (2973646, 3)\n",
      "Data shape for item 1 is (2981069, 3)\n",
      "Overall data shape is (5954715, 3)\n",
      "File range: [5, 6, 7]\n",
      "Data shape for item 5 is (2975471, 3)\n",
      "Data shape for item 6 is (2980056, 3)\n",
      "Data shape for item 7 is (2975255, 3)\n",
      "Overall data shape is (8930782, 3)\n",
      "Len of pairs: 8319218\n",
      "Len of pairs after filtering: 8318115\n",
      "Len of pairs: 5547039\n",
      "Len of pairs after filtering: 5546221\n",
      "[('<PLAIN> <norm> Д р у г а я </norm> </PLAIN> в е р с и я б е р е т н а ч а л о', '<self>', 'PLAIN'), ('<PLAIN> <norm> в е р с и я </norm> </PLAIN> б е р е т н а ч а л о о т', '<self>', 'PLAIN'), ('<PLAIN> <norm> б е р е т </norm> </PLAIN> н а ч а л о о т с л о в а', '<self>', 'PLAIN'), ('Д р у г а я в е р с и я б е р е т <PLAIN> <norm> н а ч а л о </norm> </PLAIN> о т с л о в а \"', '<self>', 'PLAIN'), ('в е р с и я б е р е т н а ч а л о <PLAIN> <norm> о т </norm> </PLAIN> с л о в а \" н е п е я', '<self>', 'PLAIN')]\n",
      "[('<PLAIN> <norm> П о </norm> </PLAIN> с о с т о я н и ю н а 1 8 6 2 г о д', '<self>', 'PLAIN'), ('<PLAIN> <norm> с о с т о я н и ю </norm> </PLAIN> н а 1 8 6 2 г о д .', '<self>', 'PLAIN'), ('<PLAIN> <norm> н а </norm> </PLAIN> 1 8 6 2 г о д . ', '<self>', 'PLAIN'), ('П о с о с т о я н и ю н а <DATE> <norm> 1 8 6 2 г о д </norm> </DATE> . ', 'тысяча восемьсот шестьдесят второй год', 'DATE'), ('с о с т о я н и ю н а 1 8 6 2 г о д <PUNCT> <norm> . </norm> </PUNCT> ', 'sil', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "data_dev = get_data(range(0,2))\n",
    "data_learn = get_data(range(5,8))\n",
    "\n",
    "train_pairs = get_pairs(data_learn)\n",
    "dev_pairs = get_pairs(data_dev)\n",
    "\n",
    "input_lang, output_lang = Lang('nonnorm'), Lang('norm')\n",
    "\n",
    "for pair in train_pairs + dev_pairs:\n",
    "    input_lang.addSentence(pair[0])\n",
    "    output_lang.addSentence(pair[1])\n",
    "    \n",
    "print(train_pairs[:5])\n",
    "print(dev_pairs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled = False\n",
    "test_pairs = make_even_sample(dev_pairs, size_of_class = 300)\n",
    "\n",
    "test_weight = dict((data_dev['class'].value_counts()/len(data_dev)))\n",
    "print(test_weight)\n",
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size, n_layers=4)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words,\n",
    "                           n_layers = 2, dropout_p=0.2)\n",
    "\n",
    "if use_cuda:\n",
    "    print('Using CUDA')\n",
    "    encoder1 = encoder1.cuda()\n",
    "    attn_decoder1 = attn_decoder1.cuda()\n",
    "\n",
    "callback_num = 100\n",
    "\n",
    "plot_losses = trainIters_weighted(encoder1, attn_decoder1, train_pairs, test_pairs, 1001, print_every=callback_num, \n",
    "                         plot_every=callback_num, evaluate_each=1000, learning_rate = 0.01)\n",
    "\n",
    "torch.save(encoder1.state_dict() , 'models/encoder_{}.states'.format(model_name))\n",
    "torch.save(attn_decoder1.state_dict(), 'models/decoder_{}.states'.format(model_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc, tst = evaluate_pairs(encoder1, attn_decoder1, test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_load = EncoderRNN(input_lang.n_words, hidden_size, n_layers=4)\n",
    "encoder_load.load_state_dict(torch.load('models/encoder_test.states'))\n",
    "\n",
    "attn_decoder_load = AttnDecoderRNN(hidden_size, output_lang.n_words,\n",
    "                           n_layers = 2, dropout_p=0.2)\n",
    "attn_decoder_load.load_state_dict(torch.load('models/decoder_test.states'))\n",
    "\n",
    "if use_cuda:\n",
    "    print('Using CUDA')\n",
    "    encoder1 = encoder_load.cuda()\n",
    "    attn_decoder1 = attn_decoder_load.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc, acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_losses = trainIters_weighted(encoder_load, attn_decoder_load, train_pairs, test_pairs, 1001, print_every=callback_num, \n",
    "                         plot_every=callback_num, evaluate_each=1000, learning_rate = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, pairs, test_pairs, \n",
    "               n_iters, print_every=1000, plot_every=100, \n",
    "               learning_rate=0.01, evaluate_each=False):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    plot_accuracies = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    weighted_sample = sample_pairs(pairs, size = n_iters)\n",
    "    training_pairs = [variablesFromPair(item)\n",
    "                      for item in weighted_sample]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    " \n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "            \n",
    "        if evaluate_each and iter % evaluate_each == 0 and iter != 0:\n",
    "            \n",
    "            cur_accuracy, error_dict = evaluate_pairs(encoder, decoder, test_pairs)\n",
    "            plot_accuracies.append(cur_accuracy)\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    showPlot(plot_accuracies)\n",
    "    \n",
    "    return plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_weight = dict((data_train['class'].value_counts()/len(data_train)))\n",
    "test_weight['<eos>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<eos>': 0,\n",
       " 'CARDINAL': 0.025764016055202905,\n",
       " 'DATE': 0.017585580276203657,\n",
       " 'DECIMAL': 0.00069005522333126165,\n",
       " 'DIGIT': 0.00019026875556290237,\n",
       " 'ELECTRONIC': 0.00055151460359982433,\n",
       " 'FRACTION': 0.00023263476077770367,\n",
       " 'LETTERS': 0.01792308981328318,\n",
       " 'MEASURE': 0.0038331778021802607,\n",
       " 'MONEY': 0.00025438516524065974,\n",
       " 'ORDINAL': 0.0044198713208245177,\n",
       " 'PLAIN': 0.69605445771702457,\n",
       " 'PUNCT': 0.21642976378304218,\n",
       " 'TELEPHONE': 0.00095399165314043687,\n",
       " 'TIME': 0.00018393276817586733,\n",
       " 'VERBATIM': 0.014933260302410059}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "('э т о г о с т а л т р а н с п о р т н ы й <PLAIN> <norm> к о л л а п с </norm> </PLAIN> н а Л е н и н г р а д с к о м ш о с с е', '<self>', 'PLAIN')\n",
      "('у с л о в и я х ( г о р о д <PLAIN> <norm> М е н з е л и н с к </norm> </PLAIN> ) п р о ж и в а ю т 5 9 , 1 1 %', '<self>', 'PLAIN')\n",
      "10001\n",
      "2m 4s (- 1039m 11s) (1000 0%) 1.8199\n",
      "3m 59s (- 994m 13s) (2000 0%) 1.4111\n",
      "5m 51s (- 970m 39s) (3000 0%) 1.4005\n",
      "7m 42s (- 956m 1s) (4000 0%) 1.4486\n",
      "9m 32s (- 944m 3s) (5000 1%) 1.3076\n",
      "11m 23s (- 937m 27s) (6000 1%) 1.3273\n",
      "13m 15s (- 933m 16s) (7000 1%) 1.1620\n",
      "15m 6s (- 929m 39s) (8000 1%) 1.2938\n",
      "16m 55s (- 923m 0s) (9000 1%) 1.1628\n",
      "18m 49s (- 922m 6s) (10000 2%) 1.0666\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.enabled = False\n",
    "test_pairs = make_even_sample(dev_pairs, size_of_class = 300)\n",
    "\n",
    "\n",
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size, n_layers=4)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words,\n",
    "                           n_layers = 2, dropout_p=0.2)\n",
    "\n",
    "if use_cuda:\n",
    "    print('Using CUDA')\n",
    "    encoder1 = encoder1.cuda()\n",
    "    attn_decoder1 = attn_decoder1.cuda()\n",
    "\n",
    "callback_num = 1000\n",
    "plot_losses = trainIters_weighted(encoder1, attn_decoder1, train_pairs, test_pairs, 500000, print_every=callback_num, \n",
    "                         plot_every=callback_num, evaluate_each=10000, learning_rate = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "('с о с т о р о н ы м е с т н о г о <norm> н а с е л е н и я </norm> . ', '<self>', 'PLAIN')\n",
      "('— п о м о ч ь с п р а в и т ь с я <norm> с о </norm> с в о и м и и н с т и н к т а м и .', '<self>', 'PLAIN')\n",
      "10001\n",
      "1m 49s (- 910m 30s) (1000 0%) 1.8550\n",
      "3m 31s (- 876m 40s) (2000 0%) 1.4991\n",
      "5m 14s (- 868m 23s) (3000 0%) 1.4103\n",
      "6m 56s (- 859m 57s) (4000 0%) 1.4693\n",
      "8m 36s (- 852m 55s) (5000 1%) 1.3569\n",
      "10m 19s (- 850m 26s) (6000 1%) 1.2606\n",
      "12m 2s (- 847m 57s) (7000 1%) 1.3307\n",
      "13m 41s (- 841m 55s) (8000 1%) 1.3229\n",
      "15m 23s (- 839m 35s) (9000 1%) 1.2368\n",
      "17m 3s (- 836m 2s) (10000 2%) 1.1838\n",
      "\t\t eval accuracy: 0.120\n",
      "\t\t\t PLAIN eval error: 0.297\n",
      "\t\t\t PUNCT eval error: 0.313\n",
      "\t\t\t VERBATIM eval error: 0.633\n",
      "\t\t\t ORDINAL eval error: 1.000\n",
      "\t\t\t MEASURE eval error: 0.993\n",
      "\t\t\t DATE eval error: 0.997\n",
      "\t\t\t ELECTRONIC eval error: 0.993\n",
      "\t\t\t CARDINAL eval error: 0.997\n",
      "\t\t\t LETTERS eval error: 1.000\n",
      "\t\t\t DECIMAL eval error: 0.983\n",
      "\t\t\t FRACTION eval error: 0.997\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 1.000\n",
      "\t\t\t MONEY eval error: 0.990\n",
      "\t\t\t DIGIT eval error: 1.000\n",
      "{'PLAIN': 1, 'PUNCT': 2, 'VERBATIM': 4.0, 'ORDINAL': 4.0, 'MEASURE': 4.0, 'DATE': 4.0, 'ELECTRONIC': 4.0, 'CARDINAL': 4.0, 'LETTERS': 4.0, 'DECIMAL': 4.0, 'FRACTION': 4.0, 'TELEPHONE': 4.0, 'TIME': 4.0, 'MONEY': 4.0, 'DIGIT': 4.0, '<eos>': 0.0}\n",
      "('в м и р у Э л и е <norm> К р и с т я </norm> , р у м .', '<self>', 'PLAIN')\n",
      "('в з е м л е Б а д е н <norm> - </norm> В ю р т е м б е р г . ', 'sil', 'VERBATIM')\n",
      "10001\n",
      "21m 57s (- 976m 22s) (11000 2%) 1.3502\n",
      "23m 39s (- 962m 0s) (12000 2%) 1.3242\n",
      "25m 22s (- 950m 49s) (13000 2%) 1.1765\n",
      "27m 5s (- 940m 15s) (14000 2%) 0.9945\n",
      "28m 47s (- 930m 53s) (15000 3%) 1.0549\n",
      "30m 28s (- 922m 3s) (16000 3%) 1.0875\n",
      "32m 11s (- 914m 46s) (17000 3%) 0.9882\n",
      "33m 55s (- 908m 15s) (18000 3%) 1.0162\n",
      "35m 36s (- 901m 15s) (19000 3%) 0.9520\n",
      "37m 19s (- 895m 50s) (20000 4%) 0.9721\n",
      "\t\t eval accuracy: 0.191\n",
      "\t\t\t PLAIN eval error: 0.087\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.093\n",
      "\t\t\t ORDINAL eval error: 1.000\n",
      "\t\t\t MEASURE eval error: 1.000\n",
      "\t\t\t DATE eval error: 1.000\n",
      "\t\t\t ELECTRONIC eval error: 1.000\n",
      "\t\t\t CARDINAL eval error: 0.987\n",
      "\t\t\t LETTERS eval error: 0.970\n",
      "\t\t\t DECIMAL eval error: 1.000\n",
      "\t\t\t FRACTION eval error: 1.000\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 1.000\n",
      "\t\t\t MONEY eval error: 1.000\n",
      "\t\t\t DIGIT eval error: 1.000\n",
      "{'PLAIN': 1, 'PUNCT': 2, 'VERBATIM': 4.0, 'ORDINAL': 5.0, 'MEASURE': 5.0, 'DATE': 5.0, 'ELECTRONIC': 5.0, 'CARDINAL': 5.0, 'LETTERS': 5.0, 'DECIMAL': 5.0, 'FRACTION': 5.0, 'TELEPHONE': 5.0, 'TIME': 5.0, 'MONEY': 5.0, 'DIGIT': 5.0, '<eos>': 0.0}\n",
      "('п и в о с о д е р ж и т н е м н о г о <norm> м е н ь ш е </norm> с п и р т а и х м е л я', '<self>', 'PLAIN')\n",
      "(', п р и н а д л е ж а щ а я Ш т у т г а р т с к о й <norm> т о р г о в о й </norm> я р м а р к е , о х в а т ы в а е т', '<self>', 'PLAIN')\n",
      "10001\n",
      "42m 23s (- 966m 54s) (21000 4%) 1.0193\n",
      "44m 4s (- 957m 30s) (22000 4%) 0.9759\n",
      "45m 46s (- 949m 15s) (23000 4%) 0.9612\n",
      "47m 26s (- 940m 55s) (24000 4%) 0.9540\n",
      "49m 6s (- 933m 6s) (25000 5%) 1.0179\n",
      "50m 47s (- 926m 3s) (26000 5%) 0.9786\n",
      "52m 30s (- 919m 48s) (27000 5%) 0.9471\n",
      "54m 12s (- 913m 52s) (28000 5%) 0.8134\n",
      "55m 54s (- 908m 0s) (29000 5%) 0.9628\n",
      "57m 34s (- 902m 0s) (30000 6%) 0.9180\n",
      "\t\t eval accuracy: 0.192\n",
      "\t\t\t PLAIN eval error: 0.110\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.100\n",
      "\t\t\t ORDINAL eval error: 1.000\n",
      "\t\t\t MEASURE eval error: 1.000\n",
      "\t\t\t DATE eval error: 1.000\n",
      "\t\t\t ELECTRONIC eval error: 0.980\n",
      "\t\t\t CARDINAL eval error: 0.960\n",
      "\t\t\t LETTERS eval error: 0.983\n",
      "\t\t\t DECIMAL eval error: 0.997\n",
      "\t\t\t FRACTION eval error: 1.000\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 1.000\n",
      "\t\t\t MONEY eval error: 1.000\n",
      "\t\t\t DIGIT eval error: 0.987\n",
      "{'PLAIN': 2, 'PUNCT': 3, 'VERBATIM': 5.0, 'ORDINAL': 6.0, 'MEASURE': 6.0, 'DATE': 6.0, 'ELECTRONIC': 6.0, 'CARDINAL': 6.0, 'LETTERS': 6.0, 'DECIMAL': 6.0, 'FRACTION': 6.0, 'TELEPHONE': 6.0, 'TIME': 6.0, 'MONEY': 6.0, 'DIGIT': 6.0, '<eos>': 0.0}\n",
      "('в 1 0 - й к о р п у с <norm> С С </norm> . ', 'с с', 'LETTERS')\n",
      "('ц е р к в и р а с п о л о ж и л и ш к о л у <norm> . </norm> ', 'sil', 'PUNCT')\n",
      "10001\n",
      "62m 39s (- 948m 2s) (31000 6%) 0.7402\n",
      "64m 25s (- 942m 13s) (32000 6%) 0.7058\n",
      "66m 10s (- 936m 30s) (33000 6%) 0.6719\n",
      "67m 54s (- 930m 40s) (34000 6%) 0.6541\n",
      "69m 39s (- 925m 24s) (35000 7%) 0.7334\n",
      "71m 24s (- 920m 21s) (36000 7%) 0.6303\n",
      "73m 10s (- 915m 42s) (37000 7%) 0.7266\n",
      "74m 54s (- 910m 45s) (38000 7%) 0.6372\n",
      "76m 40s (- 906m 16s) (39000 7%) 0.6540\n",
      "78m 26s (- 902m 7s) (40000 8%) 0.7306\n",
      "\t\t eval accuracy: 0.135\n",
      "\t\t\t PLAIN eval error: 0.387\n",
      "\t\t\t PUNCT eval error: 0.200\n",
      "\t\t\t VERBATIM eval error: 0.450\n",
      "\t\t\t ORDINAL eval error: 0.997\n",
      "\t\t\t MEASURE eval error: 0.993\n",
      "\t\t\t DATE eval error: 0.997\n",
      "\t\t\t ELECTRONIC eval error: 0.993\n",
      "\t\t\t CARDINAL eval error: 0.993\n",
      "\t\t\t LETTERS eval error: 1.000\n",
      "\t\t\t DECIMAL eval error: 0.987\n",
      "\t\t\t FRACTION eval error: 0.997\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.993\n",
      "\t\t\t MONEY eval error: 0.983\n",
      "\t\t\t DIGIT eval error: 1.000\n",
      "{'PLAIN': 3, 'PUNCT': 4, 'VERBATIM': 6.0, 'ORDINAL': 7.0, 'MEASURE': 7.0, 'DATE': 7.0, 'ELECTRONIC': 7.0, 'CARDINAL': 7.0, 'LETTERS': 7.0, 'DECIMAL': 7.0, 'FRACTION': 7.0, 'TELEPHONE': 7.0, 'TIME': 7.0, 'MONEY': 7.0, 'DIGIT': 7.0, '<eos>': 0.0}\n",
      "('д е р е в я н н ы й я щ и к с <norm> п о д в и ж н о й </norm> р а м о й . ', '<self>', 'PLAIN')\n",
      "(', ж е л е з н о д о р о ж н ы м и <norm> м о р с к и м </norm> т р а н с п о р т о м . ', '<self>', 'PLAIN')\n",
      "10001\n",
      "83m 27s (- 934m 16s) (41000 8%) 1.2603\n",
      "85m 9s (- 928m 39s) (42000 8%) 1.0412\n",
      "86m 52s (- 923m 13s) (43000 8%) 0.9333\n",
      "88m 33s (- 917m 50s) (44000 8%) 0.8354\n",
      "90m 19s (- 913m 18s) (45000 9%) 0.6323\n",
      "92m 3s (- 908m 36s) (46000 9%) 0.7424\n",
      "93m 46s (- 903m 46s) (47000 9%) 0.7298\n",
      "95m 33s (- 899m 45s) (48000 9%) 0.7191\n",
      "97m 18s (- 895m 36s) (49000 9%) 0.6342\n",
      "99m 4s (- 891m 36s) (50000 10%) 0.6460\n",
      "\t\t eval accuracy: 0.198\n",
      "\t\t\t PLAIN eval error: 0.083\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.097\n",
      "\t\t\t ORDINAL eval error: 0.997\n",
      "\t\t\t MEASURE eval error: 1.000\n",
      "\t\t\t DATE eval error: 0.997\n",
      "\t\t\t ELECTRONIC eval error: 0.980\n",
      "\t\t\t CARDINAL eval error: 0.960\n",
      "\t\t\t LETTERS eval error: 0.920\n",
      "\t\t\t DECIMAL eval error: 0.997\n",
      "\t\t\t FRACTION eval error: 0.997\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 1.000\n",
      "\t\t\t MONEY eval error: 1.000\n",
      "\t\t\t DIGIT eval error: 1.000\n",
      "{'PLAIN': 3, 'PUNCT': 5, 'VERBATIM': 7.0, 'ORDINAL': 8.0, 'MEASURE': 8.0, 'DATE': 8.0, 'ELECTRONIC': 8.0, 'CARDINAL': 8.0, 'LETTERS': 8.0, 'DECIMAL': 8.0, 'FRACTION': 8.0, 'TELEPHONE': 8.0, 'TIME': 8.0, 'MONEY': 8.0, 'DIGIT': 8.0, '<eos>': 0.0}\n",
      "('- Л И З И Н Г / <norm> / </norm> b a n k i . r u . ', 'sil', 'PUNCT')\n",
      "('и н ж е н е р а м к о м п а н и и S i e m e n s <norm> . </norm> ', 'sil', 'PUNCT')\n",
      "10001\n",
      "104m 9s (- 916m 58s) (51000 10%) 0.6118\n",
      "105m 53s (- 912m 18s) (52000 10%) 0.6563\n",
      "107m 38s (- 907m 52s) (53000 10%) 0.5644\n",
      "109m 21s (- 903m 16s) (54000 10%) 0.6976\n",
      "111m 6s (- 898m 56s) (55000 11%) 0.5656\n",
      "112m 52s (- 894m 57s) (56000 11%) 0.5877\n",
      "114m 37s (- 890m 49s) (57000 11%) 0.6045\n",
      "116m 20s (- 886m 32s) (58000 11%) 0.5401\n",
      "118m 3s (- 882m 23s) (59000 11%) 0.5779\n",
      "119m 47s (- 878m 26s) (60000 12%) 0.5779\n",
      "\t\t eval accuracy: 0.217\n",
      "\t\t\t PLAIN eval error: 0.083\n",
      "\t\t\t PUNCT eval error: 0.003\n",
      "\t\t\t VERBATIM eval error: 0.107\n",
      "\t\t\t ORDINAL eval error: 1.000\n",
      "\t\t\t MEASURE eval error: 1.000\n",
      "\t\t\t DATE eval error: 1.000\n",
      "\t\t\t ELECTRONIC eval error: 0.980\n",
      "\t\t\t CARDINAL eval error: 0.883\n",
      "\t\t\t LETTERS eval error: 0.687\n",
      "\t\t\t DECIMAL eval error: 1.000\n",
      "\t\t\t FRACTION eval error: 1.000\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 1.000\n",
      "\t\t\t MONEY eval error: 1.000\n",
      "\t\t\t DIGIT eval error: 1.000\n",
      "{'PLAIN': 4, 'PUNCT': 6, 'VERBATIM': 8.0, 'ORDINAL': 9.0, 'MEASURE': 9.0, 'DATE': 9.0, 'ELECTRONIC': 9.0, 'CARDINAL': 9.0, 'LETTERS': 9.0, 'DECIMAL': 9.0, 'FRACTION': 9.0, 'TELEPHONE': 9.0, 'TIME': 9.0, 'MONEY': 9.0, 'DIGIT': 9.0, '<eos>': 0.0}\n",
      "('\" В е с т н и к С Г С Э У <norm> \" </norm> . ', 'sil', 'PUNCT')\n",
      "('х а р а к т е р Ф р е д е р и к а , <norm> п р и в и л а </norm> с п о с о б н о с т ь т р е з в о о ц е н и в а т ь', '<self>', 'PLAIN')\n",
      "10001\n",
      "124m 56s (- 899m 9s) (61000 12%) 0.5328\n",
      "126m 41s (- 895m 1s) (62000 12%) 0.5549\n",
      "128m 25s (- 890m 49s) (63000 12%) 0.4485\n",
      "130m 9s (- 886m 39s) (64000 12%) 0.4239\n",
      "131m 51s (- 882m 24s) (65000 13%) 0.5595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133m 35s (- 878m 30s) (66000 13%) 0.5233\n",
      "135m 20s (- 874m 39s) (67000 13%) 0.4685\n",
      "137m 5s (- 870m 56s) (68000 13%) 0.5021\n",
      "138m 52s (- 867m 26s) (69000 13%) 0.4670\n",
      "140m 35s (- 863m 38s) (70000 14%) 0.4913\n",
      "\t\t eval accuracy: 0.239\n",
      "\t\t\t PLAIN eval error: 0.080\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.080\n",
      "\t\t\t ORDINAL eval error: 1.000\n",
      "\t\t\t MEASURE eval error: 1.000\n",
      "\t\t\t DATE eval error: 0.973\n",
      "\t\t\t ELECTRONIC eval error: 0.980\n",
      "\t\t\t CARDINAL eval error: 0.757\n",
      "\t\t\t LETTERS eval error: 0.740\n",
      "\t\t\t DECIMAL eval error: 0.983\n",
      "\t\t\t FRACTION eval error: 1.000\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 1.000\n",
      "\t\t\t MONEY eval error: 1.000\n",
      "\t\t\t DIGIT eval error: 0.827\n",
      "{'PLAIN': 4, 'PUNCT': 7, 'VERBATIM': 8.0, 'ORDINAL': 10.0, 'MEASURE': 10.0, 'DATE': 10.0, 'ELECTRONIC': 10.0, 'CARDINAL': 10.0, 'LETTERS': 10.0, 'DECIMAL': 10.0, 'FRACTION': 10.0, 'TELEPHONE': 10.0, 'TIME': 10.0, 'MONEY': 10.0, 'DIGIT': 10.0, '<eos>': 0.0}\n",
      "('8 . П а ч у л и а <norm> В . П . </norm> В к р а ю З о л о т о г о', 'в п', 'LETTERS')\n",
      "('и м . Ш . <norm> В а л и х а н о в а </norm> п о д о т к р ы т ы м н е б о м', '<self>', 'PLAIN')\n",
      "10001\n",
      "145m 47s (- 880m 55s) (71000 14%) 0.4163\n",
      "147m 33s (- 877m 8s) (72000 14%) 0.4651\n",
      "149m 21s (- 873m 37s) (73000 14%) 0.4999\n",
      "151m 5s (- 869m 50s) (74000 14%) 0.4642\n",
      "152m 51s (- 866m 10s) (75000 15%) 0.4696\n",
      "154m 35s (- 862m 26s) (76000 15%) 0.4253\n",
      "156m 18s (- 858m 41s) (77000 15%) 0.3742\n",
      "158m 5s (- 855m 20s) (78000 15%) 0.4530\n",
      "159m 49s (- 851m 42s) (79000 15%) 0.4404\n",
      "161m 35s (- 848m 22s) (80000 16%) 0.4292\n",
      "\t\t eval accuracy: 0.268\n",
      "\t\t\t PLAIN eval error: 0.073\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.080\n",
      "\t\t\t ORDINAL eval error: 0.930\n",
      "\t\t\t MEASURE eval error: 1.000\n",
      "\t\t\t DATE eval error: 0.970\n",
      "\t\t\t ELECTRONIC eval error: 0.980\n",
      "\t\t\t CARDINAL eval error: 0.703\n",
      "\t\t\t LETTERS eval error: 0.653\n",
      "\t\t\t DECIMAL eval error: 0.990\n",
      "\t\t\t FRACTION eval error: 0.990\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.987\n",
      "\t\t\t MONEY eval error: 1.000\n",
      "\t\t\t DIGIT eval error: 0.623\n",
      "{'PLAIN': 4, 'PUNCT': 8, 'VERBATIM': 9.0, 'ORDINAL': 11.0, 'MEASURE': 11.0, 'DATE': 11.0, 'ELECTRONIC': 11.0, 'CARDINAL': 11.0, 'LETTERS': 11.0, 'DECIMAL': 11.0, 'FRACTION': 11.0, 'TELEPHONE': 11.0, 'TIME': 11.0, 'MONEY': 11.0, 'DIGIT': 11.0, '<eos>': 0.0}\n",
      "('ч е р е з к а б е л и и з <norm> о п т и ч е с к о г о </norm> в о л о к н а д л я к а ж д о г о', '<self>', 'PLAIN')\n",
      "('с о с т а в р а й о н а Д и т м а р ш е н <norm> . </norm> ', 'sil', 'PUNCT')\n",
      "10001\n",
      "166m 55s (- 863m 28s) (81000 16%) 0.4311\n",
      "168m 38s (- 859m 38s) (82000 16%) 0.3543\n",
      "170m 22s (- 855m 58s) (83000 16%) 0.3829\n",
      "172m 3s (- 852m 4s) (84000 16%) 0.4038\n",
      "173m 43s (- 848m 12s) (85000 17%) 0.4304\n",
      "175m 25s (- 844m 28s) (86000 17%) 0.4219\n",
      "177m 7s (- 840m 52s) (87000 17%) 0.3473\n",
      "178m 51s (- 837m 24s) (88000 17%) 0.4174\n",
      "180m 36s (- 834m 1s) (89000 17%) 0.3851\n",
      "182m 19s (- 830m 35s) (90000 18%) 0.3622\n",
      "\t\t eval accuracy: 0.292\n",
      "\t\t\t PLAIN eval error: 0.077\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.087\n",
      "\t\t\t ORDINAL eval error: 0.953\n",
      "\t\t\t MEASURE eval error: 1.000\n",
      "\t\t\t DATE eval error: 0.957\n",
      "\t\t\t ELECTRONIC eval error: 0.980\n",
      "\t\t\t CARDINAL eval error: 0.663\n",
      "\t\t\t LETTERS eval error: 0.587\n",
      "\t\t\t DECIMAL eval error: 0.953\n",
      "\t\t\t FRACTION eval error: 1.000\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.940\n",
      "\t\t\t MONEY eval error: 1.000\n",
      "\t\t\t DIGIT eval error: 0.430\n",
      "{'PLAIN': 5, 'PUNCT': 9, 'VERBATIM': 10.0, 'ORDINAL': 12.0, 'MEASURE': 12.0, 'DATE': 12.0, 'ELECTRONIC': 12.0, 'CARDINAL': 12.0, 'LETTERS': 12.0, 'DECIMAL': 12.0, 'FRACTION': 12.0, 'TELEPHONE': 12.0, 'TIME': 12.0, 'MONEY': 12.0, 'DIGIT': 11.0, '<eos>': 0.0}\n",
      "('о б щ е с о ю з н о й к у л ь т у р н о - <norm> о б р а з о в а т е л ь н о й </norm> , х у д о ж е с т в е н н о й ,', '<self>', 'PLAIN')\n",
      "('ә д б ә <norm> ј </norm> о в Р ә', 'sil', 'VERBATIM')\n",
      "10001\n",
      "187m 33s (- 842m 58s) (91000 18%) 0.3978\n",
      "189m 15s (- 839m 18s) (92000 18%) 0.3963\n",
      "190m 59s (- 835m 50s) (93000 18%) 0.3791\n",
      "192m 43s (- 832m 22s) (94000 18%) 0.3732\n",
      "194m 28s (- 829m 3s) (95000 19%) 0.3504\n",
      "196m 13s (- 825m 45s) (96000 19%) 0.3584\n",
      "197m 59s (- 822m 36s) (97000 19%) 0.3391\n",
      "199m 46s (- 819m 27s) (98000 19%) 0.3872\n",
      "201m 32s (- 816m 19s) (99000 19%) 0.3917\n",
      "203m 15s (- 813m 0s) (100000 20%) 0.3478\n",
      "\t\t eval accuracy: 0.302\n",
      "\t\t\t PLAIN eval error: 0.070\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.077\n",
      "\t\t\t ORDINAL eval error: 0.937\n",
      "\t\t\t MEASURE eval error: 0.947\n",
      "\t\t\t DATE eval error: 0.920\n",
      "\t\t\t ELECTRONIC eval error: 0.980\n",
      "\t\t\t CARDINAL eval error: 0.600\n",
      "\t\t\t LETTERS eval error: 0.517\n",
      "\t\t\t DECIMAL eval error: 0.950\n",
      "\t\t\t FRACTION eval error: 1.000\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.937\n",
      "\t\t\t MONEY eval error: 1.000\n",
      "\t\t\t DIGIT eval error: 0.537\n",
      "{'PLAIN': 5, 'PUNCT': 10, 'VERBATIM': 10.0, 'ORDINAL': 13.0, 'MEASURE': 13.0, 'DATE': 13.0, 'ELECTRONIC': 13.0, 'CARDINAL': 13.0, 'LETTERS': 13.0, 'DECIMAL': 13.0, 'FRACTION': 13.0, 'TELEPHONE': 13.0, 'TIME': 13.0, 'MONEY': 13.0, 'DIGIT': 12.0, '<eos>': 0.0}\n",
      "('1 C ) <norm> , </norm> н о о н н е', 'sil', 'PUNCT')\n",
      "('o f t h e s e v e n g i l l <norm> s h a r k </norm> N o t o r h y n c h u s c e p e d i a n u s \"', 'ш_trans а_trans р_trans к_trans', 'PLAIN')\n",
      "10001\n",
      "208m 26s (- 823m 26s) (101000 20%) 0.3515\n",
      "210m 8s (- 819m 57s) (102000 20%) 0.3500\n",
      "211m 51s (- 816m 36s) (103000 20%) 0.3597\n",
      "213m 32s (- 813m 7s) (104000 20%) 0.4077\n",
      "215m 15s (- 809m 45s) (105000 21%) 0.3095\n",
      "216m 56s (- 806m 23s) (106000 21%) 0.3740\n",
      "218m 39s (- 803m 6s) (107000 21%) 0.3681\n",
      "220m 21s (- 799m 48s) (108000 21%) 0.3079\n",
      "222m 4s (- 796m 35s) (109000 21%) 0.3096\n",
      "223m 46s (- 793m 22s) (110000 22%) 0.3037\n",
      "\t\t eval accuracy: 0.326\n",
      "\t\t\t PLAIN eval error: 0.063\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.070\n",
      "\t\t\t ORDINAL eval error: 0.907\n",
      "\t\t\t MEASURE eval error: 0.917\n",
      "\t\t\t DATE eval error: 0.910\n",
      "\t\t\t ELECTRONIC eval error: 0.980\n",
      "\t\t\t CARDINAL eval error: 0.620\n",
      "\t\t\t LETTERS eval error: 0.513\n",
      "\t\t\t DECIMAL eval error: 0.947\n",
      "\t\t\t FRACTION eval error: 0.980\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.867\n",
      "\t\t\t MONEY eval error: 1.000\n",
      "\t\t\t DIGIT eval error: 0.330\n",
      "{'PLAIN': 5, 'PUNCT': 11, 'VERBATIM': 10.0, 'ORDINAL': 14.0, 'MEASURE': 14.0, 'DATE': 14.0, 'ELECTRONIC': 14.0, 'CARDINAL': 14.0, 'LETTERS': 14.0, 'DECIMAL': 14.0, 'FRACTION': 14.0, 'TELEPHONE': 14.0, 'TIME': 14.0, 'MONEY': 14.0, 'DIGIT': 12.0, '<eos>': 0.0}\n",
      "('б и б л и о т е к а I I 7 <norm> , </norm> 2 П а в с а н и й .', 'sil', 'PUNCT')\n",
      "('В <norm> н о я б р е </norm> 2 0 1 0 г о д а М и к к и Т о м а с', '<self>', 'PLAIN')\n",
      "10001\n",
      "229m 38s (- 804m 47s) (111000 22%) 0.3036\n",
      "231m 20s (- 801m 25s) (112000 22%) 0.3697\n",
      "233m 3s (- 798m 12s) (113000 22%) 0.2757\n",
      "234m 49s (- 795m 6s) (114000 22%) 0.3158\n",
      "236m 32s (- 791m 54s) (115000 23%) 0.3032\n",
      "238m 16s (- 788m 46s) (116000 23%) 0.2661\n",
      "239m 59s (- 785m 35s) (117000 23%) 0.3380\n",
      "241m 44s (- 782m 33s) (118000 23%) 0.3281\n",
      "243m 26s (- 779m 25s) (119000 23%) 0.2999\n",
      "245m 9s (- 776m 20s) (120000 24%) 0.3247\n",
      "\t\t eval accuracy: 0.338\n",
      "\t\t\t PLAIN eval error: 0.083\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.093\n",
      "\t\t\t ORDINAL eval error: 0.890\n",
      "\t\t\t MEASURE eval error: 0.963\n",
      "\t\t\t DATE eval error: 0.830\n",
      "\t\t\t ELECTRONIC eval error: 0.980\n",
      "\t\t\t CARDINAL eval error: 0.547\n",
      "\t\t\t LETTERS eval error: 0.410\n",
      "\t\t\t DECIMAL eval error: 0.937\n",
      "\t\t\t FRACTION eval error: 0.990\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.863\n",
      "\t\t\t MONEY eval error: 1.000\n",
      "\t\t\t DIGIT eval error: 0.337\n",
      "{'PLAIN': 6, 'PUNCT': 12, 'VERBATIM': 11.0, 'ORDINAL': 15.0, 'MEASURE': 15.0, 'DATE': 15.0, 'ELECTRONIC': 15.0, 'CARDINAL': 15.0, 'LETTERS': 14.0, 'DECIMAL': 15.0, 'FRACTION': 15.0, 'TELEPHONE': 15.0, 'TIME': 15.0, 'MONEY': 15.0, 'DIGIT': 13.0, '<eos>': 0.0}\n",
      "('D a v i d A . B a u m <norm> : </norm> T h e C o m p a r a t i v e P o l l i n a t i o n', 'sil', 'PUNCT')\n",
      "('в х о д е н е м е ц к о г о <norm> н а с т у п л е н и я </norm> Ч о р т к о в б ы л о к к у п и р о в а н', '<self>', 'PLAIN')\n",
      "10001\n",
      "250m 26s (- 784m 27s) (121000 24%) 0.2959\n",
      "252m 9s (- 781m 16s) (122000 24%) 0.2857\n",
      "253m 52s (- 778m 9s) (123000 24%) 0.3062\n",
      "255m 35s (- 775m 2s) (124000 24%) 0.2954\n",
      "257m 18s (- 771m 54s) (125000 25%) 0.3311\n",
      "259m 0s (- 768m 48s) (126000 25%) 0.2993\n",
      "260m 45s (- 765m 50s) (127000 25%) 0.2425\n",
      "262m 28s (- 762m 48s) (128000 25%) 0.2726\n",
      "264m 12s (- 759m 50s) (129000 25%) 0.2413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265m 54s (- 756m 49s) (130000 26%) 0.3100\n",
      "\t\t eval accuracy: 0.354\n",
      "\t\t\t PLAIN eval error: 0.067\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.063\n",
      "\t\t\t ORDINAL eval error: 0.853\n",
      "\t\t\t MEASURE eval error: 0.897\n",
      "\t\t\t DATE eval error: 0.727\n",
      "\t\t\t ELECTRONIC eval error: 0.980\n",
      "\t\t\t CARDINAL eval error: 0.550\n",
      "\t\t\t LETTERS eval error: 0.393\n",
      "\t\t\t DECIMAL eval error: 0.933\n",
      "\t\t\t FRACTION eval error: 0.983\n",
      "\t\t\t TELEPHONE eval error: 0.993\n",
      "\t\t\t TIME eval error: 0.860\n",
      "\t\t\t MONEY eval error: 1.000\n",
      "\t\t\t DIGIT eval error: 0.387\n",
      "{'PLAIN': 7, 'PUNCT': 13, 'VERBATIM': 11.0, 'ORDINAL': 16.0, 'MEASURE': 16.0, 'DATE': 16.0, 'ELECTRONIC': 16.0, 'CARDINAL': 16.0, 'LETTERS': 14.0, 'DECIMAL': 16.0, 'FRACTION': 16.0, 'TELEPHONE': 16.0, 'TIME': 16.0, 'MONEY': 16.0, 'DIGIT': 14.0, '<eos>': 0.0}\n",
      "('<norm> К р о м е </norm> т о г о о н р а б о т а л', '<self>', 'PLAIN')\n",
      "(', A n t o z z i C <norm> , </norm> e t a l .', 'sil', 'PUNCT')\n",
      "10001\n",
      "271m 14s (- 764m 3s) (131000 26%) 0.2585\n",
      "273m 1s (- 761m 8s) (132000 26%) 0.2699\n",
      "274m 46s (- 758m 13s) (133000 26%) 0.2693\n",
      "276m 31s (- 755m 16s) (134000 26%) 0.3005\n",
      "278m 19s (- 752m 29s) (135000 27%) 0.2828\n",
      "280m 3s (- 749m 34s) (136000 27%) 0.2627\n",
      "281m 49s (- 746m 43s) (137000 27%) 0.2541\n",
      "283m 36s (- 743m 56s) (138000 27%) 0.2698\n",
      "285m 20s (- 741m 4s) (139000 27%) 0.3001\n",
      "287m 3s (- 738m 8s) (140000 28%) 0.2699\n",
      "\t\t eval accuracy: 0.375\n",
      "\t\t\t PLAIN eval error: 0.067\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.083\n",
      "\t\t\t ORDINAL eval error: 0.847\n",
      "\t\t\t MEASURE eval error: 0.850\n",
      "\t\t\t DATE eval error: 0.693\n",
      "\t\t\t ELECTRONIC eval error: 0.980\n",
      "\t\t\t CARDINAL eval error: 0.473\n",
      "\t\t\t LETTERS eval error: 0.423\n",
      "\t\t\t DECIMAL eval error: 0.927\n",
      "\t\t\t FRACTION eval error: 0.980\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.710\n",
      "\t\t\t MONEY eval error: 1.000\n",
      "\t\t\t DIGIT eval error: 0.337\n",
      "{'PLAIN': 8, 'PUNCT': 14, 'VERBATIM': 12.0, 'ORDINAL': 17.0, 'MEASURE': 17.0, 'DATE': 17.0, 'ELECTRONIC': 17.0, 'CARDINAL': 16.0, 'LETTERS': 15.0, 'DECIMAL': 17.0, 'FRACTION': 17.0, 'TELEPHONE': 17.0, 'TIME': 17.0, 'MONEY': 17.0, 'DIGIT': 15.0, '<eos>': 0.0}\n",
      "('и е г о ж е н а <norm> , </norm> д у м а ю щ а я , ч т о', 'sil', 'PUNCT')\n",
      "('<norm> Н е </norm> в ы з в а л а е г о п р е т е н з и й', '<self>', 'PLAIN')\n",
      "10001\n",
      "292m 20s (- 744m 19s) (141000 28%) 0.2659\n",
      "294m 6s (- 741m 28s) (142000 28%) 0.2755\n",
      "295m 48s (- 738m 30s) (143000 28%) 0.2448\n",
      "297m 32s (- 735m 35s) (144000 28%) 0.2327\n",
      "299m 17s (- 732m 44s) (145000 28%) 0.2872\n",
      "301m 0s (- 729m 49s) (146000 29%) 0.2408\n",
      "302m 45s (- 727m 2s) (147000 29%) 0.2634\n",
      "304m 29s (- 724m 12s) (148000 29%) 0.2540\n",
      "306m 14s (- 721m 24s) (149000 29%) 0.2052\n",
      "307m 58s (- 718m 35s) (150000 30%) 0.2426\n",
      "\t\t eval accuracy: 0.376\n",
      "\t\t\t PLAIN eval error: 0.067\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.063\n",
      "\t\t\t ORDINAL eval error: 0.823\n",
      "\t\t\t MEASURE eval error: 0.860\n",
      "\t\t\t DATE eval error: 0.667\n",
      "\t\t\t ELECTRONIC eval error: 0.980\n",
      "\t\t\t CARDINAL eval error: 0.507\n",
      "\t\t\t LETTERS eval error: 0.380\n",
      "\t\t\t DECIMAL eval error: 0.960\n",
      "\t\t\t FRACTION eval error: 0.970\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.773\n",
      "\t\t\t MONEY eval error: 0.997\n",
      "\t\t\t DIGIT eval error: 0.317\n",
      "{'PLAIN': 9, 'PUNCT': 15, 'VERBATIM': 13.0, 'ORDINAL': 18.0, 'MEASURE': 18.0, 'DATE': 18.0, 'ELECTRONIC': 18.0, 'CARDINAL': 17.0, 'LETTERS': 15.0, 'DECIMAL': 18.0, 'FRACTION': 18.0, 'TELEPHONE': 18.0, 'TIME': 18.0, 'MONEY': 18.0, 'DIGIT': 15.0, '<eos>': 0.0}\n",
      "('В ы с т у п л е н и е н а I <norm> В с е с о с ю з н ы х </norm> Ш а г а л о в с к и х д н я х в', '<self>', 'PLAIN')\n",
      "('( 5 а п р е л я 2 0 0 9 ) <norm> . </norm> ', 'sil', 'PUNCT')\n",
      "10001\n",
      "313m 11s (- 723m 51s) (151000 30%) 0.2728\n",
      "314m 57s (- 721m 5s) (152000 30%) 0.2488\n",
      "316m 44s (- 718m 22s) (153000 30%) 0.1728\n",
      "318m 30s (- 715m 37s) (154000 30%) 0.2252\n",
      "320m 17s (- 712m 54s) (155000 31%) 0.2243\n",
      "322m 2s (- 710m 8s) (156000 31%) 0.2421\n",
      "323m 46s (- 707m 21s) (157000 31%) 0.2598\n",
      "325m 33s (- 704m 40s) (158000 31%) 0.2459\n",
      "327m 18s (- 701m 57s) (159000 31%) 0.2494\n",
      "329m 1s (- 699m 9s) (160000 32%) 0.2471\n",
      "\t\t eval accuracy: 0.373\n",
      "\t\t\t PLAIN eval error: 0.067\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.057\n",
      "\t\t\t ORDINAL eval error: 0.773\n",
      "\t\t\t MEASURE eval error: 0.823\n",
      "\t\t\t DATE eval error: 0.613\n",
      "\t\t\t ELECTRONIC eval error: 0.977\n",
      "\t\t\t CARDINAL eval error: 0.470\n",
      "\t\t\t LETTERS eval error: 0.367\n",
      "\t\t\t DECIMAL eval error: 0.903\n",
      "\t\t\t FRACTION eval error: 0.990\n",
      "\t\t\t TELEPHONE eval error: 0.997\n",
      "\t\t\t TIME eval error: 0.727\n",
      "\t\t\t MONEY eval error: 0.993\n",
      "\t\t\t DIGIT eval error: 0.647\n",
      "{'PLAIN': 10, 'PUNCT': 16, 'VERBATIM': 13.0, 'ORDINAL': 19.0, 'MEASURE': 19.0, 'DATE': 19.0, 'ELECTRONIC': 19.0, 'CARDINAL': 17.0, 'LETTERS': 15.0, 'DECIMAL': 19.0, 'FRACTION': 19.0, 'TELEPHONE': 19.0, 'TIME': 19.0, 'MONEY': 19.0, 'DIGIT': 16.0, '<eos>': 0.0}\n",
      "('Н а с т у п и л о т н о с и т е л ь н о с п о к о й н ы й <norm> и </norm> с а м ы й п л о д о т в о р н ы й п е р и о д', '<self>', 'PLAIN')\n",
      "('М а н ь о — т и т у л я р н а я <norm> ц е р к о в ь </norm> н а Ц е л и и ,', '<self>', 'PLAIN')\n",
      "10001\n",
      "334m 23s (- 704m 4s) (161000 32%) 0.2225\n",
      "336m 6s (- 701m 16s) (162000 32%) 0.2225\n",
      "337m 51s (- 698m 30s) (163000 32%) 0.2546\n",
      "339m 35s (- 695m 45s) (164000 32%) 0.2172\n",
      "341m 21s (- 693m 3s) (165000 33%) 0.2253\n",
      "343m 5s (- 690m 19s) (166000 33%) 0.2509\n",
      "344m 51s (- 687m 39s) (167000 33%) 0.2499\n",
      "346m 36s (- 684m 58s) (168000 33%) 0.2681\n",
      "348m 22s (- 682m 18s) (169000 33%) 0.2682\n",
      "350m 5s (- 679m 34s) (170000 34%) 0.2364\n",
      "\t\t eval accuracy: 0.367\n",
      "\t\t\t PLAIN eval error: 0.063\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.087\n",
      "\t\t\t ORDINAL eval error: 0.757\n",
      "\t\t\t MEASURE eval error: 0.903\n",
      "\t\t\t DATE eval error: 0.617\n",
      "\t\t\t ELECTRONIC eval error: 0.980\n",
      "\t\t\t CARDINAL eval error: 0.503\n",
      "\t\t\t LETTERS eval error: 0.423\n",
      "\t\t\t DECIMAL eval error: 0.927\n",
      "\t\t\t FRACTION eval error: 0.987\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.693\n",
      "\t\t\t MONEY eval error: 0.980\n",
      "\t\t\t DIGIT eval error: 0.580\n",
      "{'PLAIN': 11, 'PUNCT': 17, 'VERBATIM': 14.0, 'ORDINAL': 20.0, 'MEASURE': 20.0, 'DATE': 20.0, 'ELECTRONIC': 20.0, 'CARDINAL': 18.0, 'LETTERS': 16.0, 'DECIMAL': 20.0, 'FRACTION': 20.0, 'TELEPHONE': 20.0, 'TIME': 20.0, 'MONEY': 20.0, 'DIGIT': 17.0, '<eos>': 0.0}\n",
      "('Ч о н н а м Д р э г о н з » <norm> — </norm> ю ж н о к о р е й с к и й ф у т б о л ь н ы й к л у б', 'sil', 'PUNCT')\n",
      "('с е м е й с т в о М а к Б е й н о в и <norm> и х </norm> д р у з е й о т п р а в л я е т с я н а', '<self>', 'PLAIN')\n",
      "10001\n",
      "355m 17s (- 683m 35s) (171000 34%) 0.2700\n",
      "357m 4s (- 680m 55s) (172000 34%) 0.2162\n",
      "358m 51s (- 678m 18s) (173000 34%) 0.2176\n",
      "Setting new learning rate to 0.00316\n",
      "360m 37s (- 675m 38s) (174000 34%) 0.2198\n",
      "362m 23s (- 673m 1s) (175000 35%) 0.2301\n",
      "364m 9s (- 670m 22s) (176000 35%) 0.1783\n",
      "365m 53s (- 667m 42s) (177000 35%) 0.1886\n",
      "367m 37s (- 665m 2s) (178000 35%) 0.1998\n",
      "Setting new learning rate to 0.00100\n",
      "369m 25s (- 662m 29s) (179000 35%) 0.2000\n",
      "371m 9s (- 659m 49s) (180000 36%) 0.1854\n",
      "\t\t eval accuracy: 0.450\n",
      "\t\t\t PLAIN eval error: 0.067\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.047\n",
      "\t\t\t ORDINAL eval error: 0.657\n",
      "\t\t\t MEASURE eval error: 0.770\n",
      "\t\t\t DATE eval error: 0.497\n",
      "\t\t\t ELECTRONIC eval error: 0.980\n",
      "\t\t\t CARDINAL eval error: 0.370\n",
      "\t\t\t LETTERS eval error: 0.303\n",
      "\t\t\t DECIMAL eval error: 0.880\n",
      "\t\t\t FRACTION eval error: 0.960\n",
      "\t\t\t TELEPHONE eval error: 0.997\n",
      "\t\t\t TIME eval error: 0.547\n",
      "\t\t\t MONEY eval error: 0.967\n",
      "\t\t\t DIGIT eval error: 0.213\n",
      "{'PLAIN': 12, 'PUNCT': 18, 'VERBATIM': 14.0, 'ORDINAL': 21.0, 'MEASURE': 21.0, 'DATE': 20.0, 'ELECTRONIC': 21.0, 'CARDINAL': 18.0, 'LETTERS': 16.0, 'DECIMAL': 21.0, 'FRACTION': 21.0, 'TELEPHONE': 21.0, 'TIME': 21.0, 'MONEY': 21.0, 'DIGIT': 17.0, '<eos>': 0.0}\n",
      "('з а к р ы т и е м л и н и й , <norm> п о з в о л и л а </norm> о т к а з а т ь с я C I E о т', '<self>', 'PLAIN')\n",
      "('П е р е в о д с н е м е ц к о г о <norm> В . </norm> М е ж е в и ч а . ', 'в', 'LETTERS')\n",
      "10001\n",
      "376m 29s (- 663m 33s) (181000 36%) 0.1778\n",
      "378m 15s (- 660m 55s) (182000 36%) 0.1890\n",
      "379m 59s (- 658m 14s) (183000 36%) 0.1868\n",
      "Setting new learning rate to 0.00032\n",
      "381m 43s (- 655m 34s) (184000 36%) 0.1888\n",
      "383m 29s (- 652m 57s) (185000 37%) 0.1567\n",
      "385m 12s (- 650m 17s) (186000 37%) 0.1923\n",
      "386m 57s (- 647m 41s) (187000 37%) 0.1599\n",
      "388m 44s (- 645m 8s) (188000 37%) 0.2057\n",
      "390m 29s (- 642m 32s) (189000 37%) 0.1664\n",
      "392m 14s (- 639m 57s) (190000 38%) 0.1932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t eval accuracy: 0.456\n",
      "\t\t\t PLAIN eval error: 0.063\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.043\n",
      "\t\t\t ORDINAL eval error: 0.667\n",
      "\t\t\t MEASURE eval error: 0.763\n",
      "\t\t\t DATE eval error: 0.490\n",
      "\t\t\t ELECTRONIC eval error: 0.980\n",
      "\t\t\t CARDINAL eval error: 0.373\n",
      "\t\t\t LETTERS eval error: 0.297\n",
      "\t\t\t DECIMAL eval error: 0.857\n",
      "\t\t\t FRACTION eval error: 0.947\n",
      "\t\t\t TELEPHONE eval error: 0.997\n",
      "\t\t\t TIME eval error: 0.520\n",
      "\t\t\t MONEY eval error: 0.973\n",
      "\t\t\t DIGIT eval error: 0.187\n",
      "{'PLAIN': 13, 'PUNCT': 19, 'VERBATIM': 14.0, 'ORDINAL': 22.0, 'MEASURE': 22.0, 'DATE': 20.0, 'ELECTRONIC': 22.0, 'CARDINAL': 19.0, 'LETTERS': 16.0, 'DECIMAL': 22.0, 'FRACTION': 22.0, 'TELEPHONE': 22.0, 'TIME': 22.0, 'MONEY': 22.0, 'DIGIT': 17.0, '<eos>': 0.0}\n",
      "('В 1 9 7 5 г о д у в <norm> д н е в н и к а х </norm> Б ы к о в а п о я в л я е т с я з а п и с ь', '<self>', 'PLAIN')\n",
      "('в Д н е п р о п е т р о в с к и й г о с у д а р с т в е н н ы й <norm> У н и в е р с и т е т </norm> н а ф и з и к о -', '<self>', 'PLAIN')\n",
      "10001\n",
      "397m 31s (- 643m 7s) (191000 38%) 0.1751\n",
      "399m 17s (- 640m 31s) (192000 38%) 0.1919\n",
      "401m 2s (- 637m 55s) (193000 38%) 0.1748\n",
      "402m 47s (- 635m 19s) (194000 38%) 0.2062\n",
      "404m 35s (- 632m 49s) (195000 39%) 0.2154\n",
      "406m 22s (- 630m 18s) (196000 39%) 0.1731\n",
      "408m 8s (- 627m 44s) (197000 39%) 0.1543\n",
      "409m 55s (- 625m 13s) (198000 39%) 0.1754\n",
      "411m 43s (- 622m 45s) (199000 39%) 0.1523\n",
      "413m 29s (- 620m 14s) (200000 40%) 0.1991\n",
      "\t\t eval accuracy: 0.467\n",
      "\t\t\t PLAIN eval error: 0.060\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.043\n",
      "\t\t\t ORDINAL eval error: 0.650\n",
      "\t\t\t MEASURE eval error: 0.743\n",
      "\t\t\t DATE eval error: 0.480\n",
      "\t\t\t ELECTRONIC eval error: 0.977\n",
      "\t\t\t CARDINAL eval error: 0.343\n",
      "\t\t\t LETTERS eval error: 0.283\n",
      "\t\t\t DECIMAL eval error: 0.863\n",
      "\t\t\t FRACTION eval error: 0.933\n",
      "\t\t\t TELEPHONE eval error: 0.997\n",
      "\t\t\t TIME eval error: 0.483\n",
      "\t\t\t MONEY eval error: 0.953\n",
      "\t\t\t DIGIT eval error: 0.180\n",
      "{'PLAIN': 13, 'PUNCT': 20, 'VERBATIM': 15.0, 'ORDINAL': 23.0, 'MEASURE': 23.0, 'DATE': 20.0, 'ELECTRONIC': 23.0, 'CARDINAL': 19.0, 'LETTERS': 16.0, 'DECIMAL': 23.0, 'FRACTION': 23.0, 'TELEPHONE': 23.0, 'TIME': 22.0, 'MONEY': 23.0, 'DIGIT': 17.0, '<eos>': 0.0}\n",
      "('М о с к о в с к и й д о м ф о т о г р а ф и и <norm> . </norm> ', 'sil', 'PUNCT')\n",
      "('п р е д п о л о ж е н и е , ч т о <norm> д а н н ы й </norm> к р а т е р я в л я е т с я к р у п н е й ш и м', '<self>', 'PLAIN')\n",
      "10001\n",
      "418m 47s (- 622m 59s) (201000 40%) 0.1950\n",
      "420m 33s (- 620m 25s) (202000 40%) 0.1488\n",
      "422m 18s (- 617m 52s) (203000 40%) 0.1926\n",
      "424m 4s (- 615m 19s) (204000 40%) 0.1528\n",
      "425m 50s (- 612m 48s) (205000 41%) 0.1996\n",
      "427m 34s (- 610m 13s) (206000 41%) 0.1750\n",
      "429m 21s (- 607m 43s) (207000 41%) 0.1917\n",
      "431m 7s (- 605m 14s) (208000 41%) 0.1807\n",
      "432m 52s (- 602m 42s) (209000 41%) 0.1806\n",
      "434m 36s (- 600m 10s) (210000 42%) 0.1525\n",
      "\t\t eval accuracy: 0.466\n",
      "\t\t\t PLAIN eval error: 0.060\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.050\n",
      "\t\t\t ORDINAL eval error: 0.650\n",
      "\t\t\t MEASURE eval error: 0.740\n",
      "\t\t\t DATE eval error: 0.483\n",
      "\t\t\t ELECTRONIC eval error: 0.980\n",
      "\t\t\t CARDINAL eval error: 0.353\n",
      "\t\t\t LETTERS eval error: 0.297\n",
      "\t\t\t DECIMAL eval error: 0.853\n",
      "\t\t\t FRACTION eval error: 0.937\n",
      "\t\t\t TELEPHONE eval error: 0.993\n",
      "\t\t\t TIME eval error: 0.477\n",
      "\t\t\t MONEY eval error: 0.960\n",
      "\t\t\t DIGIT eval error: 0.173\n",
      "{'PLAIN': 14, 'PUNCT': 21, 'VERBATIM': 16.0, 'ORDINAL': 24.0, 'MEASURE': 24.0, 'DATE': 21.0, 'ELECTRONIC': 24.0, 'CARDINAL': 20.0, 'LETTERS': 17.0, 'DECIMAL': 24.0, 'FRACTION': 24.0, 'TELEPHONE': 24.0, 'TIME': 22.0, 'MONEY': 24.0, 'DIGIT': 17.0, '<eos>': 0.0}\n",
      "('г и г о с е и о н и <norm> е д у т </norm> н а п о л е б о я', '<self>', 'PLAIN')\n",
      "('« Е с л и в ы <norm> к о т е н о к </norm> » , м у з ы к а', '<self>', 'PLAIN')\n",
      "10001\n",
      "439m 51s (- 602m 28s) (211000 42%) 0.1838\n",
      "441m 38s (- 599m 57s) (212000 42%) 0.1735\n",
      "443m 24s (- 597m 27s) (213000 42%) 0.2011\n",
      "445m 12s (- 594m 59s) (214000 42%) 0.1493\n",
      "447m 0s (- 592m 32s) (215000 43%) 0.1999\n",
      "448m 46s (- 590m 3s) (216000 43%) 0.1622\n",
      "450m 33s (- 587m 35s) (217000 43%) 0.1716\n",
      "452m 21s (- 585m 9s) (218000 43%) 0.1517\n",
      "454m 9s (- 582m 44s) (219000 43%) 0.1988\n",
      "455m 57s (- 580m 18s) (220000 44%) 0.1675\n",
      "\t\t eval accuracy: 0.471\n",
      "\t\t\t PLAIN eval error: 0.060\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.050\n",
      "\t\t\t ORDINAL eval error: 0.643\n",
      "\t\t\t MEASURE eval error: 0.720\n",
      "\t\t\t DATE eval error: 0.490\n",
      "\t\t\t ELECTRONIC eval error: 0.977\n",
      "\t\t\t CARDINAL eval error: 0.337\n",
      "\t\t\t LETTERS eval error: 0.293\n",
      "\t\t\t DECIMAL eval error: 0.843\n",
      "\t\t\t FRACTION eval error: 0.943\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.460\n",
      "\t\t\t MONEY eval error: 0.950\n",
      "\t\t\t DIGIT eval error: 0.167\n",
      "{'PLAIN': 15, 'PUNCT': 22, 'VERBATIM': 17.0, 'ORDINAL': 25.0, 'MEASURE': 25.0, 'DATE': 22.0, 'ELECTRONIC': 25.0, 'CARDINAL': 20.0, 'LETTERS': 18.0, 'DECIMAL': 25.0, 'FRACTION': 25.0, 'TELEPHONE': 25.0, 'TIME': 22.0, 'MONEY': 25.0, 'DIGIT': 17.0, '<eos>': 0.0}\n",
      "('— 3 1 . 1 2 . 1 9 7 0 ) <norm> — </norm> н а в о д ч и к м и н о м е т а 6 4 1 - г о', 'sil', 'PUNCT')\n",
      "('с м е с ь х а р д - <norm> р о к а </norm> , ф а н к а и', '<self>', 'PLAIN')\n",
      "10001\n",
      "461m 17s (- 582m 21s) (221000 44%) 0.1825\n",
      "463m 3s (- 579m 52s) (222000 44%) 0.1666\n",
      "464m 49s (- 577m 23s) (223000 44%) 0.1852\n",
      "466m 35s (- 574m 54s) (224000 44%) 0.1891\n",
      "468m 19s (- 572m 23s) (225000 45%) 0.1681\n",
      "470m 5s (- 569m 56s) (226000 45%) 0.1803\n",
      "471m 50s (- 567m 26s) (227000 45%) 0.1653\n",
      "473m 34s (- 564m 57s) (228000 45%) 0.1577\n",
      "475m 19s (- 562m 29s) (229000 45%) 0.1940\n",
      "477m 5s (- 560m 3s) (230000 46%) 0.1733\n",
      "\t\t eval accuracy: 0.470\n",
      "\t\t\t PLAIN eval error: 0.057\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.043\n",
      "\t\t\t ORDINAL eval error: 0.640\n",
      "\t\t\t MEASURE eval error: 0.710\n",
      "\t\t\t DATE eval error: 0.487\n",
      "\t\t\t ELECTRONIC eval error: 0.977\n",
      "\t\t\t CARDINAL eval error: 0.350\n",
      "\t\t\t LETTERS eval error: 0.290\n",
      "\t\t\t DECIMAL eval error: 0.847\n",
      "\t\t\t FRACTION eval error: 0.950\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.473\n",
      "\t\t\t MONEY eval error: 0.957\n",
      "\t\t\t DIGIT eval error: 0.177\n",
      "{'PLAIN': 15, 'PUNCT': 23, 'VERBATIM': 18.0, 'ORDINAL': 26.0, 'MEASURE': 26.0, 'DATE': 23.0, 'ELECTRONIC': 26.0, 'CARDINAL': 21.0, 'LETTERS': 19.0, 'DECIMAL': 26.0, 'FRACTION': 26.0, 'TELEPHONE': 26.0, 'TIME': 23.0, 'MONEY': 26.0, 'DIGIT': 18.0, '<eos>': 0.0}\n",
      "('p e r s o n a l b i o g r a p h y T a y l o r <norm> W a n e </norm> ( 2 0 1 3 )', 'у_trans о_trans н_trans', 'PLAIN')\n",
      "('о ч е н ь с и л ь н о е в л и я н и е <norm> н а </norm> с т а н о в л е н и е л и ч н о с т и М о р а в и а', '<self>', 'PLAIN')\n",
      "10001\n",
      "482m 23s (- 561m 44s) (231000 46%) 0.1959\n",
      "484m 11s (- 559m 19s) (232000 46%) 0.1585\n",
      "485m 57s (- 556m 52s) (233000 46%) 0.1803\n",
      "487m 44s (- 554m 26s) (234000 46%) 0.1851\n",
      "489m 32s (- 552m 1s) (235000 47%) 0.1913\n",
      "491m 18s (- 549m 36s) (236000 47%) 0.1544\n",
      "493m 5s (- 547m 11s) (237000 47%) 0.2011\n",
      "Setting new learning rate to 0.00010\n",
      "494m 51s (- 544m 45s) (238000 47%) 0.1617\n",
      "496m 37s (- 542m 20s) (239000 47%) 0.1677\n",
      "498m 23s (- 539m 55s) (240000 48%) 0.2074\n",
      "\t\t eval accuracy: 0.474\n",
      "\t\t\t PLAIN eval error: 0.057\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.047\n",
      "\t\t\t ORDINAL eval error: 0.637\n",
      "\t\t\t MEASURE eval error: 0.720\n",
      "\t\t\t DATE eval error: 0.480\n",
      "\t\t\t ELECTRONIC eval error: 0.980\n",
      "\t\t\t CARDINAL eval error: 0.343\n",
      "\t\t\t LETTERS eval error: 0.283\n",
      "\t\t\t DECIMAL eval error: 0.827\n",
      "\t\t\t FRACTION eval error: 0.933\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.457\n",
      "\t\t\t MONEY eval error: 0.957\n",
      "\t\t\t DIGIT eval error: 0.173\n",
      "{'PLAIN': 16, 'PUNCT': 24, 'VERBATIM': 19.0, 'ORDINAL': 27.0, 'MEASURE': 27.0, 'DATE': 24.0, 'ELECTRONIC': 27.0, 'CARDINAL': 22.0, 'LETTERS': 20.0, 'DECIMAL': 27.0, 'FRACTION': 27.0, 'TELEPHONE': 27.0, 'TIME': 23.0, 'MONEY': 27.0, 'DIGIT': 19.0, '<eos>': 0.0}\n",
      "('R e a l M a d r i d о т <norm> 4 </norm> - 1 A t l', 'четырех', 'CARDINAL')\n",
      "('м е с т о с с о с т о я н и е м <norm> 7 0 0 м л н д о л л а р о в С Ш А </norm> . ', 'семисот миллионов долларов сэ ш а', 'MONEY')\n",
      "10001\n",
      "503m 42s (- 541m 19s) (241000 48%) 0.1522\n",
      "505m 28s (- 538m 53s) (242000 48%) 0.1682\n",
      "Setting new learning rate to 0.00003\n",
      "507m 13s (- 536m 27s) (243000 48%) 0.1545\n",
      "508m 59s (- 534m 1s) (244000 48%) 0.1540\n",
      "510m 45s (- 531m 36s) (245000 49%) 0.2334\n",
      "512m 29s (- 529m 9s) (246000 49%) 0.1897\n",
      "514m 14s (- 526m 43s) (247000 49%) 0.1529\n",
      "Setting new learning rate to 0.00001\n",
      "515m 57s (- 524m 17s) (248000 49%) 0.1420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517m 44s (- 521m 53s) (249000 49%) 0.1773\n",
      "519m 29s (- 519m 29s) (250000 50%) 0.1632\n",
      "\t\t eval accuracy: 0.473\n",
      "\t\t\t PLAIN eval error: 0.060\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.047\n",
      "\t\t\t ORDINAL eval error: 0.640\n",
      "\t\t\t MEASURE eval error: 0.717\n",
      "\t\t\t DATE eval error: 0.467\n",
      "\t\t\t ELECTRONIC eval error: 0.980\n",
      "\t\t\t CARDINAL eval error: 0.343\n",
      "\t\t\t LETTERS eval error: 0.277\n",
      "\t\t\t DECIMAL eval error: 0.850\n",
      "\t\t\t FRACTION eval error: 0.947\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.450\n",
      "\t\t\t MONEY eval error: 0.960\n",
      "\t\t\t DIGIT eval error: 0.163\n",
      "{'PLAIN': 17, 'PUNCT': 25, 'VERBATIM': 20.0, 'ORDINAL': 28.0, 'MEASURE': 28.0, 'DATE': 24.0, 'ELECTRONIC': 28.0, 'CARDINAL': 23.0, 'LETTERS': 20.0, 'DECIMAL': 28.0, 'FRACTION': 28.0, 'TELEPHONE': 28.0, 'TIME': 23.0, 'MONEY': 28.0, 'DIGIT': 19.0, '<eos>': 0.0}\n",
      "('П р е з и д и у м а б ы л Т и т о <norm> , </norm> з а н и м а в ш и й п о с т п о ж и з н е н н о г о', 'sil', 'PUNCT')\n",
      "('в х о д и т в с о с т а в <norm> г о р о д с к о г о </norm> п о с е л е н и я Ф р я н о в о .', '<self>', 'PLAIN')\n",
      "10001\n",
      "524m 49s (- 520m 38s) (251000 50%) 0.1822\n",
      "526m 34s (- 518m 13s) (252000 50%) 0.2404\n",
      "528m 23s (- 515m 51s) (253000 50%) 0.1863\n",
      "530m 9s (- 513m 27s) (254000 50%) 0.1604\n",
      "531m 56s (- 511m 5s) (255000 51%) 0.1530\n",
      "533m 42s (- 508m 41s) (256000 51%) 0.1418\n",
      "535m 28s (- 506m 18s) (257000 51%) 0.1828\n",
      "537m 17s (- 503m 58s) (258000 51%) 0.2282\n",
      "539m 3s (- 501m 35s) (259000 51%) 0.1691\n",
      "540m 49s (- 499m 13s) (260000 52%) 0.1876\n",
      "\t\t eval accuracy: 0.474\n",
      "\t\t\t PLAIN eval error: 0.060\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.047\n",
      "\t\t\t ORDINAL eval error: 0.640\n",
      "\t\t\t MEASURE eval error: 0.720\n",
      "\t\t\t DATE eval error: 0.477\n",
      "\t\t\t ELECTRONIC eval error: 0.977\n",
      "\t\t\t CARDINAL eval error: 0.340\n",
      "\t\t\t LETTERS eval error: 0.283\n",
      "\t\t\t DECIMAL eval error: 0.827\n",
      "\t\t\t FRACTION eval error: 0.947\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.447\n",
      "\t\t\t MONEY eval error: 0.960\n",
      "\t\t\t DIGIT eval error: 0.167\n",
      "{'PLAIN': 18, 'PUNCT': 26, 'VERBATIM': 21.0, 'ORDINAL': 29.0, 'MEASURE': 29.0, 'DATE': 25.0, 'ELECTRONIC': 29.0, 'CARDINAL': 24.0, 'LETTERS': 21.0, 'DECIMAL': 29.0, 'FRACTION': 29.0, 'TELEPHONE': 29.0, 'TIME': 23.0, 'MONEY': 29.0, 'DIGIT': 20.0, '<eos>': 0.0}\n",
      "('н а с е л е н и я , в о з в о д я т с я <norm> а д м и н и с т р а т и в н ы е </norm> з д а н и я . ', '<self>', 'PLAIN')\n",
      "('ф р а н к а п о с т е п е н н о с н и ж а е т с я <norm> , </norm> у с т у п а я т о к -', 'sil', 'PUNCT')\n",
      "10001\n",
      "546m 7s (- 500m 5s) (261000 52%) 0.1711\n",
      "547m 52s (- 497m 41s) (262000 52%) 0.1821\n",
      "549m 36s (- 495m 16s) (263000 52%) 0.1805\n",
      "551m 24s (- 492m 55s) (264000 52%) 0.1958\n",
      "553m 8s (- 490m 31s) (265000 53%) 0.1899\n",
      "554m 53s (- 488m 8s) (266000 53%) 0.1742\n",
      "556m 39s (- 485m 46s) (267000 53%) 0.1523\n",
      "558m 23s (- 483m 22s) (268000 53%) 0.1834\n",
      "560m 8s (- 481m 0s) (269000 53%) 0.2229\n",
      "561m 55s (- 478m 40s) (270000 54%) 0.2193\n",
      "\t\t eval accuracy: 0.476\n",
      "\t\t\t PLAIN eval error: 0.060\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.043\n",
      "\t\t\t ORDINAL eval error: 0.637\n",
      "\t\t\t MEASURE eval error: 0.727\n",
      "\t\t\t DATE eval error: 0.463\n",
      "\t\t\t ELECTRONIC eval error: 0.977\n",
      "\t\t\t CARDINAL eval error: 0.340\n",
      "\t\t\t LETTERS eval error: 0.290\n",
      "\t\t\t DECIMAL eval error: 0.830\n",
      "\t\t\t FRACTION eval error: 0.940\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.440\n",
      "\t\t\t MONEY eval error: 0.957\n",
      "\t\t\t DIGIT eval error: 0.163\n",
      "{'PLAIN': 19, 'PUNCT': 27, 'VERBATIM': 22.0, 'ORDINAL': 30.0, 'MEASURE': 30.0, 'DATE': 25.0, 'ELECTRONIC': 30.0, 'CARDINAL': 25.0, 'LETTERS': 22.0, 'DECIMAL': 30.0, 'FRACTION': 30.0, 'TELEPHONE': 30.0, 'TIME': 23.0, 'MONEY': 30.0, 'DIGIT': 21.0, '<eos>': 0.0}\n",
      "('с е г о д н я : И в а н <norm> Д о р н </norm> . ', '<self>', 'PLAIN')\n",
      "('и л и п о д к а р н и з а м и <norm> з д а н и й </norm> . ', '<self>', 'PLAIN')\n",
      "10001\n",
      "567m 15s (- 479m 20s) (271000 54%) 0.1967\n",
      "569m 5s (- 477m 1s) (272000 54%) 0.1694\n",
      "570m 51s (- 474m 40s) (273000 54%) 0.1968\n",
      "572m 39s (- 472m 20s) (274000 54%) 0.1695\n",
      "574m 26s (- 469m 59s) (275000 55%) 0.1531\n",
      "576m 13s (- 467m 39s) (276000 55%) 0.2030\n",
      "577m 58s (- 465m 17s) (277000 55%) 0.1550\n",
      "579m 43s (- 462m 57s) (278000 55%) 0.1681\n",
      "581m 31s (- 460m 37s) (279000 55%) 0.1956\n",
      "583m 16s (- 458m 17s) (280000 56%) 0.1456\n",
      "\t\t eval accuracy: 0.475\n",
      "\t\t\t PLAIN eval error: 0.060\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.043\n",
      "\t\t\t ORDINAL eval error: 0.640\n",
      "\t\t\t MEASURE eval error: 0.713\n",
      "\t\t\t DATE eval error: 0.470\n",
      "\t\t\t ELECTRONIC eval error: 0.977\n",
      "\t\t\t CARDINAL eval error: 0.347\n",
      "\t\t\t LETTERS eval error: 0.283\n",
      "\t\t\t DECIMAL eval error: 0.830\n",
      "\t\t\t FRACTION eval error: 0.950\n",
      "\t\t\t TELEPHONE eval error: 0.997\n",
      "\t\t\t TIME eval error: 0.447\n",
      "\t\t\t MONEY eval error: 0.953\n",
      "\t\t\t DIGIT eval error: 0.163\n",
      "{'PLAIN': 20, 'PUNCT': 28, 'VERBATIM': 23.0, 'ORDINAL': 31.0, 'MEASURE': 31.0, 'DATE': 26.0, 'ELECTRONIC': 31.0, 'CARDINAL': 26.0, 'LETTERS': 23.0, 'DECIMAL': 31.0, 'FRACTION': 31.0, 'TELEPHONE': 31.0, 'TIME': 24.0, 'MONEY': 31.0, 'DIGIT': 22.0, '<eos>': 0.0}\n",
      "('н е с х о д и л с о <norm> с т р а н и ц </norm> т а б л о и д о в . ', '<self>', 'PLAIN')\n",
      "(', S t e p h e n T h o m a s <norm> . </norm> ', 'sil', 'PUNCT')\n",
      "10001\n",
      "588m 36s (- 458m 44s) (281000 56%) 0.1447\n",
      "590m 23s (- 456m 23s) (282000 56%) 0.1720\n",
      "592m 8s (- 454m 2s) (283000 56%) 0.1425\n",
      "593m 53s (- 451m 41s) (284000 56%) 0.1616\n",
      "595m 39s (- 449m 21s) (285000 56%) 0.1916\n",
      "597m 25s (- 447m 1s) (286000 57%) 0.1359\n",
      "599m 11s (- 444m 42s) (287000 57%) 0.1812\n",
      "600m 55s (- 442m 21s) (288000 57%) 0.1708\n",
      "602m 42s (- 440m 2s) (289000 57%) 0.1473\n",
      "604m 29s (- 437m 43s) (290000 57%) 0.1665\n",
      "\t\t eval accuracy: 0.474\n",
      "\t\t\t PLAIN eval error: 0.060\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.047\n",
      "\t\t\t ORDINAL eval error: 0.637\n",
      "\t\t\t MEASURE eval error: 0.710\n",
      "\t\t\t DATE eval error: 0.477\n",
      "\t\t\t ELECTRONIC eval error: 0.977\n",
      "\t\t\t CARDINAL eval error: 0.343\n",
      "\t\t\t LETTERS eval error: 0.283\n",
      "\t\t\t DECIMAL eval error: 0.840\n",
      "\t\t\t FRACTION eval error: 0.940\n",
      "\t\t\t TELEPHONE eval error: 0.997\n",
      "\t\t\t TIME eval error: 0.453\n",
      "\t\t\t MONEY eval error: 0.957\n",
      "\t\t\t DIGIT eval error: 0.167\n",
      "{'PLAIN': 21, 'PUNCT': 29, 'VERBATIM': 24.0, 'ORDINAL': 32.0, 'MEASURE': 32.0, 'DATE': 27.0, 'ELECTRONIC': 32.0, 'CARDINAL': 27.0, 'LETTERS': 24.0, 'DECIMAL': 32.0, 'FRACTION': 32.0, 'TELEPHONE': 32.0, 'TIME': 25.0, 'MONEY': 32.0, 'DIGIT': 23.0, '<eos>': 0.0}\n",
      "('В <norm> х р а м е </norm> и м е л о с ь « ж и в о п и с н о е', '<self>', 'PLAIN')\n",
      "('B a n k к у п и л д о л ю <norm> в </norm> ч е л я б и н с к о м б а н к е (', '<self>', 'PLAIN')\n",
      "10001\n",
      "609m 49s (- 437m 58s) (291000 58%) 0.1865\n",
      "611m 37s (- 435m 40s) (292000 58%) 0.1435\n",
      "613m 23s (- 433m 21s) (293000 58%) 0.2028\n",
      "615m 11s (- 431m 3s) (294000 58%) 0.1712\n",
      "616m 59s (- 428m 45s) (295000 59%) 0.2034\n",
      "618m 46s (- 426m 27s) (296000 59%) 0.2026\n",
      "620m 35s (- 424m 10s) (297000 59%) 0.1839\n",
      "622m 21s (- 421m 52s) (298000 59%) 0.1556\n",
      "624m 8s (- 419m 34s) (299000 59%) 0.1494\n",
      "625m 56s (- 417m 17s) (300000 60%) 0.1980\n",
      "\t\t eval accuracy: 0.473\n",
      "\t\t\t PLAIN eval error: 0.060\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.043\n",
      "\t\t\t ORDINAL eval error: 0.637\n",
      "\t\t\t MEASURE eval error: 0.720\n",
      "\t\t\t DATE eval error: 0.480\n",
      "\t\t\t ELECTRONIC eval error: 0.980\n",
      "\t\t\t CARDINAL eval error: 0.340\n",
      "\t\t\t LETTERS eval error: 0.290\n",
      "\t\t\t DECIMAL eval error: 0.833\n",
      "\t\t\t FRACTION eval error: 0.937\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.447\n",
      "\t\t\t MONEY eval error: 0.957\n",
      "\t\t\t DIGIT eval error: 0.177\n",
      "{'PLAIN': 22, 'PUNCT': 30, 'VERBATIM': 25.0, 'ORDINAL': 33.0, 'MEASURE': 33.0, 'DATE': 28.0, 'ELECTRONIC': 33.0, 'CARDINAL': 28.0, 'LETTERS': 25.0, 'DECIMAL': 33.0, 'FRACTION': 33.0, 'TELEPHONE': 33.0, 'TIME': 26.0, 'MONEY': 33.0, 'DIGIT': 24.0, '<eos>': 0.0}\n",
      "('с п е к т а к л и в т е а т р а х <norm> В е н е ц и и </norm> . ', '<self>', 'PLAIN')\n",
      "('о т 8 8 8 - <norm> 9 2 </norm> . S c o t t R', 'девяноста двух', 'CARDINAL')\n",
      "10001\n",
      "631m 17s (- 417m 21s) (301000 60%) 0.1554\n",
      "633m 2s (- 415m 2s) (302000 60%) 0.1742\n",
      "634m 47s (- 412m 43s) (303000 60%) 0.1683\n",
      "636m 33s (- 410m 25s) (304000 60%) 0.1680\n",
      "638m 20s (- 408m 7s) (305000 61%) 0.2072\n",
      "640m 5s (- 405m 48s) (306000 61%) 0.1581\n",
      "641m 51s (- 403m 30s) (307000 61%) 0.1861\n",
      "643m 37s (- 401m 13s) (308000 61%) 0.1961\n",
      "645m 23s (- 398m 56s) (309000 61%) 0.1816\n",
      "647m 9s (- 396m 38s) (310000 62%) 0.1746\n",
      "\t\t eval accuracy: 0.476\n",
      "\t\t\t PLAIN eval error: 0.060\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.043\n",
      "\t\t\t ORDINAL eval error: 0.640\n",
      "\t\t\t MEASURE eval error: 0.710\n",
      "\t\t\t DATE eval error: 0.473\n",
      "\t\t\t ELECTRONIC eval error: 0.977\n",
      "\t\t\t CARDINAL eval error: 0.333\n",
      "\t\t\t LETTERS eval error: 0.283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t DECIMAL eval error: 0.823\n",
      "\t\t\t FRACTION eval error: 0.937\n",
      "\t\t\t TELEPHONE eval error: 0.997\n",
      "\t\t\t TIME eval error: 0.463\n",
      "\t\t\t MONEY eval error: 0.943\n",
      "\t\t\t DIGIT eval error: 0.177\n",
      "{'PLAIN': 23, 'PUNCT': 31, 'VERBATIM': 26.0, 'ORDINAL': 34.0, 'MEASURE': 34.0, 'DATE': 29.0, 'ELECTRONIC': 34.0, 'CARDINAL': 28.0, 'LETTERS': 26.0, 'DECIMAL': 34.0, 'FRACTION': 34.0, 'TELEPHONE': 34.0, 'TIME': 27.0, 'MONEY': 34.0, 'DIGIT': 25.0, '<eos>': 0.0}\n",
      "('н а р у с с к и й я з ы к <norm> н е т </norm> . ', '<self>', 'PLAIN')\n",
      "('в е к а п р и х о д я т и <norm> д р у г и е </norm> и с с л е д о в а т е л и . ', '<self>', 'PLAIN')\n",
      "10001\n",
      "652m 28s (- 396m 31s) (311000 62%) 0.1414\n",
      "654m 13s (- 394m 12s) (312000 62%) 0.1823\n",
      "656m 0s (- 391m 55s) (313000 62%) 0.1662\n",
      "657m 46s (- 389m 38s) (314000 62%) 0.1690\n",
      "659m 32s (- 387m 21s) (315000 63%) 0.1555\n",
      "661m 19s (- 385m 4s) (316000 63%) 0.1744\n",
      "663m 6s (- 382m 48s) (317000 63%) 0.1796\n",
      "664m 51s (- 380m 30s) (318000 63%) 0.1904\n",
      "666m 38s (- 378m 15s) (319000 63%) 0.1715\n",
      "668m 24s (- 375m 58s) (320000 64%) 0.2150\n",
      "\t\t eval accuracy: 0.475\n",
      "\t\t\t PLAIN eval error: 0.060\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.043\n",
      "\t\t\t ORDINAL eval error: 0.637\n",
      "\t\t\t MEASURE eval error: 0.717\n",
      "\t\t\t DATE eval error: 0.477\n",
      "\t\t\t ELECTRONIC eval error: 0.977\n",
      "\t\t\t CARDINAL eval error: 0.343\n",
      "\t\t\t LETTERS eval error: 0.283\n",
      "\t\t\t DECIMAL eval error: 0.827\n",
      "\t\t\t FRACTION eval error: 0.937\n",
      "\t\t\t TELEPHONE eval error: 0.997\n",
      "\t\t\t TIME eval error: 0.447\n",
      "\t\t\t MONEY eval error: 0.960\n",
      "\t\t\t DIGIT eval error: 0.173\n",
      "{'PLAIN': 24, 'PUNCT': 32, 'VERBATIM': 27.0, 'ORDINAL': 35.0, 'MEASURE': 35.0, 'DATE': 30.0, 'ELECTRONIC': 35.0, 'CARDINAL': 29.0, 'LETTERS': 27.0, 'DECIMAL': 35.0, 'FRACTION': 35.0, 'TELEPHONE': 35.0, 'TIME': 28.0, 'MONEY': 35.0, 'DIGIT': 26.0, '<eos>': 0.0}\n",
      "('о н и о б о з н а ч а ю т с я п р о с т о <norm> к а к </norm> « В р а г »', '<self>', 'PLAIN')\n",
      "('В 1 9 9 9 <norm> з а щ и т и л </norm> к а н д и д а т с к у ю д и с с е р т а ц и ю п о', '<self>', 'PLAIN')\n",
      "10001\n",
      "673m 45s (- 375m 42s) (321000 64%) 0.1823\n",
      "675m 32s (- 373m 25s) (322000 64%) 0.1774\n",
      "677m 18s (- 371m 9s) (323000 64%) 0.1785\n",
      "679m 4s (- 368m 52s) (324000 64%) 0.1498\n",
      "680m 49s (- 366m 35s) (325000 65%) 0.2214\n",
      "682m 33s (- 364m 18s) (326000 65%) 0.1913\n",
      "684m 19s (- 362m 2s) (327000 65%) 0.1865\n",
      "686m 6s (- 359m 47s) (328000 65%) 0.1867\n",
      "687m 52s (- 357m 31s) (329000 65%) 0.1865\n",
      "689m 39s (- 355m 16s) (330000 66%) 0.2083\n",
      "\t\t eval accuracy: 0.474\n",
      "\t\t\t PLAIN eval error: 0.060\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.043\n",
      "\t\t\t ORDINAL eval error: 0.640\n",
      "\t\t\t MEASURE eval error: 0.723\n",
      "\t\t\t DATE eval error: 0.470\n",
      "\t\t\t ELECTRONIC eval error: 0.977\n",
      "\t\t\t CARDINAL eval error: 0.337\n",
      "\t\t\t LETTERS eval error: 0.287\n",
      "\t\t\t DECIMAL eval error: 0.827\n",
      "\t\t\t FRACTION eval error: 0.947\n",
      "\t\t\t TELEPHONE eval error: 0.997\n",
      "\t\t\t TIME eval error: 0.453\n",
      "\t\t\t MONEY eval error: 0.957\n",
      "\t\t\t DIGIT eval error: 0.167\n",
      "{'PLAIN': 25, 'PUNCT': 33, 'VERBATIM': 28.0, 'ORDINAL': 36.0, 'MEASURE': 36.0, 'DATE': 31.0, 'ELECTRONIC': 36.0, 'CARDINAL': 30.0, 'LETTERS': 28.0, 'DECIMAL': 36.0, 'FRACTION': 36.0, 'TELEPHONE': 36.0, 'TIME': 29.0, 'MONEY': 36.0, 'DIGIT': 27.0, '<eos>': 0.0}\n",
      "('с л а в а н а п о л н и л а з е м л ю <norm> . </norm> ', 'sil', 'PUNCT')\n",
      "(') — н о м и н а ц и я <norm> н а </norm> г л а в н ы й п р и з н а', '<self>', 'PLAIN')\n",
      "10001\n",
      "694m 58s (- 354m 50s) (331000 66%) 0.1670\n",
      "696m 45s (- 352m 34s) (332000 66%) 0.2072\n",
      "698m 31s (- 350m 18s) (333000 66%) 0.1502\n",
      "700m 18s (- 348m 3s) (334000 66%) 0.1808\n",
      "702m 3s (- 345m 47s) (335000 67%) 0.1795\n",
      "703m 50s (- 343m 32s) (336000 67%) 0.1830\n",
      "Setting new learning rate to 0.00000\n",
      "705m 39s (- 341m 18s) (337000 67%) 0.1970\n",
      "707m 24s (- 339m 3s) (338000 67%) 0.1948\n",
      "709m 10s (- 336m 48s) (339000 67%) 0.1798\n",
      "710m 57s (- 334m 34s) (340000 68%) 0.1564\n",
      "\t\t eval accuracy: 0.474\n",
      "\t\t\t PLAIN eval error: 0.060\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.043\n",
      "\t\t\t ORDINAL eval error: 0.647\n",
      "\t\t\t MEASURE eval error: 0.717\n",
      "\t\t\t DATE eval error: 0.477\n",
      "\t\t\t ELECTRONIC eval error: 0.977\n",
      "\t\t\t CARDINAL eval error: 0.333\n",
      "\t\t\t LETTERS eval error: 0.290\n",
      "\t\t\t DECIMAL eval error: 0.830\n",
      "\t\t\t FRACTION eval error: 0.950\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.450\n",
      "\t\t\t MONEY eval error: 0.960\n",
      "\t\t\t DIGIT eval error: 0.163\n",
      "{'PLAIN': 26, 'PUNCT': 34, 'VERBATIM': 29.0, 'ORDINAL': 37.0, 'MEASURE': 37.0, 'DATE': 32.0, 'ELECTRONIC': 37.0, 'CARDINAL': 31.0, 'LETTERS': 29.0, 'DECIMAL': 37.0, 'FRACTION': 37.0, 'TELEPHONE': 37.0, 'TIME': 30.0, 'MONEY': 37.0, 'DIGIT': 28.0, '<eos>': 0.0}\n",
      "('M i k h a i l <norm> A . </norm> F e d o n k i n , J a m e s', 'a', 'LETTERS')\n",
      "('д у ш у н а с е л е н и я с о с т а в л я л <norm> 1 2 7 9 4 U S D </norm> . ', 'двенадцать тысяч семьсот девяносто четыре доллара сэ ш а', 'MONEY')\n",
      "10001\n",
      "716m 17s (- 333m 59s) (341000 68%) 0.1629\n",
      "Setting new learning rate to 0.00000\n",
      "718m 3s (- 331m 44s) (342000 68%) 0.2074\n",
      "719m 52s (- 329m 30s) (343000 68%) 0.1980\n",
      "721m 39s (- 327m 15s) (344000 68%) 0.1955\n",
      "723m 25s (- 325m 0s) (345000 69%) 0.1610\n",
      "725m 10s (- 322m 46s) (346000 69%) 0.1829\n",
      "Setting new learning rate to 0.00000\n",
      "726m 54s (- 320m 30s) (347000 69%) 0.1857\n",
      "728m 39s (- 318m 15s) (348000 69%) 0.1567\n",
      "730m 27s (- 316m 2s) (349000 69%) 0.1751\n",
      "732m 13s (- 313m 48s) (350000 70%) 0.1663\n",
      "\t\t eval accuracy: 0.474\n",
      "\t\t\t PLAIN eval error: 0.060\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.047\n",
      "\t\t\t ORDINAL eval error: 0.633\n",
      "\t\t\t MEASURE eval error: 0.720\n",
      "\t\t\t DATE eval error: 0.473\n",
      "\t\t\t ELECTRONIC eval error: 0.973\n",
      "\t\t\t CARDINAL eval error: 0.340\n",
      "\t\t\t LETTERS eval error: 0.283\n",
      "\t\t\t DECIMAL eval error: 0.827\n",
      "\t\t\t FRACTION eval error: 0.947\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.467\n",
      "\t\t\t MONEY eval error: 0.957\n",
      "\t\t\t DIGIT eval error: 0.163\n",
      "{'PLAIN': 27, 'PUNCT': 35, 'VERBATIM': 30.0, 'ORDINAL': 38.0, 'MEASURE': 38.0, 'DATE': 33.0, 'ELECTRONIC': 38.0, 'CARDINAL': 32.0, 'LETTERS': 30.0, 'DECIMAL': 38.0, 'FRACTION': 38.0, 'TELEPHONE': 38.0, 'TIME': 31.0, 'MONEY': 38.0, 'DIGIT': 29.0, '<eos>': 0.0}\n",
      "('в ы с т а в и л о ц е н к у 8 4 % <norm> . </norm> ', 'sil', 'PUNCT')\n",
      "('О с н о в н ы м ж е с о а в т о р о м <norm> с ц е н а р и я </norm> с т а л р е ж и с с е р Р и ч а р д', '<self>', 'PLAIN')\n",
      "10001\n",
      "737m 31s (- 313m 4s) (351000 70%) 0.1555\n",
      "Setting new learning rate to 0.00000\n",
      "739m 18s (- 310m 50s) (352000 70%) 0.1753\n",
      "741m 5s (- 308m 36s) (353000 70%) 0.1704\n",
      "742m 51s (- 306m 22s) (354000 70%) 0.1412\n",
      "744m 41s (- 304m 10s) (355000 71%) 0.1604\n",
      "746m 27s (- 301m 56s) (356000 71%) 0.1873\n",
      "Setting new learning rate to 0.00000\n",
      "748m 13s (- 299m 42s) (357000 71%) 0.1591\n",
      "749m 59s (- 297m 29s) (358000 71%) 0.1515\n",
      "751m 46s (- 295m 15s) (359000 71%) 0.1712\n",
      "753m 32s (- 293m 2s) (360000 72%) 0.1711\n",
      "\t\t eval accuracy: 0.475\n",
      "\t\t\t PLAIN eval error: 0.060\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.047\n",
      "\t\t\t ORDINAL eval error: 0.640\n",
      "\t\t\t MEASURE eval error: 0.713\n",
      "\t\t\t DATE eval error: 0.473\n",
      "\t\t\t ELECTRONIC eval error: 0.973\n",
      "\t\t\t CARDINAL eval error: 0.340\n",
      "\t\t\t LETTERS eval error: 0.290\n",
      "\t\t\t DECIMAL eval error: 0.827\n",
      "\t\t\t FRACTION eval error: 0.950\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.450\n",
      "\t\t\t MONEY eval error: 0.957\n",
      "\t\t\t DIGIT eval error: 0.153\n",
      "{'PLAIN': 28, 'PUNCT': 36, 'VERBATIM': 31.0, 'ORDINAL': 39.0, 'MEASURE': 39.0, 'DATE': 34.0, 'ELECTRONIC': 39.0, 'CARDINAL': 33.0, 'LETTERS': 31.0, 'DECIMAL': 39.0, 'FRACTION': 39.0, 'TELEPHONE': 39.0, 'TIME': 32.0, 'MONEY': 39.0, 'DIGIT': 29.0, '<eos>': 0.0}\n",
      "('п р о г р а м м ы / т а н ц а <norm> . </norm> ', 'sil', 'PUNCT')\n",
      "('<norm> Л . </norm> К р и г е р С е м ь л у к', 'л', 'LETTERS')\n",
      "10001\n",
      "758m 51s (- 292m 11s) (361000 72%) 0.1726\n",
      "Setting new learning rate to 0.00000\n",
      "760m 36s (- 289m 57s) (362000 72%) 0.1458\n",
      "762m 21s (- 287m 43s) (363000 72%) 0.1619\n",
      "764m 8s (- 285m 30s) (364000 72%) 0.1779\n",
      "765m 53s (- 283m 16s) (365000 73%) 0.1637\n",
      "767m 38s (- 281m 3s) (366000 73%) 0.1695\n",
      "Setting new learning rate to 0.00000\n",
      "769m 27s (- 278m 50s) (367000 73%) 0.1700\n",
      "771m 12s (- 276m 37s) (368000 73%) 0.1744\n",
      "772m 56s (- 274m 24s) (369000 73%) 0.1759\n",
      "774m 43s (- 272m 12s) (370000 74%) 0.1641\n",
      "\t\t eval accuracy: 0.475\n",
      "\t\t\t PLAIN eval error: 0.060\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.047\n",
      "\t\t\t ORDINAL eval error: 0.643\n",
      "\t\t\t MEASURE eval error: 0.713\n",
      "\t\t\t DATE eval error: 0.470\n",
      "\t\t\t ELECTRONIC eval error: 0.977\n",
      "\t\t\t CARDINAL eval error: 0.347\n",
      "\t\t\t LETTERS eval error: 0.283\n",
      "\t\t\t DECIMAL eval error: 0.833\n",
      "\t\t\t FRACTION eval error: 0.943\n",
      "\t\t\t TELEPHONE eval error: 0.997\n",
      "\t\t\t TIME eval error: 0.453\n",
      "\t\t\t MONEY eval error: 0.950\n",
      "\t\t\t DIGIT eval error: 0.160\n",
      "{'PLAIN': 29, 'PUNCT': 37, 'VERBATIM': 32.0, 'ORDINAL': 40.0, 'MEASURE': 40.0, 'DATE': 35.0, 'ELECTRONIC': 40.0, 'CARDINAL': 34.0, 'LETTERS': 32.0, 'DECIMAL': 40.0, 'FRACTION': 40.0, 'TELEPHONE': 40.0, 'TIME': 33.0, 'MONEY': 40.0, 'DIGIT': 30.0, '<eos>': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Н о с и т <norm> р а с к р а ш е н н ы й </norm> в х о л о д н ы е ц в е т а', '<self>', 'PLAIN')\n",
      "('п р о г н а т ь д е р з к о г о к а в а л е р а <norm> , </norm> о д н а к о г о с т и п р и м и р я ю т', 'sil', 'PUNCT')\n",
      "10001\n",
      "780m 2s (- 271m 13s) (371000 74%) 0.1842\n",
      "Setting new learning rate to 0.00000\n",
      "781m 50s (- 269m 1s) (372000 74%) 0.1593\n",
      "783m 36s (- 266m 48s) (373000 74%) 0.1644\n",
      "785m 26s (- 264m 36s) (374000 74%) 0.2102\n",
      "787m 13s (- 262m 24s) (375000 75%) 0.1899\n",
      "789m 1s (- 260m 12s) (376000 75%) 0.1438\n",
      "Setting new learning rate to 0.00000\n",
      "790m 50s (- 258m 1s) (377000 75%) 0.1503\n",
      "792m 38s (- 255m 49s) (378000 75%) 0.1458\n",
      "794m 24s (- 253m 37s) (379000 75%) 0.1637\n",
      "796m 12s (- 251m 26s) (380000 76%) 0.1910\n",
      "\t\t eval accuracy: 0.474\n",
      "\t\t\t PLAIN eval error: 0.060\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.043\n",
      "\t\t\t ORDINAL eval error: 0.637\n",
      "\t\t\t MEASURE eval error: 0.713\n",
      "\t\t\t DATE eval error: 0.473\n",
      "\t\t\t ELECTRONIC eval error: 0.977\n",
      "\t\t\t CARDINAL eval error: 0.340\n",
      "\t\t\t LETTERS eval error: 0.293\n",
      "\t\t\t DECIMAL eval error: 0.827\n",
      "\t\t\t FRACTION eval error: 0.937\n",
      "\t\t\t TELEPHONE eval error: 0.997\n",
      "\t\t\t TIME eval error: 0.460\n",
      "\t\t\t MONEY eval error: 0.960\n",
      "\t\t\t DIGIT eval error: 0.170\n",
      "{'PLAIN': 30, 'PUNCT': 38, 'VERBATIM': 33.0, 'ORDINAL': 41.0, 'MEASURE': 41.0, 'DATE': 36.0, 'ELECTRONIC': 41.0, 'CARDINAL': 35.0, 'LETTERS': 33.0, 'DECIMAL': 41.0, 'FRACTION': 41.0, 'TELEPHONE': 41.0, 'TIME': 34.0, 'MONEY': 41.0, 'DIGIT': 31.0, '<eos>': 0.0}\n",
      "(') A n d r z e j A l e k s a n d r o w i c z <norm> , </norm> k s i a z e z l i n i i', 'sil', 'PUNCT')\n",
      "('K a z a k h s t a n / / <norm> O p e r a t i o n </norm> W o r l d : T h e', 'о_trans п_trans е_trans р_trans е_trans й_trans ш_trans е_trans н_trans', 'PLAIN')\n",
      "10001\n",
      "801m 31s (- 250m 20s) (381000 76%) 0.1811\n",
      "Setting new learning rate to 0.00000\n",
      "803m 16s (- 248m 7s) (382000 76%) 0.1564\n",
      "805m 3s (- 245m 55s) (383000 76%) 0.1783\n",
      "806m 47s (- 243m 43s) (384000 76%) 0.1869\n",
      "808m 36s (- 241m 31s) (385000 77%) 0.1687\n",
      "810m 24s (- 239m 20s) (386000 77%) 0.1889\n",
      "Setting new learning rate to 0.00000\n",
      "812m 13s (- 237m 9s) (387000 77%) 0.1906\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-ce2a8f978055>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcallback_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m plot_losses = trainIters_weighted(encoder1, attn_decoder1, train_pairs, test_pairs, 500000, print_every=callback_num, \n\u001b[0;32m---> 17\u001b[0;31m                          plot_every=callback_num, evaluate_each=10000, learning_rate = 0.01)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-1e8c9f6a3576>\u001b[0m in \u001b[0;36mtrainIters_weighted\u001b[0;34m(encoder, decoder, pairs, test_pairs, n_iters, print_every, plot_every, learning_rate, evaluate_each)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             loss = train(input_variable, target_variable, encoder,\n\u001b[0;32m---> 46\u001b[0;31m                          decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-71796064a020>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mei\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         encoder_output, encoder_hidden = encoder(\n\u001b[0;32m---> 21\u001b[0;31m             input_variable[ei], encoder_hidden)\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-c227f15ad09e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         )\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutogradRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mGRUCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mgi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mgh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfusedBackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRUFused\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(tensor1, tensor2, out)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim_tensor1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim_tensor2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mmm\u001b[0;34m(self, matrix)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mAddmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/_functions/blas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, add_matrix, matrix1, matrix2, alpha, beta, inplace)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_matrix_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.enabled = False\n",
    "test_pairs = make_even_sample(dev_pairs, size_of_class = 300)\n",
    "\n",
    "\n",
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size, n_layers=4)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words,\n",
    "                           n_layers = 2, dropout_p=0.2)\n",
    "\n",
    "if use_cuda:\n",
    "    print('Using CUDA')\n",
    "    encoder1 = encoder1.cuda()\n",
    "    attn_decoder1 = attn_decoder1.cuda()\n",
    "\n",
    "callback_num = 1000\n",
    "plot_losses = trainIters_weighted(encoder1, attn_decoder1, train_pairs, test_pairs, 500000, print_every=callback_num, \n",
    "                         plot_every=callback_num, evaluate_each=10000, learning_rate = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "1m 41s (- 166m 44s) (1000 1%) 1.6956\n",
      "3m 12s (- 157m 30s) (2000 2%) 1.3795\n",
      "4m 46s (- 154m 21s) (3000 3%) 1.4491\n",
      "6m 19s (- 151m 51s) (4000 4%) 1.1839\n",
      "7m 53s (- 149m 52s) (5000 5%) 1.1675\n",
      "\t\t eval accuracy: 0.126\n",
      "\t\t\t PLAIN eval error: 0.147\n",
      "\t\t\t PUNCT eval error: 0.323\n",
      "\t\t\t VERBATIM eval error: 0.703\n",
      "\t\t\t ORDINAL eval error: 1.000\n",
      "\t\t\t MEASURE eval error: 0.997\n",
      "\t\t\t DATE eval error: 1.000\n",
      "\t\t\t ELECTRONIC eval error: 0.990\n",
      "\t\t\t CARDINAL eval error: 0.997\n",
      "\t\t\t LETTERS eval error: 1.000\n",
      "\t\t\t DECIMAL eval error: 0.987\n",
      "\t\t\t FRACTION eval error: 0.990\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.983\n",
      "\t\t\t MONEY eval error: 0.990\n",
      "\t\t\t DIGIT eval error: 1.000\n",
      "{'PLAIN': 1, 'PUNCT': 2, 'VERBATIM': 4.0, 'ORDINAL': 4.0, 'MEASURE': 4.0, 'DATE': 4.0, 'ELECTRONIC': 4.0, 'CARDINAL': 4.0, 'LETTERS': 4.0, 'DECIMAL': 4.0, 'FRACTION': 4.0, 'TELEPHONE': 4.0, 'TIME': 4.0, 'MONEY': 4.0, 'DIGIT': 4.0, '<eos>': 0.0}\n",
      "12m 20s (- 193m 19s) (6000 6%) 1.3486\n",
      "13m 53s (- 184m 30s) (7000 7%) 1.3110\n",
      "15m 27s (- 177m 44s) (8000 8%) 1.3781\n",
      "17m 0s (- 171m 57s) (9000 9%) 1.3703\n",
      "18m 33s (- 167m 4s) (10000 10%) 1.2734\n",
      "\t\t eval accuracy: 0.120\n",
      "\t\t\t PLAIN eval error: 0.437\n",
      "\t\t\t PUNCT eval error: 0.250\n",
      "\t\t\t VERBATIM eval error: 0.597\n",
      "\t\t\t ORDINAL eval error: 1.000\n",
      "\t\t\t MEASURE eval error: 0.997\n",
      "\t\t\t DATE eval error: 1.000\n",
      "\t\t\t ELECTRONIC eval error: 0.987\n",
      "\t\t\t CARDINAL eval error: 0.997\n",
      "\t\t\t LETTERS eval error: 1.000\n",
      "\t\t\t DECIMAL eval error: 0.983\n",
      "\t\t\t FRACTION eval error: 0.990\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.987\n",
      "\t\t\t MONEY eval error: 0.983\n",
      "\t\t\t DIGIT eval error: 1.000\n",
      "{'PLAIN': 2, 'PUNCT': 2, 'VERBATIM': 4.0, 'ORDINAL': 5.0, 'MEASURE': 5.0, 'DATE': 5.0, 'ELECTRONIC': 4.0, 'CARDINAL': 5.0, 'LETTERS': 5.0, 'DECIMAL': 4.0, 'FRACTION': 5.0, 'TELEPHONE': 5.0, 'TIME': 5.0, 'MONEY': 4.0, 'DIGIT': 5.0, '<eos>': 0.0}\n",
      "23m 5s (- 186m 52s) (11000 11%) 1.1514\n",
      "24m 43s (- 181m 15s) (12000 12%) 1.2101\n",
      "26m 18s (- 176m 4s) (13000 13%) 1.0947\n",
      "27m 54s (- 171m 24s) (14000 14%) 1.1917\n",
      "29m 29s (- 167m 4s) (15000 15%) 1.1504\n",
      "\t\t eval accuracy: 0.100\n",
      "\t\t\t PLAIN eval error: 0.140\n",
      "\t\t\t PUNCT eval error: 0.547\n",
      "\t\t\t VERBATIM eval error: 0.843\n",
      "\t\t\t ORDINAL eval error: 1.000\n",
      "\t\t\t MEASURE eval error: 0.997\n",
      "\t\t\t DATE eval error: 1.000\n",
      "\t\t\t ELECTRONIC eval error: 0.993\n",
      "\t\t\t CARDINAL eval error: 1.000\n",
      "\t\t\t LETTERS eval error: 1.000\n",
      "\t\t\t DECIMAL eval error: 0.997\n",
      "\t\t\t FRACTION eval error: 0.993\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.993\n",
      "\t\t\t MONEY eval error: 0.997\n",
      "\t\t\t DIGIT eval error: 1.000\n",
      "{'PLAIN': 2, 'PUNCT': 3, 'VERBATIM': 5.0, 'ORDINAL': 6.0, 'MEASURE': 6.0, 'DATE': 6.0, 'ELECTRONIC': 5.0, 'CARDINAL': 6.0, 'LETTERS': 6.0, 'DECIMAL': 5.0, 'FRACTION': 6.0, 'TELEPHONE': 6.0, 'TIME': 6.0, 'MONEY': 5.0, 'DIGIT': 6.0, '<eos>': 0.0}\n",
      "33m 56s (- 178m 12s) (16000 16%) 1.1935\n",
      "35m 32s (- 173m 29s) (17000 17%) 1.1862\n",
      "37m 7s (- 169m 7s) (18000 18%) 1.0644\n",
      "38m 45s (- 165m 15s) (19000 19%) 1.0243\n",
      "40m 21s (- 161m 26s) (20000 20%) 0.9456\n",
      "\t\t eval accuracy: 0.187\n",
      "\t\t\t PLAIN eval error: 0.097\n",
      "\t\t\t PUNCT eval error: 0.003\n",
      "\t\t\t VERBATIM eval error: 0.117\n",
      "\t\t\t ORDINAL eval error: 1.000\n",
      "\t\t\t MEASURE eval error: 0.997\n",
      "\t\t\t DATE eval error: 1.000\n",
      "\t\t\t ELECTRONIC eval error: 0.983\n",
      "\t\t\t CARDINAL eval error: 0.997\n",
      "\t\t\t LETTERS eval error: 1.000\n",
      "\t\t\t DECIMAL eval error: 1.000\n",
      "\t\t\t FRACTION eval error: 1.000\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 1.000\n",
      "\t\t\t MONEY eval error: 1.000\n",
      "\t\t\t DIGIT eval error: 1.000\n",
      "{'PLAIN': 2, 'PUNCT': 3, 'VERBATIM': 5.0, 'ORDINAL': 7.0, 'MEASURE': 7.0, 'DATE': 7.0, 'ELECTRONIC': 5.0, 'CARDINAL': 6.0, 'LETTERS': 7.0, 'DECIMAL': 6.0, 'FRACTION': 7.0, 'TELEPHONE': 7.0, 'TIME': 7.0, 'MONEY': 6.0, 'DIGIT': 7.0, '<eos>': 0.0}\n",
      "44m 59s (- 169m 13s) (21000 21%) 0.8560\n",
      "46m 32s (- 165m 2s) (22000 22%) 0.9828\n",
      "48m 9s (- 161m 12s) (23000 23%) 0.9479\n",
      "49m 44s (- 157m 30s) (24000 24%) 0.9480\n",
      "51m 19s (- 153m 58s) (25000 25%) 0.9015\n",
      "\t\t eval accuracy: 0.189\n",
      "\t\t\t PLAIN eval error: 0.090\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.123\n",
      "\t\t\t ORDINAL eval error: 1.000\n",
      "\t\t\t MEASURE eval error: 1.000\n",
      "\t\t\t DATE eval error: 0.997\n",
      "\t\t\t ELECTRONIC eval error: 0.983\n",
      "\t\t\t CARDINAL eval error: 0.997\n",
      "\t\t\t LETTERS eval error: 0.983\n",
      "\t\t\t DECIMAL eval error: 1.000\n",
      "\t\t\t FRACTION eval error: 0.997\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 1.000\n",
      "\t\t\t MONEY eval error: 1.000\n",
      "\t\t\t DIGIT eval error: 1.000\n",
      "{'PLAIN': 2, 'PUNCT': 3, 'VERBATIM': 6.0, 'ORDINAL': 8.0, 'MEASURE': 8.0, 'DATE': 7.0, 'ELECTRONIC': 6.0, 'CARDINAL': 7.0, 'LETTERS': 7.0, 'DECIMAL': 7.0, 'FRACTION': 7.0, 'TELEPHONE': 8.0, 'TIME': 8.0, 'MONEY': 7.0, 'DIGIT': 8.0, '<eos>': 0.0}\n",
      "55m 59s (- 159m 20s) (26000 26%) 0.9454\n",
      "57m 34s (- 155m 39s) (27000 27%) 0.7844\n",
      "59m 10s (- 152m 9s) (28000 28%) 0.7969\n",
      "60m 44s (- 148m 43s) (29000 28%) 1.0770\n",
      "62m 20s (- 145m 27s) (30000 30%) 1.1407\n",
      "\t\t eval accuracy: 0.116\n",
      "\t\t\t PLAIN eval error: 0.130\n",
      "\t\t\t PUNCT eval error: 0.390\n",
      "\t\t\t VERBATIM eval error: 0.783\n",
      "\t\t\t ORDINAL eval error: 1.000\n",
      "\t\t\t MEASURE eval error: 0.997\n",
      "\t\t\t DATE eval error: 1.000\n",
      "\t\t\t ELECTRONIC eval error: 0.993\n",
      "\t\t\t CARDINAL eval error: 0.997\n",
      "\t\t\t LETTERS eval error: 0.997\n",
      "\t\t\t DECIMAL eval error: 0.990\n",
      "\t\t\t FRACTION eval error: 0.993\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.997\n",
      "\t\t\t MONEY eval error: 0.990\n",
      "\t\t\t DIGIT eval error: 1.000\n",
      "{'PLAIN': 3, 'PUNCT': 4, 'VERBATIM': 7.0, 'ORDINAL': 9.0, 'MEASURE': 8.0, 'DATE': 8.0, 'ELECTRONIC': 7.0, 'CARDINAL': 8.0, 'LETTERS': 8.0, 'DECIMAL': 7.0, 'FRACTION': 7.0, 'TELEPHONE': 9.0, 'TIME': 8.0, 'MONEY': 7.0, 'DIGIT': 9.0, '<eos>': 0.0}\n",
      "66m 50s (- 148m 47s) (31000 31%) 0.9800\n",
      "68m 27s (- 145m 28s) (32000 32%) 0.8973\n",
      "70m 3s (- 142m 14s) (33000 33%) 0.9363\n",
      "71m 36s (- 139m 1s) (34000 34%) 0.9057\n",
      "73m 15s (- 136m 2s) (35000 35%) 0.9213\n",
      "\t\t eval accuracy: 0.187\n",
      "\t\t\t PLAIN eval error: 0.100\n",
      "\t\t\t PUNCT eval error: 0.010\n",
      "\t\t\t VERBATIM eval error: 0.123\n",
      "\t\t\t ORDINAL eval error: 1.000\n",
      "\t\t\t MEASURE eval error: 1.000\n",
      "\t\t\t DATE eval error: 1.000\n",
      "\t\t\t ELECTRONIC eval error: 0.997\n",
      "\t\t\t CARDINAL eval error: 0.993\n",
      "\t\t\t LETTERS eval error: 1.000\n",
      "\t\t\t DECIMAL eval error: 0.983\n",
      "\t\t\t FRACTION eval error: 0.997\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 0.997\n",
      "\t\t\t MONEY eval error: 1.000\n",
      "\t\t\t DIGIT eval error: 1.000\n",
      "{'PLAIN': 3, 'PUNCT': 4, 'VERBATIM': 7.0, 'ORDINAL': 10.0, 'MEASURE': 9.0, 'DATE': 9.0, 'ELECTRONIC': 8.0, 'CARDINAL': 8.0, 'LETTERS': 9.0, 'DECIMAL': 7.0, 'FRACTION': 8.0, 'TELEPHONE': 10.0, 'TIME': 9.0, 'MONEY': 8.0, 'DIGIT': 10.0, '<eos>': 0.0}\n",
      "77m 46s (- 138m 16s) (36000 36%) 0.7966\n",
      "79m 23s (- 135m 10s) (37000 37%) 0.7967\n",
      "81m 0s (- 132m 10s) (38000 38%) 0.8076\n",
      "82m 38s (- 129m 15s) (39000 39%) 0.7644\n",
      "84m 14s (- 126m 21s) (40000 40%) 0.7568\n",
      "\t\t eval accuracy: 0.187\n",
      "\t\t\t PLAIN eval error: 0.090\n",
      "\t\t\t PUNCT eval error: 0.000\n",
      "\t\t\t VERBATIM eval error: 0.143\n",
      "\t\t\t ORDINAL eval error: 1.000\n",
      "\t\t\t MEASURE eval error: 1.000\n",
      "\t\t\t DATE eval error: 1.000\n",
      "\t\t\t ELECTRONIC eval error: 0.983\n",
      "\t\t\t CARDINAL eval error: 1.000\n",
      "\t\t\t LETTERS eval error: 0.990\n",
      "\t\t\t DECIMAL eval error: 0.990\n",
      "\t\t\t FRACTION eval error: 1.000\n",
      "\t\t\t TELEPHONE eval error: 1.000\n",
      "\t\t\t TIME eval error: 1.000\n",
      "\t\t\t MONEY eval error: 1.000\n",
      "\t\t\t DIGIT eval error: 1.000\n",
      "{'PLAIN': 3, 'PUNCT': 4, 'VERBATIM': 8.0, 'ORDINAL': 11.0, 'MEASURE': 10.0, 'DATE': 10.0, 'ELECTRONIC': 8.0, 'CARDINAL': 9.0, 'LETTERS': 9.0, 'DECIMAL': 8.0, 'FRACTION': 9.0, 'TELEPHONE': 11.0, 'TIME': 10.0, 'MONEY': 9.0, 'DIGIT': 11.0, '<eos>': 0.0}\n",
      "89m 2s (- 128m 8s) (41000 41%) 0.7500\n",
      "90m 41s (- 125m 14s) (42000 42%) 0.8456\n",
      "92m 18s (- 122m 21s) (43000 43%) 0.8188\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-b5fd3ae4fdea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcallback_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m plot_losses = trainIters_weighted(encoder1, attn_decoder1, train_pairs, test_pairs, 100000, print_every=callback_num, \n\u001b[0;32m---> 17\u001b[0;31m                          plot_every=callback_num, evaluate_each=5000, learning_rate = 0.01)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-7ba0da5cb8f9>\u001b[0m in \u001b[0;36mtrainIters_weighted\u001b[0;34m(encoder, decoder, pairs, test_pairs, n_iters, print_every, plot_every, learning_rate, evaluate_each)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             loss = train(input_variable, target_variable, encoder,\n\u001b[0;32m---> 38\u001b[0;31m                          decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-71796064a020>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.enabled = False\n",
    "test_pairs = make_even_sample(dev_pairs, size_of_class = 300)\n",
    "\n",
    "\n",
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size, n_layers=4)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words,\n",
    "                           n_layers =2, dropout_p=0.1)\n",
    "\n",
    "if use_cuda:\n",
    "    print('Using CUDA')\n",
    "    encoder1 = encoder1.cuda()\n",
    "    attn_decoder1 = attn_decoder1.cuda()\n",
    "\n",
    "callback_num = 1000\n",
    "plot_losses = trainIters_weighted(encoder1, attn_decoder1, train_pairs, test_pairs, 100000, print_every=callback_num, \n",
    "                         plot_every=callback_num, evaluate_each=5000, learning_rate = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-f452abe3886e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_losses' is not defined"
     ]
    }
   ],
   "source": [
    "plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Using CUDA\n",
    "1m 0s (- 49m 32s) (1000 2%) 1.3384\n",
    "1m 56s (- 46m 37s) (2000 4%) 1.1094\n",
    "2m 52s (- 44m 55s) (3000 6%) 0.9032\n",
    "3m 47s (- 43m 32s) (4000 8%) 0.8677\n",
    "4m 42s (- 42m 22s) (5000 10%) 0.8003\n",
    "5m 38s (- 41m 21s) (6000 12%) 0.7245\n",
    "6m 33s (- 40m 15s) (7000 14%) 0.7180\n",
    "7m 28s (- 39m 16s) (8000 16%) 0.5546\n",
    "8m 25s (- 38m 20s) (9000 18%) 0.5971\n",
    "9m 21s (- 37m 24s) (10000 20%) 0.6258\n",
    "\t\t eval accuracy: 0.831"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10m 0s (- 991m 19s) (10000 1%) 0.0716\n",
      "19m 7s (- 936m 56s) (20000 2%) 0.0660\n",
      "28m 11s (- 911m 21s) (30000 3%) 0.0642\n",
      "37m 15s (- 894m 2s) (40000 4%) 0.0750\n",
      "46m 19s (- 880m 13s) (50000 5%) 0.0783\n",
      "\t\t eval accuracy: 0.945\n",
      "58m 57s (- 923m 37s) (60000 6%) 0.0748\n",
      "68m 4s (- 904m 24s) (70000 7%) 0.0711\n",
      "77m 7s (- 886m 55s) (80000 8%) 0.0685\n",
      "86m 14s (- 872m 1s) (90000 9%) 0.0708\n",
      "95m 18s (- 857m 49s) (100000 10%) 0.0752\n",
      "\t\t eval accuracy: 0.946\n",
      "107m 59s (- 873m 47s) (110000 11%) 0.0675\n",
      "117m 6s (- 858m 49s) (120000 12%) 0.0722\n",
      "126m 9s (- 844m 18s) (130000 13%) 0.0721\n",
      "135m 16s (- 830m 57s) (140000 14%) 0.0749\n",
      "144m 21s (- 818m 0s) (150000 15%) 0.0733\n",
      "\t\t eval accuracy: 0.945\n",
      "157m 3s (- 824m 33s) (160000 16%) 0.0709\n",
      "166m 10s (- 811m 18s) (170000 17%) 0.0687\n",
      "175m 13s (- 798m 14s) (180000 18%) 0.0720\n",
      "184m 17s (- 785m 41s) (190000 19%) 0.0703\n",
      "193m 24s (- 773m 38s) (200000 20%) 0.0763\n",
      "\t\t eval accuracy: 0.945\n",
      "206m 3s (- 775m 9s) (210000 21%) 0.0711\n",
      "215m 7s (- 762m 43s) (220000 22%) 0.0733\n",
      "224m 14s (- 750m 43s) (230000 23%) 0.0712\n",
      "233m 16s (- 738m 43s) (240000 24%) 0.0660\n",
      "242m 21s (- 727m 5s) (250000 25%) 0.0665\n",
      "\t\t eval accuracy: 0.944\n",
      "255m 2s (- 725m 53s) (260000 26%) 0.0735\n",
      "264m 7s (- 714m 7s) (270000 27%) 0.0751\n",
      "273m 13s (- 702m 34s) (280000 28%) 0.0763\n",
      "282m 16s (- 691m 5s) (290000 28%) 0.0695\n",
      "291m 20s (- 679m 48s) (300000 30%) 0.0771\n",
      "\t\t eval accuracy: 0.944\n",
      "304m 2s (- 676m 44s) (310000 31%) 0.0706\n",
      "313m 8s (- 665m 25s) (320000 32%) 0.0666\n",
      "322m 15s (- 654m 17s) (330000 33%) 0.0691\n",
      "331m 21s (- 643m 13s) (340000 34%) 0.0743\n",
      "340m 26s (- 632m 15s) (350000 35%) 0.0742\n",
      "\t\t eval accuracy: 0.942\n",
      "353m 5s (- 627m 43s) (360000 36%) 0.0708\n",
      "362m 11s (- 616m 41s) (370000 37%) 0.0778\n",
      "371m 18s (- 605m 48s) (380000 38%) 0.0753\n",
      "380m 22s (- 594m 57s) (390000 39%) 0.0777\n",
      "389m 25s (- 584m 8s) (400000 40%) 0.0640\n",
      "\t\t eval accuracy: 0.946\n",
      "402m 10s (- 578m 44s) (410000 41%) 0.0730\n",
      "411m 15s (- 567m 55s) (420000 42%) 0.0757\n",
      "420m 19s (- 557m 10s) (430000 43%) 0.0752\n",
      "429m 25s (- 546m 32s) (440000 44%) 0.0724\n",
      "438m 28s (- 535m 55s) (450000 45%) 0.0712\n",
      "\t\t eval accuracy: 0.942\n",
      "451m 8s (- 529m 35s) (460000 46%) 0.0724\n",
      "460m 13s (- 518m 58s) (470000 47%) 0.0689\n",
      "469m 17s (- 508m 23s) (480000 48%) 0.0685\n",
      "478m 20s (- 497m 51s) (490000 49%) 0.0715\n",
      "487m 24s (- 487m 24s) (500000 50%) 0.0800\n",
      "\t\t eval accuracy: 0.945\n",
      "500m 5s (- 480m 28s) (510000 51%) 0.0697\n",
      "509m 12s (- 470m 2s) (520000 52%) 0.0732\n",
      "518m 17s (- 459m 36s) (530000 53%) 0.0735\n",
      "527m 22s (- 449m 14s) (540000 54%) 0.0772\n",
      "536m 26s (- 438m 54s) (550000 55%) 0.0680\n",
      "\t\t eval accuracy: 0.943\n",
      "549m 10s (- 431m 29s) (560000 56%) 0.0735\n",
      "558m 17s (- 421m 10s) (570000 56%) 0.0665\n",
      "567m 21s (- 410m 50s) (580000 57%) 0.0735\n",
      "576m 26s (- 400m 34s) (590000 59%) 0.0789\n",
      "585m 34s (- 390m 23s) (600000 60%) 0.0774\n",
      "\t\t eval accuracy: 0.942\n",
      "598m 15s (- 382m 29s) (610000 61%) 0.0673\n",
      "607m 22s (- 372m 15s) (620000 62%) 0.0737\n",
      "616m 24s (- 362m 1s) (630000 63%) 0.0719\n",
      "625m 29s (- 351m 50s) (640000 64%) 0.0726\n",
      "634m 38s (- 341m 43s) (650000 65%) 0.0805\n",
      "\t\t eval accuracy: 0.944\n",
      "647m 16s (- 333m 26s) (660000 66%) 0.0786\n",
      "656m 20s (- 323m 16s) (670000 67%) 0.0782\n",
      "665m 25s (- 313m 8s) (680000 68%) 0.0741\n",
      "674m 32s (- 303m 3s) (690000 69%) 0.0765\n",
      "683m 39s (- 292m 59s) (700000 70%) 0.0676\n",
      "\t\t eval accuracy: 0.947\n",
      "696m 20s (- 284m 25s) (710000 71%) 0.0835\n",
      "705m 26s (- 274m 20s) (720000 72%) 0.0689\n",
      "714m 32s (- 264m 17s) (730000 73%) 0.0792\n",
      "723m 38s (- 254m 15s) (740000 74%) 0.0746\n",
      "732m 48s (- 244m 16s) (750000 75%) 0.0798\n",
      "\t\t eval accuracy: 0.943\n",
      "745m 33s (- 235m 26s) (760000 76%) 0.0783\n",
      "754m 39s (- 225m 25s) (770000 77%) 0.0665\n",
      "763m 45s (- 215m 25s) (780000 78%) 0.0700\n",
      "772m 54s (- 205m 27s) (790000 79%) 0.0725\n",
      "782m 1s (- 195m 30s) (800000 80%) 0.0754\n",
      "\t\t eval accuracy: 0.944\n",
      "794m 44s (- 186m 25s) (810000 81%) 0.0803\n",
      "803m 47s (- 176m 26s) (820000 82%) 0.0677\n",
      "812m 56s (- 166m 30s) (830000 83%) 0.0714\n",
      "822m 1s (- 156m 34s) (840000 84%) 0.0628\n",
      "831m 6s (- 146m 40s) (850000 85%) 0.0678\n",
      "\t\t eval accuracy: 0.942\n",
      "843m 48s (- 137m 21s) (860000 86%) 0.0750\n",
      "852m 53s (- 127m 26s) (870000 87%) 0.0753\n",
      "862m 1s (- 117m 32s) (880000 88%) 0.0768\n",
      "871m 7s (- 107m 40s) (890000 89%) 0.0777\n",
      "880m 15s (- 97m 48s) (900000 90%) 0.0786\n",
      "\t\t eval accuracy: 0.945\n",
      "892m 57s (- 88m 18s) (910000 91%) 0.0824\n",
      "902m 2s (- 78m 26s) (920000 92%) 0.0710\n",
      "911m 10s (- 68m 34s) (930000 93%) 0.0738\n",
      "920m 15s (- 58m 44s) (940000 94%) 0.0802\n",
      "929m 22s (- 48m 54s) (950000 95%) 0.0766\n",
      "\t\t eval accuracy: 0.943\n",
      "942m 7s (- 39m 15s) (960000 96%) 0.0775\n",
      "951m 13s (- 29m 25s) (970000 97%) 0.0744\n",
      "960m 16s (- 19m 35s) (980000 98%) 0.0688\n",
      "969m 20s (- 9m 47s) (990000 99%) 0.0818\n",
      "978m 28s (- 0m 0s) (1000000 100%) 0.0836\n",
      "\t\t eval accuracy: 0.940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d1cb73048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAD8CAYAAABAWd66AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c3ef0b978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b142827b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAD8CAYAAABAWd66AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c44e0af60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses = trainIters(encoder1, attn_decoder1, train_pairs, 1000000, print_every=callback_num, \n",
    "                         plot_every=callback_num, evaluate_each=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9m 33s (- 468m 22s) (10000 2%) 0.0770\n",
      "18m 35s (- 446m 11s) (20000 4%) 0.0663\n",
      "27m 39s (- 433m 24s) (30000 6%) 0.0677\n",
      "36m 49s (- 423m 32s) (40000 8%) 0.0638\n",
      "45m 53s (- 413m 5s) (50000 10%) 0.0647\n",
      "\t\t eval accuracy: 0.947\n",
      "58m 34s (- 429m 35s) (60000 12%) 0.0581\n",
      "67m 38s (- 415m 30s) (70000 14%) 0.0609\n",
      "76m 43s (- 402m 46s) (80000 16%) 0.0598\n",
      "85m 47s (- 390m 51s) (90000 18%) 0.0645\n",
      "94m 53s (- 379m 35s) (100000 20%) 0.0613\n",
      "\t\t eval accuracy: 0.952\n",
      "107m 34s (- 381m 24s) (110000 22%) 0.0596\n",
      "116m 39s (- 369m 26s) (120000 24%) 0.0525\n",
      "125m 45s (- 357m 55s) (130000 26%) 0.0580\n",
      "134m 51s (- 346m 47s) (140000 28%) 0.0635\n",
      "143m 56s (- 335m 50s) (150000 30%) 0.0581\n",
      "\t\t eval accuracy: 0.953\n",
      "156m 34s (- 332m 44s) (160000 32%) 0.0554\n",
      "165m 36s (- 321m 29s) (170000 34%) 0.0523\n",
      "174m 40s (- 310m 31s) (180000 36%) 0.0563\n",
      "183m 42s (- 299m 43s) (190000 38%) 0.0583\n",
      "192m 43s (- 289m 4s) (200000 40%) 0.0504\n",
      "\t\t eval accuracy: 0.954\n",
      "205m 16s (- 283m 28s) (210000 42%) 0.0534\n",
      "214m 17s (- 272m 43s) (220000 44%) 0.0520\n",
      "223m 20s (- 262m 10s) (230000 46%) 0.0572\n",
      "232m 24s (- 251m 46s) (240000 48%) 0.0506\n",
      "241m 26s (- 241m 26s) (250000 50%) 0.0577\n",
      "\t\t eval accuracy: 0.956\n",
      "254m 2s (- 234m 29s) (260000 52%) 0.0490\n",
      "263m 4s (- 224m 5s) (270000 54%) 0.0503\n",
      "272m 4s (- 213m 46s) (280000 56%) 0.0530\n",
      "281m 5s (- 203m 32s) (290000 57%) 0.0533\n",
      "290m 6s (- 193m 24s) (300000 60%) 0.0509\n",
      "\t\t eval accuracy: 0.957\n",
      "302m 43s (- 185m 32s) (310000 62%) 0.0545\n",
      "311m 46s (- 175m 22s) (320000 64%) 0.0567\n",
      "320m 47s (- 165m 15s) (330000 66%) 0.0542\n",
      "329m 50s (- 155m 13s) (340000 68%) 0.0551\n",
      "338m 55s (- 145m 15s) (350000 70%) 0.0507\n",
      "\t\t eval accuracy: 0.957\n",
      "351m 34s (- 136m 43s) (360000 72%) 0.0540\n",
      "360m 38s (- 126m 42s) (370000 74%) 0.0448\n",
      "369m 44s (- 116m 45s) (380000 76%) 0.0542\n",
      "378m 49s (- 106m 50s) (390000 78%) 0.0502\n",
      "387m 52s (- 96m 58s) (400000 80%) 0.0500\n",
      "\t\t eval accuracy: 0.959\n",
      "400m 30s (- 87m 55s) (410000 82%) 0.0524\n",
      "409m 34s (- 78m 0s) (420000 84%) 0.0532\n",
      "418m 38s (- 68m 9s) (430000 86%) 0.0466\n",
      "427m 39s (- 58m 19s) (440000 88%) 0.0548\n",
      "436m 42s (- 48m 31s) (450000 90%) 0.0438\n",
      "\t\t eval accuracy: 0.960\n",
      "449m 20s (- 39m 4s) (460000 92%) 0.0488\n",
      "458m 23s (- 29m 15s) (470000 94%) 0.0512\n",
      "467m 28s (- 19m 28s) (480000 96%) 0.0523\n",
      "476m 34s (- 9m 43s) (490000 98%) 0.0533\n",
      "485m 38s (- 0m 0s) (500000 100%) 0.0472\n",
      "\t\t eval accuracy: 0.960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d81ccb400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAD8CAYAAABAWd66AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1YaR0ygAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1cc8f4def0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c33773d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAD8CAYAAABAWd66AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c4630a390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses = trainIters(encoder1, attn_decoder1, train_pairs, 500000, print_every=callback_num, \n",
    "                         plot_every=callback_num, evaluate_each=50000, learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9m 12s (- 128m 51s) (10000 6%) 0.0526\n",
      "18m 14s (- 118m 31s) (20000 13%) 0.0540\n",
      "27m 14s (- 108m 56s) (30000 20%) 0.0541\n",
      "36m 17s (- 99m 48s) (40000 26%) 0.0522\n",
      "45m 21s (- 90m 43s) (50000 33%) 0.0481\n",
      "\t\t eval accuracy: 0.960\n",
      "57m 54s (- 86m 52s) (60000 40%) 0.0455\n",
      "66m 56s (- 76m 30s) (70000 46%) 0.0468\n",
      "75m 58s (- 66m 28s) (80000 53%) 0.0503\n",
      "85m 1s (- 56m 41s) (90000 60%) 0.0515\n",
      "94m 7s (- 47m 3s) (100000 66%) 0.0581\n",
      "\t\t eval accuracy: 0.960\n"
     ]
    }
   ],
   "source": [
    "plot_losses = trainIters(encoder1, attn_decoder1, train_pairs, 150000, print_every=callback_num, \n",
    "                         plot_every=callback_num, evaluate_each=50000, learning_rate = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind_to_test = -51\n",
    "\n",
    "print(input_list[ind_to_test])\n",
    "evaluate(encoder1, attn_decoder1, input_list[ind_to_test])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pairs = dev_pairs[-2000:]\n",
    "\n",
    "\n",
    "preds = np.array([(item[1], ' '.join(evaluate(encoder1, attn_decoder1, item[0])[0][:-1]), item[0]) for item in test_pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = np.array([item[0] == item[1] for item in preds] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61099999999999999"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61099999999999999"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_norm = np.array([item[0].lower() == item[1].lower() for item in preds] )\n",
    "results_norm.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['пятьдесят один', 'пятьсот одиннадцать',\n",
       "       'и с т р е б и т е л и Р - <CARDINAL> 5 1 </CARDINAL> « М у с т а н г »'],\n",
       "      dtype='<U141')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[~results][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind_to_test = 5\n",
    "\n",
    "print(input_list[ind_to_test])\n",
    "evaluate(encoder1, attn_decoder1, input_list[ind_to_test])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
